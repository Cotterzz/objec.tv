<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <title>WGSL Editor with Monaco</title>
    <style>
        body {
            margin: 0;
            padding: 10px;
            background: #1e1e1e;
            color: #d4d4d4;
            font-family: system-ui, -apple-system, sans-serif;
            overflow: hidden;
        }
        #editorTabs {
    display: flex;
    gap: 5px;
    margin-bottom: 5px;
}
.editorTab {
    background: #2d2d2d;
    color: #858585;
    border: none;
    padding: 6px 12px;
    cursor: pointer;
    font-size: 13px;
}
.editorTab.active {
    background: #1e1e1e;
    color: #d4d4d4;
}
#jsEditorContainer {
    display: none;
}
        #container {
            display: flex;
            gap: 10px;
            height: 98vh;
        }
        #leftPanel {
            flex: 1;
            display: flex;
            flex-direction: column;
            gap: 10px;
            min-width: 400px;
        }
        #rightPanel {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        #editorContainer {
            flex: 1;
            border: 1px solid #3c3c3c;
            overflow: hidden;
            position: relative;
        }
        #loadingMessage {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #858585;
            font-size: 14px;
        }
        #controls {
            display: flex;
            gap: 10px;
            align-items: center;
            flex-wrap: wrap;
        }
        button {
            background: #0e639c;
            color: white;
            border: none;
            padding: 8px 16px;
            cursor: pointer;
            font-size: 14px;
            font-weight: 500;
            transition: background 0.2s;
        }
        button:hover {
            background: #1177bb;
        }
        button.playing {
            background: #16825d;
        }
        button.playing:hover {
            background: #1a9870;
        }
        button.paused {
            background: #c5a332;
        }
        button.paused:hover {
            background: #d4b547;
        }
        #errorDisplay {
            background: #1e1e1e;
            border: 1px solid #3c3c3c;
            padding: 10px;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 12px;
            min-height: 60px;
            max-height: 120px;
            overflow-y: auto;
        }
        .error { color: #f48771; }
        .success { color: #4ec9b0; }
        .info { color: #9cdcfe; }
        #canvas {
            border: 1px solid #3c3c3c;
            image-rendering: pixelated;
        }
        .hint {
            color: #858585;
            font-size: 12px;
        }
        .statusBadge {
            display: inline-block;
            padding: 2px 8px;
            font-size: 11px;
            font-weight: bold;
        }
        .statusBadge.playing {
            background: #16825d;
            color: white;
        }
        .statusBadge.paused {
            background: #c5a332;
            color: white;
        }
    </style>
</head>
<body>
    <div id="container">
        <div id="leftPanel">
<div id="editorTabs" style="display: flex; gap: 5px; margin-bottom: 5px; align-items: center;">
    <!-- Tabs will be dynamically added here -->
    <button id="addPassBtn" style="padding: 6px 12px; font-size: 13px; margin-left: auto;">+ Add Pass</button>
</div>
<div id="boilerplateContainer" style="flex: 1; border: 1px solid #3c3c3c; overflow: hidden; display: none;">
</div>
<div id="graphicsContainer" style="flex: 1; border: 1px solid #3c3c3c; overflow: hidden;">
    <div id="loadingMessage">Loading Monaco Editor...</div>
</div>
<div id="audioContainer" style="flex: 1; border: 1px solid #3c3c3c; overflow: hidden; display: none;">
</div>
<div id="jsEditorContainer" style="flex: 1; border: 1px solid #3c3c3c; overflow: hidden; display: none;">
</div>
<div id="helpContainer" style="flex: 1; border: 1px solid #3c3c3c; overflow: hidden; display: none;">
</div>
            <div>
                <div class="hint">Status:</div>
                <div id="errorDisplay" class="info">Loading editor...</div>
            </div>
        </div>
        <div id="rightPanel">
            <canvas id="canvas"></canvas>
            <div id="controls">
                <button id="playPauseBtn" class="playing">⏸</button>
                <button id="restartBtn" title="Restart from beginning">⟳</button>
                <button id="reloadBtn" title="Reload shaders">⚙</button>
                <label style="color: #858585;">
                    Volume: <input type="range" id="volumeSlider" min="0" max="100" value="50" style="width: 100px;">
                    <span id="volumeValue">50%</span>
                </label>
            </div>
            <div class="hint">
                Frame: <span id="frameCounter">0</span><br>
                Time: <span id="timeCounter">0.00s</span>
            </div>
            <div style="display: flex; gap: 5px; align-items: center; margin-top: 10px;">
                <label style="color: #858585; font-size: 13px;">Example:</label>
                <select id="exampleSelector" style="background: #2d2d2d; color: #d4d4d4; border: 1px solid #3c3c3c; padding: 4px 8px; font-size: 13px; cursor: pointer; flex: 1;">
                    <!-- Populated by JS -->
                </select>
            </div>
        </div>
    </div>

    <!-- Load from CDN -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/monaco-editor/0.44.0/min/vs/loader.min.js"></script>
    
    <script>
    'use strict';

    // Monaco Editor Setup

    let monacoEditor = null;

    // Configure Monaco loader
    require.config({ 
        paths: { 
            'vs': 'https://cdnjs.cloudflare.com/ajax/libs/monaco-editor/0.44.0/min/vs' 
        }
    });

    // Define WGSL language configuration
    const WGSL_LANGUAGE_CONFIG = {
        comments: {
            lineComment: '//',
            blockComment: ['/*', '*/']
        },
        brackets: [
            ['{', '}'],
            ['[', ']'],
            ['(', ')']
        ],
        autoClosingPairs: [
            { open: '{', close: '}' },
            { open: '[', close: ']' },
            { open: '(', close: ')' },
            { open: '"', close: '"', notIn: ['string'] },
        ],
        surroundingPairs: [
            { open: '{', close: '}' },
            { open: '[', close: ']' },
            { open: '(', close: ')' },
            { open: '"', close: '"' },
        ]
    };

    // WGSL syntax highlighting
    const WGSL_MONARCH_TOKENS = {
        keywords: [
            'const', 'let', 'var', 'fn', 'return', 'if', 'else', 'for', 'while',
            'break', 'continue', 'discard', 'struct', 'type', 'alias'
        ],
        typeKeywords: [
            'f32', 'f16', 'i32', 'u32', 'bool',
            'vec2f', 'vec3f', 'vec4f', 'vec2i', 'vec3i', 'vec4i', 'vec2u', 'vec3u', 'vec4u',
            'vec2', 'vec3', 'vec4',
            'mat2x2', 'mat2x3', 'mat2x4', 'mat3x2', 'mat3x3', 'mat3x4', 'mat4x2', 'mat4x3', 'mat4x4',
            'mat2x2f', 'mat2x3f', 'mat2x4f', 'mat3x2f', 'mat3x3f', 'mat3x4f', 'mat4x2f', 'mat4x3f', 'mat4x4f',
            'array', 'ptr', 'sampler', 'texture_2d', 'texture_storage_2d'
        ],
        builtins: [
            'position', 'vertex_index', 'instance_index', 'front_facing', 'frag_depth',
            'local_invocation_id', 'local_invocation_index', 'global_invocation_id',
            'workgroup_id', 'num_workgroups', 'sample_index', 'sample_mask'
        ],
        operators: [
            '=', '>', '<', '!', '~', '?', ':', '==', '<=', '>=', '!=',
            '&&', '||', '++', '--', '+', '-', '*', '/', '&', '|', '^', '%',
            '<<', '>>', '+=', '-=', '*=', '/=', '&=', '|=', '^=',
            '%=', '<<=', '>>=', '->'
        ],
        functions: [
            'sin', 'cos', 'tan', 'asin', 'acos', 'atan', 'atan2',
            'sinh', 'cosh', 'tanh', 'asinh', 'acosh', 'atanh',
            'pow', 'exp', 'log', 'exp2', 'log2', 'sqrt', 'inverseSqrt',
            'abs', 'sign', 'floor', 'ceil', 'fract', 'trunc', 'round',
            'min', 'max', 'clamp', 'saturate', 'mix', 'step', 'smoothstep',
            'length', 'distance', 'dot', 'cross', 'normalize', 'reflect', 'refract',
            'select', 'all', 'any', 'arrayLength', 'textureStore', 'textureLoad'
        ],
        tokenizer: {
            root: [
                // Attributes
                [/@[a-zA-Z_]\w*/, 'annotation'],
                
                // Keywords
                [/\b(fn|let|const|var|return|if|else|for|while|break|continue|struct)\b/, 'keyword'],
                
                // Type keywords
                [/\b(f32|f16|i32|u32|bool|vec2f|vec3f|vec4f|vec2i|vec3i|vec4i|vec2u|vec3u|vec4u|vec2|vec3|vec4|mat2x2|mat3x3|mat4x4|array|ptr|sampler|texture_2d|texture_storage_2d)\b/, 'type'],
                
                // Built-in functions
                [/\b(sin|cos|tan|abs|min|max|clamp|mix|length|dot|normalize|cross|select|textureStore|textureLoad)\b/, 'support.function'],
                
                // Numbers
                [/\b\d+\.?\d*[fu]?\b/, 'number'],
                [/0[xX][0-9a-fA-F]+[ul]?/, 'number'],
                
                // Strings
                [/"([^"\\]|\\.)*$/, 'string.invalid'],
                [/"/, { token: 'string.quote', bracket: '@open', next: '@string' }],
                
                // Comments
                [/\/\/.*$/, 'comment'],
                [/\/\*/, { token: 'comment', next: '@comment' }],
                
                // Operators
                [/[<>]=?/, 'operator'],
                [/[+\-*\/%=&|^!~]/, 'operator'],
                
                // Delimiters
                [/[{}()\[\]]/, '@brackets'],
                [/[;,.]/, 'delimiter'],
            ],
            comment: [
                [/[^\/*]+/, 'comment'],
                [/\/\*/, 'comment', '@push'],
                ['\\*/', 'comment', '@pop'],
                [/[\/*]/, 'comment']
            ],
            string: [
                [/[^\\"]+/, 'string'],
                [/"/, { token: 'string.quote', bracket: '@close', next: '@pop' }]
            ],
        }
    };

    // Configuration & Constants

    const CONFIG = {
        audioBlockDuration: 0.05,
        channels: 2,
        volume: 0.5,
        screenSize: 512,
        computeThreads: 64,
        computeBufferSize: 65536,  // 64 KB (was 2 MB) - for data sharing between passes
    };

    // These will be set after AudioContext is created
    const DERIVED = {
        sampleRate: 0,              // Read from AudioContext
        samplesPerBlock: 0,         // Calculated from actual sample rate
        audioBufferSize: 0,         // Calculated from samplesPerBlock
        audioWorkgroups: 0,         // Ceil(samplesPerBlock / computeThreads)
    };

    const UNIFORM_STRUCT = {
        time: 0,
        audioCurrentTime: 1,
        audioPlayTime: 2,
        audioFractTime: 3,
        audioFrame: 4,
        SIZE: 5,
    };

    // Application State

    const state = {
        gpuDevice: null,
        audioContext: null,
        gainNode: null,
        
        canvas: null,
        gpuContext: null,
        bindGroupLayout: null,
        graphicsPipeline: null,
        audioPipeline: null,
        uniformBuffer: null,
        computeBuffer: null,
        phaseStateBuffer: null,
        audioBufferGPU: null,
        audioBuffersReadback: [null, null],
        
        lastFrameTime: 0,
        visualFrame: 0,        // Visual frame counter (increments every render)
        audioFrame: 0,         // Audio frame counter (increments when audio generated)
        nextAudioTime: 0,
        startTime: 0,          // When animation started (for time offset)
        pausedTime: 0,         // Total time spent paused
        lastPauseTime: 0,      // When we last paused
        
        readbackIndex: 0,
        pendingAudio: false,
        isRunning: false,      // System initialized and ready
        isPlaying: true,       // Currently playing (default true)
    
        // Monaco editors
        boilerplateEditor: null,
        graphicsEditor: null,
        audioEditor: null,
        jsEditor: null,
        helpEditor: null,
        
        // Active tabs and current example
        activeTabs: ['graphics', 'help'],  // Start with just these
        currentTab: 'graphics',
        currentExample: 'hello_world',
        
        userState: null,
        userInit: null,
        userEnterframe: null,
        mouseX: 0.5,
        mouseY: 0.5,
};


    // Default WGSL Shader Parts

function getBoilerplate() {
    return `// ============================================================================
// AUTO-GENERATED BOILERPLATE
// This section is read-only and updates when settings change
// ============================================================================

const SAMPLE_RATE = ${DERIVED.sampleRate}f;
const SAMPLES_PER_BLOCK = ${DERIVED.samplesPerBlock};
const COMPUTE_THREADS = ${CONFIG.computeThreads};
const SCREEN_SIZE = ${CONFIG.screenSize};
const PI = 3.1415926535897932f;
const TAU = 6.283185307179586f;

struct Uniforms {
    time: f32,              // 0
    audioCurrentTime: f32,  // 1
    audioPlayTime: f32,     // 2
    audioFractTime: f32,    // 3
    audioFrame: i32,        // 4
    
    // User-accessible uniforms (controlled from JavaScript)
    mouseX: f32,            // 5
    mouseY: f32,            // 6
    frequency: f32,         // 7
    user3: f32,             // 8
    user4: f32,             // 9
}

@binding(0) @group(0) var<uniform> uniforms: Uniforms;
@binding(1) @group(0) var<storage, read_write> computeBuffer: array<f32>;
@binding(2) @group(0) var<storage, read_write> audioBuffer: array<f32>;
@binding(3) @group(0) var screenTexture: texture_storage_2d<bgra8unorm, write>;
@binding(4) @group(0) var<storage, read_write> phaseState: array<f32>;
`;
}

function getDefaultGraphicsShader() {
    return `// ============================================================================
// GRAPHICS SHADER - Edit this to create visuals
// ============================================================================
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_SIZE) || gid.y >= u32(SCREEN_SIZE)) {
        return;
    }
    
    let uv = vec2f(gid.xy) / f32(SCREEN_SIZE);
    let t = uniforms.time;
    
    // Background pattern (dimmed)
    let mouseOffset = vec2f(uniforms.mouseX, uniforms.mouseY) * 5.0;
    let pattern = cos((uv + mouseOffset) * 10.0 + t);
    var color = vec3f(
        pattern.x * 0.15 + 0.15,
        pattern.y * 0.15 + 0.15,
        0.2
    );
    
    // Draw multi-scale waveforms
    let waveformCount = 4;
    let waveformColors = array<vec3f, 4>(
        vec3f(0.0, 1.0, 0.5),   // Cyan-green
        vec3f(1.0, 0.8, 0.0),   // Yellow
        vec3f(1.0, 0.3, 0.5),   // Pink
        vec3f(0.5, 0.5, 1.0)    // Light blue
    );
    
    for (var i = 0; i < waveformCount; i++) {
        let waveformY = (f32(i) + 0.5) / f32(waveformCount);  // Vertical position
        let zoom = pow(4.0, f32(i));  // 1x, 4x, 16x, 64x zoom
        
        // Sample audio buffer at current X position with zoom
        let samplePos = i32(uv.x * f32(SAMPLES_PER_BLOCK) / zoom) % SAMPLES_PER_BLOCK;
        let audioSample = audioBuffer[samplePos];  // Left channel (mono for simplicity)
        
        // Convert audio sample (-1 to 1) to screen space around waveformY
        let waveformHeight = 0.15 / f32(waveformCount);  // Height of each waveform strip
        let sampleY = waveformY + audioSample * waveformHeight;
        
        // Anti-aliased line drawing
        let distToWaveform = abs(uv.y - sampleY);
        let lineThickness = 0.003;
        let lineIntensity = smoothstep(lineThickness * 2.0, lineThickness * 0.5, distToWaveform);
        
        // Add waveform to color
        color += waveformColors[i] * lineIntensity * 0.8;
        
        // Draw center line for reference
        let centerDist = abs(uv.y - waveformY);
        let centerLine = smoothstep(0.002, 0.001, centerDist) * 0.2;
        color += vec3f(0.3) * centerLine;
    }
    
    // Draw scale labels (grid lines at divisions)
    for (var i = 0; i < waveformCount + 1; i++) {
        let divY = f32(i) / f32(waveformCount);
        let divDist = abs(uv.y - divY);
        let divLine = smoothstep(0.002, 0.001, divDist) * 0.3;
        color += vec3f(0.5) * divLine;
    }
    
    textureStore(screenTexture, gid.xy, vec4f(color, 1.0));
}
`;
}

function getDefaultAudioShader() {
    return `// ============================================================================
// AUDIO SHADER - Edit this to create sound
// ============================================================================
@compute @workgroup_size(128, 1, 1)
fn audio_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    let sampleIndex = i32(gid.x);
    
    // Early exit for threads beyond sample count
    if (sampleIndex >= SAMPLES_PER_BLOCK) {
        return;
    }
    
    // GPU-SIDE PHASE ACCUMULATION - Perfect timing!
    // Read persistent phase from previous block (stored on GPU)
    let basePhase = phaseState[0];
    
    // Calculate phase increment per sample using CURRENT frequency
    let phaseIncrement = uniforms.frequency * TAU / SAMPLE_RATE;
    
    // Calculate phase for THIS specific sample
    var phase = basePhase + f32(sampleIndex) * phaseIncrement;
    
    // Generate audio sample
    let sample = sin(phase) * 0.3;
    
    // Write to interleaved stereo buffer
    audioBuffer[sampleIndex] = sample;
    audioBuffer[SAMPLES_PER_BLOCK + sampleIndex] = sample;
    
    // CRITICAL: Only the very last thread updates phase state
    // This ensures one and only one write happens
    if (sampleIndex == SAMPLES_PER_BLOCK - 1) {
        // Calculate final phase after all samples
        var finalPhase = basePhase + f32(SAMPLES_PER_BLOCK) * phaseIncrement;
        
        // Wrap phase to [0, TAU) range to prevent precision loss
        // Use while loop for robust wrapping
        while (finalPhase >= TAU) {
            finalPhase -= TAU;
        }
        while (finalPhase < 0.0) {
            finalPhase += TAU;
        }
        
        phaseState[0] = finalPhase;
    }
}
`;
}

// Minimal starter code for when user adds a new tab
const MINIMAL_JS = `function init() {
    return {};
}

function enterframe(state, api) {
    // Pass mouse position to shader
    api.uniforms.setFloat(5, api.mouse.x);
    api.uniforms.setFloat(6, api.mouse.y);
}`;

const MINIMAL_AUDIO = `// Simple sine wave
@compute @workgroup_size(128, 1, 1)
fn audio_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    let sampleIndex = i32(gid.x);
    if (sampleIndex >= SAMPLES_PER_BLOCK) { return; }
    
    let t = f32(sampleIndex) / SAMPLE_RATE;
    let sample = sin(t * 440.0 * TAU) * 0.3;
    
    audioBuffer[sampleIndex] = sample;
    audioBuffer[SAMPLES_PER_BLOCK + sampleIndex] = sample;
}`;

const DEFAULT_JS = `// This code runs alongside your WGSL shader
// Use 'state' to persist data between frames

function init() {
    // Called once when you press Play
    return {
        mouseX: 0,
        mouseY: 0,
        targetFreq: 440,
        smoothFreq: 440,
    };
}

function enterframe(state, api) {
    // Called every frame while playing
    
    // Smooth mouse movement
    state.mouseX += (api.mouse.x - state.mouseX) * 0.1;
    state.mouseY += (api.mouse.y - state.mouseY) * 0.1;
    
    // Change frequency
    state.targetFreq = 440 + (1. + state.mouseX) * 220 ;
    
    // Optional: smooth frequency changes for even cleaner sound
    state.smoothFreq += (state.targetFreq - state.smoothFreq) * 0.3;
    
    // Pass data to WGSL shader uniforms
    // Indices 5-9 map to: mouseX, mouseY, frequency, user3, user4
    api.uniforms.setFloat(5, state.mouseX);
    api.uniforms.setFloat(6, state.mouseY);
    api.uniforms.setFloat(7, state.smoothFreq);
    
    // You can use user3 and user4 for other data:
    // api.uniforms.setFloat(8, someValue);
    // api.uniforms.setFloat(9, anotherValue);
}`;

// ============================================================================
// EXAMPLES LIBRARY
// ============================================================================

const EXAMPLES = {
    hello_world: {
        name: "Hello World",
        description: "A simple gradient",
        tabs: ["graphics", "help"],
        graphics: `// Simple gradient - your first shader!
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_SIZE) || gid.y >= u32(SCREEN_SIZE)) {
        return;
    }
    
    let uv = vec2f(gid.xy) / f32(SCREEN_SIZE);
    let color = vec3f(uv.x, uv.y, 0.5);
    
    textureStore(screenTexture, gid.xy, vec4f(color, 1.0));
}`,
        audio: null,
        js: null
    },
    
    animated_pattern: {
        name: "Animated Pattern",
        description: "Time-based animation",
        tabs: ["graphics"],
        graphics: `// Animated pattern using time
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_SIZE) || gid.y >= u32(SCREEN_SIZE)) {
        return;
    }
    
    let uv = vec2f(gid.xy) / f32(SCREEN_SIZE);
    let t = uniforms.time;
    
    // Rotating pattern
    let angle = atan2(uv.y - 0.5, uv.x - 0.5);
    let radius = length(uv - 0.5);
    let pattern = sin(angle * 5.0 + t) * cos(radius * 20.0 - t * 2.0);
    
    let color = vec3f(
        pattern * 0.5 + 0.5,
        sin(t * 0.5) * 0.5 + 0.5,
        cos(t * 0.3) * 0.5 + 0.5
    );
    
    textureStore(screenTexture, gid.xy, vec4f(color, 1.0));
}`,
        audio: null,
        js: null
    },
    
    mouse_interactive: {
        name: "Mouse Interactive",
        description: "Mouse controls the pattern",
        tabs: ["graphics", "js"],
        graphics: `// Mouse-controlled visuals
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_SIZE) || gid.y >= u32(SCREEN_SIZE)) {
        return;
    }
    
    let uv = vec2f(gid.xy) / f32(SCREEN_SIZE);
    let mouse = vec2f(uniforms.mouseX, 1.0-uniforms.mouseY);
    let t = uniforms.time;
    
    // Distance from mouse
    let dist = length(uv - mouse);
    
    // Ripple effect
    let ripple = sin(dist * 20.0 - t * 3.0) * 0.5 + 0.5;
    
    // Color based on distance and time
    let color = vec3f(
        ripple * (1.0 - dist),
        dist,
        sin(t + dist * 5.0) * 0.5 + 0.5
    );
    
    textureStore(screenTexture, gid.xy, vec4f(color, 1.0));
}`,
        audio: null,
        js: `function init() {
    return {
        mouseX: 0.5,
        mouseY: 0.5,
    };
}

function enterframe(state, api) {
    // Smooth mouse tracking
    state.mouseX += (api.mouse.x - state.mouseX) * 0.1;
    state.mouseY += (api.mouse.y - state.mouseY) * 0.1;
    
    api.uniforms.setFloat(5, state.mouseX);
    api.uniforms.setFloat(6, state.mouseY);
}`
    },
    
    simple_tone: {
        name: "Simple Tone",
        description: "Basic audio synthesis",
        tabs: ["graphics", "audio", "js"],
        graphics: `// Visualize the frequency
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_SIZE) || gid.y >= u32(SCREEN_SIZE)) {
        return;
    }
    
    let uv = vec2f(gid.xy) / f32(SCREEN_SIZE);
    let freq = uniforms.frequency;
    
    // Frequency visualization
    let normalizedFreq = (freq - 220.0) / 660.0;  // Range: 220-880 Hz
    let freqLine = smoothstep(0.02, 0.01, abs(uv.y - normalizedFreq));
    
    // Background gradient
    var color = vec3f(uv.x * 0.2, uv.y * 0.2, 0.3);
    
    // Frequency indicator line
    color += vec3f(0.0, 1.0, 0.5) * freqLine;
    
    textureStore(screenTexture, gid.xy, vec4f(color, 1.0));
}`,
        audio: `// Simple sine wave tone
@compute @workgroup_size(128, 1, 1)
fn audio_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    let sampleIndex = i32(gid.x);
    
    if (sampleIndex >= SAMPLES_PER_BLOCK) {
        return;
    }
    
    // GPU-side phase accumulation
    let basePhase = phaseState[0];
    let phaseIncrement = uniforms.frequency * TAU / SAMPLE_RATE;
    var phase = basePhase + f32(sampleIndex) * phaseIncrement;
    
    // Generate sine wave
    let sample = sin(phase) * 0.3;
    
    // Write stereo
    audioBuffer[sampleIndex] = sample;
    audioBuffer[SAMPLES_PER_BLOCK + sampleIndex] = sample;
    
    // Update phase state (last thread only)
    if (sampleIndex == SAMPLES_PER_BLOCK - 1) {
        var finalPhase = basePhase + f32(SAMPLES_PER_BLOCK) * phaseIncrement;
        while (finalPhase >= TAU) {
            finalPhase -= TAU;
        }
        while (finalPhase < 0.0) {
            finalPhase += TAU;
        }
        phaseState[0] = finalPhase;
    }
}`,
        js: `function init() {
    return {
        mouseX: 0.5,
        mouseY: 0.5,
        frequency: 440,
    };
}

function enterframe(state, api) {
    state.mouseX += (api.mouse.x - state.mouseX) * 0.1;
    state.mouseY += (api.mouse.y - state.mouseY) * 0.1;
    
    // Mouse X controls frequency (220-880 Hz)
    state.frequency = 220 + state.mouseX * 660;
    
    api.uniforms.setFloat(5, state.mouseX);
    api.uniforms.setFloat(6, state.mouseY);
    api.uniforms.setFloat(7, state.frequency);
}`
    },
    
    waveform_viz: {
        name: "Waveform Visualizer",
        description: "Multi-scale audio visualization (complex)",
        tabs: ["graphics", "audio", "js", "boilerplate"],
        graphics: getDefaultGraphicsShader(),
        audio: getDefaultAudioShader(),
        js: DEFAULT_JS
    }
};

function getHelpContent() {
    return `WEBGPU COMPUTE SHADER EDITOR - QUICK START GUIDE
═══════════════════════════════════════════════════════════════════

OVERVIEW
────────
This is a live WebGPU compute shader editor with real-time graphics and audio
output. You write WGSL shaders that run on your GPU to generate both visuals
and audio simultaneously.

EDITOR TABS
───────────
📄 BOILERPLATE - Auto-generated shader setup (read-only)
   Contains all uniforms, buffers, and constants. Updated when settings change.

🎨 GRAPHICS - Your graphics shader code
   Entry point: graphics_main(@builtin(global_invocation_id) id: vec3<u32>)
   Write to: textureOutput (512x512 RGBA8)
   Workgroup size: 8x8x1 (optimized for 2D rendering)

🔊 AUDIO - Your audio synthesis shader code
   Entry point: audio_main(@builtin(global_invocation_id) id: vec3<u32>)
   Write to: audioBuffer (stereo interleaved)
   Workgroup size: 128x1x1 (optimized for 1D audio)
   Phase accumulation handled on GPU for smooth frequency changes

⚡ JAVASCRIPT - Runtime control code
   init() - Called once when you press Play
   enterframe(state, api) - Called every visual frame (~60 FPS)
   Use this to animate uniforms, respond to mouse input, etc.

❓ HELP - This guide + WGSL cheatsheet

CONTROLS
────────
▶/⏸ - Play/Pause audio and shader execution
⟳ - Reload shader (also: F5 or Ctrl+S in any editor)
Volume Slider - Control audio output volume
Ctrl+Space - Toggle play/pause from any editor

AVAILABLE UNIFORMS (read-only in your shaders)
──────────────────────────────────────────────
struct Uniforms {
    time: f32,              // Total elapsed time in seconds
    audioCurrentTime: f32,  // Web Audio API current time
    audioPlayTime: f32,     // Time since playback started
    audioFractTime: f32,    // Fractional part of audio time
    audioFrame: u32,        // Current audio block number
    mouseX: f32,            // Mouse X position [0, 1] (set from JS)
    mouseY: f32,            // Mouse Y position [0, 1] (set from JS)
    frequency: f32,         // Audio frequency in Hz (set from JS)
    user3: f32,             // Custom uniform 3 (set from JS)
    user4: f32,             // Custom uniform 4 (set from JS)
}

Access in shaders: uniforms.time, uniforms.mouseX, etc.

AVAILABLE BUFFERS
─────────────────
@group(0) @binding(1) var<storage, read_write> computeBuffer: array<f32>;
  - 64KB shared buffer for passing data between graphics and audio passes

@group(0) @binding(2) var textureOutput: texture_storage_2d<rgba8unorm, write>;
  - 512x512 texture for graphics output

@group(0) @binding(3) var<storage, read_write> audioBuffer: array<f32>;
  - Stereo audio buffer (interleaved L/R channels)
  - Size depends on sample rate (typically 2205 or 2400 samples per block)

@group(0) @binding(4) var<storage, read_write> phaseState: array<f32>;
  - Single float for persistent phase accumulation (audio synthesis)

JAVASCRIPT API
──────────────
In your enterframe() function, you have access to:

api.time - Current time in seconds
api.audioFrame - Current audio block number
api.mouse.x, api.mouse.y - Mouse position [0, 1]
api.uniforms.setFloat(index, value) - Set uniform values:
  - Index 5: mouseX
  - Index 6: mouseY
  - Index 7: frequency (Hz)
  - Index 8: user3
  - Index 9: user4

TIPS & TRICKS
─────────────
• The audio pass runs at ~20 FPS (every 0.05 seconds by default)
• The graphics pass runs at ~60 FPS (every visual frame)
• Use computeBuffer to visualize audio data in your graphics shader
• Phase accumulation for audio happens on GPU - no need to manage it in JS
• Smooth frequency changes in JS for cleaner audio (see default JS code)
• Use the audioBuffer in graphics_main to visualize waveforms
• Press Ctrl+S or F5 in any editor to quickly reload your shader

COMMON PATTERNS
───────────────
Graphics: Distance field rendering, raymarching, cellular automata
Audio: Additive synthesis, FM synthesis, wavetable synthesis
Combined: Reactive visuals driven by audio parameters

PERFORMANCE
───────────
• Workgroup sizes are optimized: 8x8x1 for graphics, 128x1x1 for audio
• Avoid divergent branches in hot loops
• Use shared memory (var<workgroup>) for local collaboration
• Remember: This all runs on your GPU in parallel!


═══════════════════════════════════════════════════════════════════
WGSL LANGUAGE CHEATSHEET
═══════════════════════════════════════════════════════════════════

` + `// Assignment and declaration with let, var, const - All three support type inference
const A = 5u;           // const for compile time constants
let B = 5.0;            // let for immutable values that wont change
var C = vec3(1.0);      // var for mutable values, loop counters etc
// var is less efficient, use let unless you have to use var
// All three support type specifiers
const D:u32 = 5u; let E:f32 = 5.0; var F:vec3<f32> = vec3(1.0);
// var only - optional assignment, mandatory type
var G:f32;  G = 5.0;

//Scalar Types
var a: bool = true;
var b: i32 = -42;           // 32-bit signed integer
var c: u32 = 42u;           // 32-bit unsigned integer
var d: f32 = 3.14f;         // 32-bit float
var e: f16 = 1.5h;          // 16-bit float (requires extension)
//Vector Types
var v2f: vec2<f32> = vec2(1.0, 2.0);
var v3f: vec3<f32> = vec3(1.0, 2.0, 3.0);
var v4f: vec4<f32> = vec4(1.0, 2.0, 3.0, 4.0);
var v2i: vec2<i32> = vec2<i32>(1, 2);
var v3u: vec3<u32> = vec3<u32>(1u, 2u, 3u);
var v4b: vec4<bool> = vec4<bool>(true, false, true, false);
// Swizzling is read only/right hand side, unless its single component
var xy: vec2<f32> = v4f.xy;
var bgr: vec3<f32> = v4f.bgr;
var wzyx: vec4<f32> = v4f.wzyx;
//Matrix Types
var m2x2: mat2x2<f32> = mat2x2<f32>(1.0, 0.0, 0.0, 1.0);
var m3x3: mat3x3<f32> = mat3x3<f32>(/* 9 values */);
var m4x4: mat4x4<f32> = mat4x4<f32>(/* 16 values */);
// Non-square matrices
var m2x3: mat2x3<f32>;  // 2 columns, 3 rows
var m3x2: mat3x2<f32>;  // 3 columns, 2 rows
var m2x4: mat2x4<f32>;
var m4x2: mat4x2<f32>;
var m3x4: mat3x4<f32>;
var m4x3: mat4x3<f32>;
// Access
var col: vec3<f32> = m3x3[0];      // First column
var element: f32 = m3x3[1][2];     // Column 1, row 2
//Atomic Types
var<storage, read_write> atomic_val: atomic<i32>;
var<storage, read_write> atomic_uval: atomic<u32>;
//Array Types
// Fixed-size arrays
var arr: array<f32, 4> = array<f32, 4>(1.0, 2.0, 3.0, 4.0);
var arr2: array<vec3<f32>, 2>;
// Runtime-sized arrays (only in storage buffers, must be last member)
struct Buffer {
    data: array<f32>  // Runtime-sized
}
//Structs
struct MyStruct {
    position: vec3<f32>,
    @align(16) color: vec4<f32>,  // Explicit alignment
    @size(32) value: f32,          // Explicit size
    count: u32,
}
var s: MyStruct = MyStruct(
    vec3(0.0, 0.0, 0.0),
    vec4(1.0, 0.0, 0.0, 1.0),
    42.0,
    10u
);

// Access
var pos: vec3<f32> = s.position;
s.count = 20u;
Storage Qualifiers & Address Spaces
// Function scope (default)
var local_var: f32;

// Uniform buffer (read-only)
@group(0) @binding(0) var<uniform> uniforms: MyUniforms;

// Storage buffer (read or read_write)
@group(0) @binding(1) var<storage, read> input: Buffer;
@group(0) @binding(2) var<storage, read_write> output: Buffer;

// Workgroup shared memory
var<workgroup> shared_data: array<f32, 256>;

// Private (per-invocation)
var<private> private_var: f32;
//Math Operators
// Arithmetic
var add = a + b;
var sub = a - b;
var mul = a * b;
var div = a / b;
var mod = a % b;  // Integers only
var neg = -a;

// Compound assignment
a += b;
a -= b;
a *= b;
a /= b;
a %= b;  // Integers only

// Comparison
var eq = a == b;
var ne = a != b;
var lt = a < b;
var le = a <= b;
var gt = a > b;
var ge = a >= b;

// Logical
var and = a && b;
var or = a || b;
var not = !a;

// Bitwise (integers only)
var bit_and = a & b;
var bit_or = a | b;
var bit_xor = a ^ b;
var bit_not = ~a;
var shift_left = a << b;
var shift_right = a >> b;

// Compound assignment 2 (ints only)
a &= 5;   // a = a & 5
a |= 5;   // a = a | 5
a ^= 5;   // a = a ^ 5
a <<= 2;  // a = a << 2
a >>= 2;  // a = a >> 2

// Vector/Matrix operations
var v_add = v1 + v2;           // Component-wise
var v_mul = v1 * 2.0;          // Scalar multiplication
var dot_prod = dot(v1, v2);    // Dot product
var cross_prod = cross(v1, v2); // Cross product (vec3 only)
var m_mul = m1 * m2;           // Matrix multiplication
var mv_mul = m * v;            // Matrix-vector multiplication
//Built-in Functions (Compute Shader Safe)
//Math Functions
// Basic math
abs(x)                  // Absolute value
sign(x)                 // Sign (-1, 0, or 1)
floor(x)                // Round down
ceil(x)                 // Round up
round(x)                // Round to nearest
trunc(x)                // Truncate decimal
fract(x)                // Fractional part
modf(x)                 // Split to integer and fractional (returns struct)
clamp(x, min, max)      // Clamp to range
min(a, b)               // Minimum
max(a, b)               // Maximum
mix(a, b, t)            // Linear interpolation: a*(1-t) + b*t
step(edge, x)           // 0 if x < edge, else 1
smoothstep(low, high, x) // Smooth interpolation
saturate(x)             // Clamp to [0, 1]

// Power/Exponential
pow(x, y)               // x^y
exp(x)                  // e^x
exp2(x)                 // 2^x
log(x)                  // Natural logarithm
log2(x)                 // Base-2 logarithm
sqrt(x)                 // Square root
inverseSqrt(x)          // 1/sqrt(x)

// Trigonometry (radians)
sin(x)
cos(x)
tan(x)
asin(x)
acos(x)
atan(x)
atan2(y, x)             // atan(y/x) with correct quadrant
sinh(x)
cosh(x)
tanh(x)
asinh(x)
acosh(x)
atanh(x)
radians(degrees)
degrees(radians)

// Vector functions
dot(v1, v2)             // Dot product
cross(v1, v2)           // Cross product (vec3 only)
length(v)               // Vector length
distance(p1, p2)        // Distance between points
normalize(v)            // Unit vector
faceforward(N, I, Nref) // Flip N if needed
reflect(I, N)           // Reflect vector
refract(I, N, eta)      // Refract vector

// Matrix functions
determinant(m)          // Matrix determinant
transpose(m)            // Matrix transpose
//Bitwise Functions
countOneBits(x)         // Count set bits
reverseBits(x)          // Reverse bit order
firstLeadingBit(x)      // Position of first 1 from MSB
firstTrailingBit(x)     // Position of first 1 from LSB
extractBits(e, offset, count)  // Extract bit range
insertBits(e, newbits, offset, count) // Insert bit range
//Atomic Functions
atomicLoad(atomic_ptr)
atomicStore(atomic_ptr, value)
atomicAdd(atomic_ptr, value)
atomicSub(atomic_ptr, value)
atomicMax(atomic_ptr, value)
atomicMin(atomic_ptr, value)
atomicAnd(atomic_ptr, value)
atomicOr(atomic_ptr, value)
atomicXor(atomic_ptr, value)
atomicExchange(atomic_ptr, value)
atomicCompareExchangeWeak(atomic_ptr, compare, value)
//Data Packing/Unpacking
pack4x8snorm(v)         // vec4<f32> to u32
pack4x8unorm(v)
pack2x16snorm(v)        // vec2<f32> to u32
pack2x16unorm(v)
pack2x16float(v)

unpack4x8snorm(u)       // u32 to vec4<f32>
unpack4x8unorm(u)
unpack2x16snorm(u)      // u32 to vec2<f32>
unpack2x16unorm(u)
unpack2x16float(u)
//Other Useful Functions
all(v)                  // True if all components true
any(v)                  // True if any component true
select(f, t, cond)      // cond ? t : f (component-wise for vectors)
arrayLength(runtime_array_ptr)  // Length of runtime-sized array

// Derivative functions (NOT available in compute!)
// dpdx, dpdy, fwidth - these are fragment shader only
//Control Flow
//If/Else
if (condition) {
    // code
}

if (condition) {
    // code
} else {
    // code
}

if (condition1) {
    // code
} else if (condition2) {
    // code
} else {
    // code
}
//Switch
switch (value) {
    case 0: {
        // code
    }
    case 1, 2: {  // Multiple cases
        // code
    }
    default: {
        // code
    }
}
//For Loop
for (var i = 0u; i < 10u; i++) {
    // code
    break;     // Exit loop
    continue;  // Next iteration
}
//While Loop
while (condition) {
    // code
    break;
    continue;
}
//Loop (infinite with explicit break)
loop {
    if (condition) {
        break;
    }
    
    // continuing block is executed at the end of each iteration
    continuing {
        // Update code
        break if (exit_condition);  // Can break from continuing block
    }
}
//Array Operations
// Declaration
var arr1: array<f32, 4>;                    // Fixed size
var arr2 = array<f32, 4>(1.0, 2.0, 3.0, 4.0); // With initialization
var arr3: array<vec3<f32>, 2>;              // Array of vectors

// Multi-dimensional
var arr2d: array<array<f32, 3>, 4>;         // 4x3 array

// Access
var element = arr1[0];
arr1[1] = 5.0;

// Runtime-sized (in storage buffer)
struct DynamicBuffer {
    length: u32,
    data: array<f32>  // Must be last member
}

@group(0) @binding(0) var<storage, read> buffer: DynamicBuffer;

// Get length of runtime-sized array
var len = arrayLength(&buffer.data);

// Iteration
for (var i = 0u; i < 4u; i++) {
    arr1[i] = f32(i);
}
// Type Casting
// Scalar casting
let i = i32(3.14);      // f32 to i32
let f = f32(42);        // i32 to f32
let u = u32(-1);        // i32 to u32 (bitcast)
let b = bool(1);        // i32 to bool (non-zero = true)

// Vector casting
let v_f32 = vec3f(1.0, 2.0, 3.0);
let v_i32 = vec3i(v_f32);  // vec3f to vec3i

// Bitcast (reinterpret bits)
let bits = bitcast<u32>(3.14f);
let float_back = bitcast<f32>(bits);
//Pointers & References
fn modify(ptr: ptr<function, f32>) {
    *ptr = 10.0;  // Dereference
}

var value = 5.0;
modify(&value);  // Pass pointer

// Get pointer to array element
var arr = array<f32, 4>(1.0, 2.0, 3.0, 4.0);
let elem_ptr = &arr[2];
//Compute Shader Specifics
//Entry Point
@compute @workgroup_size(8, 8, 1)
fn main(
    @builtin(global_invocation_id) global_id: vec3<u32>,
    @builtin(local_invocation_id) local_id: vec3<u32>,
    @builtin(workgroup_id) workgroup_id: vec3<u32>,
    @builtin(local_invocation_index) local_index: u32,
    @builtin(num_workgroups) num_workgroups: vec3<u32>
) {
    // Compute shader code
}
//Workgroup Barrier
workgroupBarrier();  // Synchronize all invocations in workgroup
storageBarrier();    // Ensure memory writes are visible
//Constants
const PI: f32 = 3.14159265359;
const SIZE: u32 = 256u;

// Override constants (can be set from API)
override BLOCK_SIZE: u32 = 16u;
override THRESHOLD: f32;
//Type Aliases
alias Float = f32;
alias Vec3 = vec3<f32>;
alias MyArray = array<f32, 16>;`;
}
    // Monaco Initialization

    function initMonaco(callback) {
    require(['vs/editor/editor.main'], function() {
        // Register WGSL language
        monaco.languages.register({ id: 'wgsl' });
        monaco.languages.setLanguageConfiguration('wgsl', WGSL_LANGUAGE_CONFIG);
        monaco.languages.setMonarchTokensProvider('wgsl', WGSL_MONARCH_TOKENS);
        
        // Common editor options
        const editorOptions = {
            theme: 'vs-dark',
            fontSize: 13,
            minimap: { enabled: false },
            automaticLayout: true,
            scrollBeyondLastLine: false,
            wordWrap: 'on',
            tabSize: 4,
            insertSpaces: true,
            formatOnPaste: true,
            formatOnType: true,
            suggestOnTriggerCharacters: true,
            acceptSuggestionOnEnter: 'on',
            folding: true,
            foldingStrategy: 'indentation',
            renderWhitespace: 'selection',
            renderControlCharacters: false,
            scrollbar: {
                vertical: 'visible',
                horizontal: 'visible',
                useShadows: false,
                verticalHasArrows: false,
                horizontalHasArrows: false
            }
        };
        
        // Create Boilerplate editor (read-only)
        const boilerplateContainer = document.getElementById('boilerplateContainer');
        boilerplateContainer.innerHTML = '';
        state.boilerplateEditor = monaco.editor.create(boilerplateContainer, {
            ...editorOptions,
            value: getBoilerplate(),
            language: 'wgsl',
            readOnly: true,  // Read-only!
        });
        
        // Create Graphics editor
        const graphicsContainer = document.getElementById('graphicsContainer');
        state.graphicsEditor = monaco.editor.create(graphicsContainer, {
            ...editorOptions,
            value: EXAMPLES[state.currentExample].graphics || '',
            language: 'wgsl',
        });
        
        // Create Audio editor
        const audioContainer = document.getElementById('audioContainer');
        state.audioEditor = monaco.editor.create(audioContainer, {
            ...editorOptions,
            value: EXAMPLES[state.currentExample].audio || MINIMAL_AUDIO,
            language: 'wgsl',
        });
        
        // Create JavaScript editor 
        const jsContainer = document.getElementById('jsEditorContainer');
        state.jsEditor = monaco.editor.create(jsContainer, {
            ...editorOptions,
            value: EXAMPLES[state.currentExample].js || MINIMAL_JS,
            language: 'javascript',
        });
        
        // Create Help editor (read-only)
        const helpContainer = document.getElementById('helpContainer');
        state.helpEditor = monaco.editor.create(helpContainer, {
            ...editorOptions,
            value: getHelpContent(),
            language: 'plaintext',
            readOnly: true,
            wordWrap: 'on',
            lineNumbers: 'off',
        });
        
        // Keyboard shortcuts for all editors
        const addShortcuts = (editor) => {
            editor.addCommand(monaco.KeyCode.F5, () => reloadShader());
            editor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.KeyS, () => reloadShader());
            editor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.Space, () => togglePlayPause());
        };
        addShortcuts(state.boilerplateEditor);
        addShortcuts(state.graphicsEditor);
        addShortcuts(state.audioEditor);
        addShortcuts(state.jsEditor);
        addShortcuts(state.helpEditor);
            
            // Set up error markers when shader compilation fails
            window.setMonacoErrors = function(errors) {
                const markers = errors.map(err => ({
                    severity: monaco.MarkerSeverity.Error,
                    startLineNumber: err.lineNum || 1,
                    startColumn: err.linePos || 1,
                    endLineNumber: err.lineNum || 1,
                    endColumn: 1000,
                    message: err.message
                }));
                // Try to place marker in the relevant editor based on line number
                // For now, clear all and show in graphics (could be smarter later)
                monaco.editor.setModelMarkers(state.graphicsEditor.getModel(), 'wgsl', []);
                monaco.editor.setModelMarkers(state.audioEditor.getModel(), 'wgsl', []);
                monaco.editor.setModelMarkers(state.graphicsEditor.getModel(), 'wgsl', markers);
            };
            
            window.clearMonacoErrors = function() {
                monaco.editor.setModelMarkers(state.graphicsEditor.getModel(), 'wgsl', []);
                monaco.editor.setModelMarkers(state.audioEditor.getModel(), 'wgsl', []);
            };
            
            // JS error markers
            window.setJSErrors = function(errors) {
                const markers = errors.map(err => ({
                    severity: monaco.MarkerSeverity.Error,
                    startLineNumber: err.lineNum || 1,
                    startColumn: err.column || 1,
                    endLineNumber: err.lineNum || 1,
                    endColumn: err.endColumn || 1000,
                    message: err.message
                }));
                monaco.editor.setModelMarkers(state.jsEditor.getModel(), 'javascript', markers);
            };
            
            window.clearJSErrors = function() {
                monaco.editor.setModelMarkers(state.jsEditor.getModel(), 'javascript', []);
            };
            
            callback();
        });
    }
// ============================================================================
// TAB MANAGEMENT
// ============================================================================

function getTabIcon(tabName) {
    const icons = {
        boilerplate: '📄',
        graphics: '🎨',
        audio: '🔊',
        js: '⚡',
        help: '❓'
    };
    return icons[tabName] || '📝';
}

function getTabLabel(tabName) {
    const labels = {
        boilerplate: 'Boilerplate',
        graphics: 'Graphics',
        audio: 'Audio',
        js: 'JavaScript',
        help: 'Help'
    };
    return labels[tabName] || tabName;
}

function renderTabs() {
    const tabsContainer = document.getElementById('editorTabs');
    
    // Remove all tab buttons but keep the "+ Add Pass" button
    const addPassBtn = document.getElementById('addPassBtn');
    tabsContainer.innerHTML = '';
    
    // Add tab buttons
    state.activeTabs.forEach(tabName => {
        const button = document.createElement('button');
        button.className = 'editorTab' + (state.currentTab === tabName ? ' active' : '');
        button.textContent = `${getTabIcon(tabName)} ${getTabLabel(tabName)}`;
        button.onclick = () => switchTab(tabName);
        
        // Add close button for removable tabs (only graphics is mandatory)
        if (tabName !== 'graphics') {
            const closeBtn = document.createElement('span');
            closeBtn.textContent = ' ×';
            closeBtn.style.marginLeft = '6px';
            closeBtn.style.cursor = 'pointer';
            closeBtn.onclick = (e) => {
                e.stopPropagation();
                removeTab(tabName);
            };
            button.appendChild(closeBtn);
        }
        
        tabsContainer.appendChild(button);
    });
    
    // Re-add the "+ Add Pass" button at the end
    if (addPassBtn) {
        tabsContainer.appendChild(addPassBtn);
    }
}

function switchTab(tabName) {
    if (!state.activeTabs.includes(tabName)) {
        return;
    }
    
    state.currentTab = tabName;
    
    const containers = {
        boilerplate: document.getElementById('boilerplateContainer'),
        graphics: document.getElementById('graphicsContainer'),
        audio: document.getElementById('audioContainer'),
        js: document.getElementById('jsEditorContainer'),
        help: document.getElementById('helpContainer')
    };
    
    const editors = {
        boilerplate: state.boilerplateEditor,
        graphics: state.graphicsEditor,
        audio: state.audioEditor,
        js: state.jsEditor,
        help: state.helpEditor
    };
    
    // Hide all containers
    Object.values(containers).forEach(c => c.style.display = 'none');
    
    // Show selected container
    if (containers[tabName]) {
        containers[tabName].style.display = 'block';
    }
    
    // Force layout update
    if (editors[tabName]) {
        editors[tabName].layout();
    }
    
    // Update tab buttons
    renderTabs();
}

function addTab(tabName) {
    if (state.activeTabs.includes(tabName)) {
        switchTab(tabName);
        return;
    }
    
    state.activeTabs.push(tabName);
    
    // If adding a tab that the current example doesn't have, populate with minimal starter code
    const currentExample = EXAMPLES[state.currentExample];
    
    if (tabName === 'js' && !currentExample.js && state.jsEditor) {
        state.jsEditor.setValue(MINIMAL_JS);
    } else if (tabName === 'audio' && !currentExample.audio && state.audioEditor) {
        state.audioEditor.setValue(MINIMAL_AUDIO);
    }
    
    renderTabs();
    switchTab(tabName);
    
    // If we just added audio or js, reload the shader/script
    if ((tabName === 'audio' || tabName === 'js') && state.isRunning) {
        reloadShader();
    }
}

function removeTab(tabName) {
    // Can't remove graphics (it's mandatory)
    if (tabName === 'graphics') {
        return;
    }
    
    const index = state.activeTabs.indexOf(tabName);
    if (index === -1) return;
    
    state.activeTabs.splice(index, 1);
    
    // If we removed the current tab, switch to another
    if (state.currentTab === tabName) {
        switchTab(state.activeTabs[Math.max(0, index - 1)]);
    }
    
    renderTabs();
}

function showAddPassMenu() {
    const btn = document.getElementById('addPassBtn');
    
    // Create menu if it doesn't exist
    let menu = document.getElementById('addPassMenu');
    if (!menu) {
        menu = document.createElement('div');
        menu.id = 'addPassMenu';
        menu.style.cssText = `
            position: absolute;
            background: #2d2d2d;
            border: 1px solid #3c3c3c;
            padding: 4px;
            z-index: 1000;
            display: none;
        `;
        document.body.appendChild(menu);
    }
    
    // Build menu options - all available tabs except graphics (always present)
    const availableTabs = [
        { name: 'boilerplate', label: '📄 Boilerplate' },
        { name: 'audio', label: '🔊 Audio' },
        { name: 'js', label: '⚡ JavaScript' },
        { name: 'help', label: '❓ Help' }
    ];
    
    menu.innerHTML = '';
    availableTabs.forEach(tab => {
        const isActive = state.activeTabs.includes(tab.name);
        const option = document.createElement('div');
        option.textContent = tab.label + (isActive ? ' ✓' : '');
        option.style.cssText = `
            padding: 6px 12px;
            cursor: ${isActive ? 'default' : 'pointer'};
            color: ${isActive ? '#666' : '#d4d4d4'};
            pointer-events: ${isActive ? 'none' : 'auto'};
        `;
        option.onmouseenter = () => {
            if (!isActive) {
                option.style.background = '#1e1e1e';
            }
        };
        option.onmouseleave = () => {
            option.style.background = 'transparent';
        };
        option.onclick = () => {
            addTab(tab.name);
            menu.style.display = 'none';
        };
        menu.appendChild(option);
    });
    
    // Position menu below button
    const rect = btn.getBoundingClientRect();
    menu.style.left = rect.left + 'px';
    menu.style.top = (rect.bottom + 2) + 'px';
    menu.style.display = 'block';
    
    // Close menu when clicking outside
    const closeMenu = (e) => {
        if (!menu.contains(e.target) && e.target !== btn) {
            menu.style.display = 'none';
            document.removeEventListener('click', closeMenu);
        }
    };
    setTimeout(() => document.addEventListener('click', closeMenu), 0);
}
// ============================================================================
// EXAMPLE MANAGEMENT
// ============================================================================

function populateExampleSelector() {
    const selector = document.getElementById('exampleSelector');
    selector.innerHTML = '';
    
    Object.keys(EXAMPLES).forEach(exampleId => {
        const example = EXAMPLES[exampleId];
        const option = document.createElement('option');
        option.value = exampleId;
        option.textContent = example.name;
        option.title = example.description;
        selector.appendChild(option);
    });
    
    selector.value = state.currentExample;
    selector.addEventListener('change', (e) => {
        loadExample(e.target.value);
    });
}

function loadExample(exampleId) {
    const example = EXAMPLES[exampleId];
    if (!example) return;
    
    state.currentExample = exampleId;
    
    // Update active tabs to match example
    state.activeTabs = [...example.tabs];
    
    // Load code into editors (or set to minimal if example doesn't have it)
    if (state.graphicsEditor) {
        state.graphicsEditor.setValue(example.graphics || '');
    }
    if (state.audioEditor) {
        state.audioEditor.setValue(example.audio || MINIMAL_AUDIO);
    }
    if (state.jsEditor) {
        state.jsEditor.setValue(example.js || MINIMAL_JS);
    }
    
    // Update UI
    renderTabs();
    
    // Switch to graphics tab by default
    if (state.activeTabs.includes('graphics')) {
        switchTab('graphics');
    } else if (state.activeTabs.length > 0) {
        switchTab(state.activeTabs[0]);
    }
    
    // Reload shader with new code, then restart and auto-play
    if (state.isRunning) {
        reloadShader().then(() => {
            // Restart from beginning and ensure playing
            restart();
            if (!state.isPlaying) {
                state.isPlaying = true;
                state.audioContext.resume();
                updatePlayPauseButton();
            }
            logStatus(`Loaded example: ${example.name}`, 'success');
        });
    } else {
        logStatus(`Loaded example: ${example.name}`, 'success');
    }
}

function parseJSError(err, codeLines) {
    // Extract line number from error message or stack
    let lineNum = 1;
    let column = 1;
    let endColumn = 1000; // Default to end of line
    
    // Try to parse from stack trace
    const stackMatch = err.stack?.match(/<anonymous>:(\d+):(\d+)/);
    if (stackMatch) {
        // Line numbers from Function() wrapper need adjustment
        // Testing showed we need to subtract 3 to get correct line
        lineNum = Math.max(1, parseInt(stackMatch[1]) - 3);
        column = parseInt(stackMatch[2]) || 1;
        
        // Try to determine end column by looking at the error type
        // For syntax errors, highlight a reasonable amount
        if (err instanceof SyntaxError) {
            endColumn = column + 10; // Highlight ~10 chars for syntax errors
        } else {
            // For runtime errors, try to highlight the problematic token
            endColumn = column + 20; // Highlight more for runtime errors
        }
    } else {
        // Try parsing from error message (some syntax errors include line info)
        const msgMatch = err.message?.match(/line (\d+)/i);
        if (msgMatch) {
            lineNum = parseInt(msgMatch[1]);
        }
    }
    
    // Clamp to valid range
    lineNum = Math.min(lineNum, codeLines);
    
    return { lineNum, column, endColumn, message: err.message };
}

// Default JS that runs when JS tab is not visible
const INVISIBLE_DEFAULT_JS = `
function init() {
    return { mouseX: 0.5, mouseY: 0.5 };
}

function enterframe(state, api) {
    // Smooth mouse tracking
    state.mouseX += (api.mouse.x - state.mouseX) * 0.1;
    state.mouseY += (api.mouse.y - state.mouseY) * 0.1;
    
    // Pass to uniforms
    api.uniforms.setFloat(5, state.mouseX);
    api.uniforms.setFloat(6, state.mouseY);
}
`;

function compileUserJS() {
    // If JS tab is not active, use invisible default
    const useDefault = !state.activeTabs.includes('js');
    const code = useDefault ? INVISIBLE_DEFAULT_JS : state.jsEditor.getValue();
    const codeLines = code.split('\n').length;
    
    try {
        if (!useDefault) clearJSErrors();
        
        // Create a safe scope and eval the user's code
        // We add one newline before user code to make line numbers match
        const wrappedCode = `
${code}
return { init, enterframe };
`;
        const factory = new Function(wrappedCode);
        const userFunctions = factory();
        
        state.userInit = userFunctions.init;
        state.userEnterframe = userFunctions.enterframe;
        
        if (!useDefault) {
            logStatus('✓ JavaScript compiled successfully', 'success');
        }
        return true;
    } catch (err) {
        if (useDefault) {
            // Default JS should never fail, but if it does, log and continue
            console.error('Default JS compilation failed:', err);
            return false;
        }
        
        const errorInfo = parseJSError(err, codeLines);
        
        setJSErrors([{
            lineNum: errorInfo.lineNum,
            column: errorInfo.column,
            endColumn: errorInfo.endColumn,
            message: errorInfo.message
        }]);
        
        logStatus(`✗ JS Error (line ${errorInfo.lineNum}): ${errorInfo.message}`, 'error');
        return false;
    }
}
    // Global error handler to catch uncaught errors from user code
    function setupErrorHandling() {
        // Store original handlers
        const originalErrorHandler = window.onerror;
        const originalConsoleError = console.error;
        const originalConsoleWarn = console.warn;
        
        // Intercept console.error to detect user code issues
        console.error = function(...args) {
            // Check if called from user code
            const stack = new Error().stack;
            if (stack && stack.includes('<anonymous>') && state.jsEditor) {
                logStatus(`⚠ Console error from user code: ${args[0]}`, 'error');
            }
            // Always call original console.error
            originalConsoleError.apply(console, args);
        };
        
        console.warn = function(...args) {
            const stack = new Error().stack;
            if (stack && stack.includes('<anonymous>') && state.jsEditor) {
                logStatus(`⚠ Console warning from user code: ${args[0]}`, 'info');
            }
            originalConsoleWarn.apply(console, args);
        };
        
        // Global error handler
        window.onerror = function(message, source, lineno, colno, error) {
            // Check if this is from user code (anonymous function)
            if (error && error.stack && error.stack.includes('<anonymous>')) {
                const code = state.jsEditor?.getValue();
                if (code) {
                    const codeLines = code.split('\n').length;
                    const errorInfo = parseJSError(error, codeLines);
                    
                    setJSErrors([{
                        lineNum: errorInfo.lineNum,
                        column: errorInfo.column,
                        endColumn: errorInfo.endColumn,
                        message: `Uncaught error: ${errorInfo.message}`
                    }]);
                    
                    logStatus(`✗ Uncaught JS error (line ${errorInfo.lineNum}): ${error.message}`, 'error');
                    
                    // Pause if playing
                    if (state.isPlaying) {
                        state.isPlaying = false;
                        state.audioContext?.suspend();
                        
                        const btn = document.getElementById('playPauseBtn');
                        if (btn) {
                            btn.textContent = '▶';
                            btn.className = 'paused';
                        }
                    }
                    
                    return true; // Prevent default error handling
                }
            }
            
            // Let editor errors through to console
            if (originalErrorHandler) {
                return originalErrorHandler(message, source, lineno, colno, error);
            }
            return false;
        };
    }

    // Initialization
    async function init() {
        setupErrorHandling();
        setupUI();
        
        // Initialize audio FIRST to get actual sample rate
        initWebAudio();
        
        // Then initialize Monaco with correct shader values
        initMonaco(async () => {
            try {
                await initWebGPU();
                await reloadShader();
                state.isRunning = true;
                
                // Auto-play from beginning
                restart();
                state.isPlaying = true;
                state.audioContext.resume();
                updatePlayPauseButton();
                
                requestAnimationFrame(render);
                logStatus('Ready! Animation playing.', 'success');
            } catch (err) {
                logStatus('Initialization failed: ' + err.message, 'error');
            }
        });
    }

    function setupUI() {
        // Canvas
        state.canvas = document.getElementById('canvas');
        state.canvas.width = CONFIG.screenSize;
        state.canvas.height = CONFIG.screenSize;
        state.canvas.style.width = CONFIG.screenSize + 'px';
        state.canvas.style.height = CONFIG.screenSize + 'px';

        // Play/Pause button
        document.getElementById('playPauseBtn').addEventListener('click', togglePlayPause);
        
        // Restart button
        document.getElementById('restartBtn').addEventListener('click', restart);

        // Reload button
        document.getElementById('reloadBtn').addEventListener('click', reloadShader);
        
        // Add Pass button
        document.getElementById('addPassBtn').addEventListener('click', showAddPassMenu);

        // Volume control
        const volumeSlider = document.getElementById('volumeSlider');
        const volumeValue = document.getElementById('volumeValue');
        volumeSlider.addEventListener('input', (e) => {
            const vol = e.target.value / 100;
            CONFIG.volume = vol;
            if (state.gainNode) state.gainNode.gain.value = vol;
            volumeValue.textContent = e.target.value + '%';
        });
        
        // Track mouse position
        document.addEventListener('mousemove', (e) => {
            const rect = state.canvas.getBoundingClientRect();
            state.mouseX = (e.clientX - rect.left) / rect.width;
            state.mouseY = 1.0 - (e.clientY - rect.top) / rect.height; // Flip Y
        });
        
        // Handle visibility change
        document.addEventListener('visibilitychange', () => {
            if (!document.hidden && state.audioContext && state.isPlaying) {
                const ctx = state.audioContext;
                state.nextAudioTime = Math.ceil(ctx.currentTime / CONFIG.audioBlockDuration) 
                                     * CONFIG.audioBlockDuration;
                state.pendingAudio = false;
                logStatus('Audio resynced after visibility change', 'info');
            }
        });
        
        // Initialize example selector
        populateExampleSelector();
        
        // Initialize tab display
        renderTabs();
    }

function togglePlayPause() {
    if (!state.audioContext || !state.isRunning) return;
    
    if (state.isPlaying) {
        // PAUSE everything
        state.audioContext.suspend();
        state.isPlaying = false;
        state.lastPauseTime = performance.now();
        logStatus('Paused', 'info');
    } else {
        // RESUME everything
        state.audioContext.resume();
        state.isPlaying = true;
        
        // Account for time spent paused
        if (state.lastPauseTime > 0) {
            state.pausedTime += performance.now() - state.lastPauseTime;
        }
        
        // Resync audio timing
        const ctx = state.audioContext;
        state.nextAudioTime = Math.ceil(ctx.currentTime / CONFIG.audioBlockDuration) 
                             * CONFIG.audioBlockDuration;
        state.pendingAudio = false;
        
        logStatus('Playing', 'success');
    }
    
    updatePlayPauseButton();
}

function updatePlayPauseButton() {
    const btn = document.getElementById('playPauseBtn');
    if (state.isPlaying) {
        btn.textContent = '⏸';
        btn.className = 'playing';
    } else {
        btn.textContent = '▶';
        btn.className = 'paused';
    }
}

function restart() {
    // Reset time tracking
    const now = performance.now();
    state.startTime = now;
    state.pausedTime = 0;
    state.visualFrame = 0;
    state.audioFrame = 0;
    
    // If currently paused, set lastPauseTime to now so time doesn't accumulate while paused
    if (!state.isPlaying) {
        state.lastPauseTime = now;
    } else {
        state.lastPauseTime = 0;
    }
    
    // Reset GPU phase for clean audio start
    if (state.gpuDevice && state.phaseStateBuffer) {
        state.gpuDevice.queue.writeBuffer(state.phaseStateBuffer, 0, new Float32Array([0.0]));
    }
    
    // Resync audio timing
    if (state.audioContext) {
        const ctx = state.audioContext;
        state.nextAudioTime = Math.ceil(ctx.currentTime / CONFIG.audioBlockDuration) 
                             * CONFIG.audioBlockDuration;
        state.pendingAudio = false;
    }
    
    // Compile and initialize JS
    if (compileUserJS()) {
        try {
            state.userState = state.userInit ? state.userInit() : {};
            clearJSErrors();
            logStatus('Restarted from beginning', 'success');
        } catch (err) {
            const code = state.jsEditor?.getValue() || INVISIBLE_DEFAULT_JS;
            const codeLines = code.split('\n').length;
            const errorInfo = parseJSError(err, codeLines);
            
            if (state.jsEditor && state.activeTabs.includes('js')) {
                setJSErrors([{
                    lineNum: errorInfo.lineNum,
                    column: errorInfo.column,
                    endColumn: errorInfo.endColumn,
                    message: `Runtime error in init(): ${errorInfo.message}`
                }]);
            }
            
            logStatus(`✗ JS init() error (line ${errorInfo.lineNum}): ${err.message}`, 'error');
        }
    }
    
    // Update display immediately to show t=0
    document.getElementById('frameCounter').textContent = '0';
    document.getElementById('timeCounter').textContent = '0.00s';
    
    // If paused, render one frame to show the restart visually
    if (!state.isPlaying && state.isRunning) {
        renderSingleFrame();
    }
}

    async function initWebGPU() {
        const adapter = await navigator.gpu?.requestAdapter();
        if (!adapter) throw new Error('WebGPU not supported');

        state.gpuDevice = await adapter.requestDevice({
            requiredFeatures: ['bgra8unorm-storage'],
            requiredLimits: {
                maxBufferSize: Math.pow(2, 30),
                maxStorageBufferBindingSize: Math.pow(2, 30),
            }
        });

        state.gpuContext = state.canvas.getContext('webgpu');
        state.gpuContext.configure({
            device: state.gpuDevice,
            format: navigator.gpu.getPreferredCanvasFormat(),
            usage: GPUTextureUsage.STORAGE_BINDING,
        });

        createGPUResources();
    }

    function createGPUResources() {
        const device = state.gpuDevice;

        state.uniformBuffer = device.createBuffer({
            size: 256,
            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
        });

        state.computeBuffer = device.createBuffer({
            size: CONFIG.computeBufferSize,
            usage: GPUBufferUsage.STORAGE,
        });

        state.audioBufferGPU = device.createBuffer({
            size: DERIVED.audioBufferSize,
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
        });
        
        // Phase state buffer - persistent GPU-side phase for perfect timing
        state.phaseStateBuffer = device.createBuffer({
            size: 4,  // Single f32
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
        });
        
        // Initialize phase to 0
        device.queue.writeBuffer(state.phaseStateBuffer, 0, new Float32Array([0.0]));

        for (let i = 0; i < 2; i++) {
            state.audioBuffersReadback[i] = device.createBuffer({
                size: DERIVED.audioBufferSize,
                usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
            });
        }

        state.bindGroupLayout = device.createBindGroupLayout({
            entries: [
                { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'uniform' } },
                { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
                { binding: 2, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
                { binding: 3, visibility: GPUShaderStage.COMPUTE, storageTexture: { 
                    format: 'bgra8unorm', access: 'write-only', viewDimension: '2d' 
                }},
                { binding: 4, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
            ],
        });
    }

    function initWebAudio() {
        state.audioContext = new AudioContext();
        
        // Read actual sample rate from AudioContext
        DERIVED.sampleRate = state.audioContext.sampleRate;
        DERIVED.samplesPerBlock = Math.floor(CONFIG.audioBlockDuration * DERIVED.sampleRate);
        DERIVED.audioBufferSize = 4 * CONFIG.channels * DERIVED.samplesPerBlock;
        DERIVED.audioWorkgroups = Math.ceil(DERIVED.samplesPerBlock / 128);  // 128 threads per workgroup for audio
        
        console.log(`Audio initialized: ${DERIVED.sampleRate}Hz, ${DERIVED.samplesPerBlock} samples/block`);
        console.log(`Dispatch: Graphics 64×64 workgroups (8×8 threads), Audio ${DERIVED.audioWorkgroups}×1 workgroups (128 threads)`);
        
        state.gainNode = state.audioContext.createGain();
        state.gainNode.gain.value = CONFIG.volume;
        state.gainNode.connect(state.audioContext.destination);
        
        state.nextAudioTime = Math.ceil(state.audioContext.currentTime / CONFIG.audioBlockDuration) 
                             * CONFIG.audioBlockDuration;
        
        state.audioContext.suspend();
    }

    // Live Shader Reload - no time reset, no init() call
    async function reloadShader() {
    // Compose full shader from boilerplate + graphics + audio (if available)
    const boilerplate = getBoilerplate();  // Auto-generated
    const graphics = state.graphicsEditor.getValue();
    const hasAudio = state.activeTabs.includes('audio');
    const audio = hasAudio ? state.audioEditor.getValue() : '';
    const code = boilerplate + '\n' + graphics + '\n' + audio;
    
    // Update boilerplate editor to show latest auto-generated values
    state.boilerplateEditor.setValue(boilerplate);
    
    try {
        logStatus('Compiling...', 'info');
        clearMonacoErrors();
        
        const shaderModule = state.gpuDevice.createShaderModule({ code });
        
        const compilationInfo = await shaderModule.getCompilationInfo();
        const errors = compilationInfo.messages.filter(m => m.type === 'error');
        
        if (errors.length > 0) {
            setMonacoErrors(errors);
            const errorMsg = errors.map(e => 
                `Line ${e.lineNum}: ${e.message}`
            ).join('\n');
            throw new Error('Shader compilation failed:\n' + errorMsg);
        }
        
        const pipelineLayout = state.gpuDevice.createPipelineLayout({
            bindGroupLayouts: [state.bindGroupLayout],
        });
        
        // Create graphics pipeline (8×8 workgroups for 2D)
        const newGraphicsPipeline = state.gpuDevice.createComputePipeline({
            layout: pipelineLayout,
            compute: { module: shaderModule, entryPoint: 'graphics_main' },
        });
        
        state.graphicsPipeline = newGraphicsPipeline;
        
        // Create audio pipeline only if audio tab is active
        if (hasAudio) {
            const newAudioPipeline = state.gpuDevice.createComputePipeline({
                layout: pipelineLayout,
                compute: { module: shaderModule, entryPoint: 'audio_main' },
            });
            state.audioPipeline = newAudioPipeline;
        } else {
            state.audioPipeline = null;
        }
        
        // Also compile JS (but don't call init - that's restart's job)
        if (compileUserJS()) {
            logStatus('✓ Compiled successfully!', 'success');
        } else {
            logStatus('✓ Shader compiled, but JS has errors', 'error');
        }
        
    } catch (err) {
        logStatus('✗ ' + err.message, 'error');
    }
}

    function logStatus(message, type = 'info') {
        const display = document.getElementById('errorDisplay');
        display.textContent = message;
        display.className = type;
    }

    // Render a single frame (used when paused, e.g., after restart)
    function renderSingleFrame() {
        if (!state.isRunning || !state.gpuDevice) return;
        
        const device = state.gpuDevice;
        const ctx = state.audioContext;
        
        // Use t=0 for uniforms
        const uniformData = new ArrayBuffer(256);
        const uniformF32 = new Float32Array(uniformData);
        const uniformI32 = new Int32Array(uniformData);
        
        uniformF32[UNIFORM_STRUCT.time] = 0;
        uniformF32[UNIFORM_STRUCT.audioCurrentTime] = ctx.currentTime;
        uniformF32[UNIFORM_STRUCT.audioPlayTime] = state.nextAudioTime;
        uniformF32[UNIFORM_STRUCT.audioFractTime] = 0;
        uniformI32[UNIFORM_STRUCT.audioFrame] = 0;
        
        // Call enterframe at t=0 to set uniforms
        if (state.userEnterframe) {
            try {
                const api = {
                    time: 0,
                    deltaTime: 0,
                    mouse: { x: state.mouseX, y: state.mouseY },
                    sampleRate: DERIVED.sampleRate,
                    samplesPerBlock: DERIVED.samplesPerBlock,
                    audioFrame: 0,
                    audioBlockGenerated: false,
                    uniforms: {
                        setFloat: (index, value) => {
                            if (index >= 5 && index < 20) {
                                uniformF32[index] = value;
                            }
                        },
                        setInt: (index, value) => {
                            if (index >= 5 && index < 20) {
                                uniformI32[index] = value;
                            }
                        }
                    }
                };
                state.userEnterframe(state.userState, api);
            } catch (err) {
                // Silently fail for single frame render
                console.warn('enterframe error during single frame render:', err);
            }
        }
        
        device.queue.writeBuffer(state.uniformBuffer, 0, uniformData);
        
        const textureView = state.gpuContext.getCurrentTexture().createView();
        const bindGroup = device.createBindGroup({
            layout: state.bindGroupLayout,
            entries: [
                { binding: 0, resource: { buffer: state.uniformBuffer } },
                { binding: 1, resource: { buffer: state.computeBuffer } },
                { binding: 2, resource: { buffer: state.audioBufferGPU } },
                { binding: 3, resource: textureView },
                { binding: 4, resource: { buffer: state.phaseStateBuffer } },
            ],
        });
        
        const encoder = device.createCommandEncoder();
        const pass = encoder.beginComputePass();
        
        // Only render graphics (no audio)
        pass.setPipeline(state.graphicsPipeline);
        pass.setBindGroup(0, bindGroup);
        pass.dispatchWorkgroups(
            CONFIG.screenSize / 8,
            CONFIG.screenSize / 8,
            1
        );
        
        pass.end();
        device.queue.submit([encoder.finish()]);
    }

    // Render Loop
    function render(rawTime) {
        if (!state.isRunning) return;
        
        // Only render when playing
        if (!state.isPlaying) {
            requestAnimationFrame(render);
            return;
        }

        const device = state.gpuDevice;
        const ctx = state.audioContext;
        
        // Calculate elapsed time (accounting for pauses)
        const elapsedMs = rawTime - state.startTime - state.pausedTime;
        const elapsedSec = elapsedMs * 0.001;
        
        // Increment visual frame counter
        state.visualFrame++;
        
        document.getElementById('frameCounter').textContent = state.visualFrame;
        document.getElementById('timeCounter').textContent = elapsedSec.toFixed(2) + 's';

        const uniformData = new ArrayBuffer(256);
        const uniformF32 = new Float32Array(uniformData);
        const uniformI32 = new Int32Array(uniformData);
        
        uniformF32[UNIFORM_STRUCT.time] = elapsedSec;
        uniformF32[UNIFORM_STRUCT.audioCurrentTime] = ctx.currentTime;
        uniformF32[UNIFORM_STRUCT.audioPlayTime] = state.nextAudioTime;
        uniformF32[UNIFORM_STRUCT.audioFractTime] = state.nextAudioTime % 1;
        uniformI32[UNIFORM_STRUCT.audioFrame] = state.audioFrame;
        
    // Call user's enterframe with API
    if (state.isPlaying && state.userEnterframe) {
        try {
            const api = {
                time: elapsedSec,
                deltaTime: 0.016, // Could calculate real delta
                mouse: { x: state.mouseX, y: state.mouseY },
                sampleRate: DERIVED.sampleRate,
                samplesPerBlock: DERIVED.samplesPerBlock,
                audioFrame: state.audioFrame,
                audioBlockGenerated: false,  // Will be set to true if audio was generated this frame
                uniforms: {
                    setFloat: (index, value) => {
                        if (index >= 5 && index < 20) {
                            uniformF32[index] = value;
                        }
                    },
                    setInt: (index, value) => {
                        if (index >= 5 && index < 20) {
                            uniformI32[index] = value;
                        }
                    }
                }
            };
            state.userEnterframe(state.userState, api);
        } catch (err) {
            // Pause playback on runtime error
            state.isPlaying = false;
            state.audioContext.suspend();
            updatePlayPauseButton();
            
            // Show error with line number (only if JS tab is visible)
            if (state.activeTabs.includes('js')) {
                const code = state.jsEditor.getValue();
                const codeLines = code.split('\n').length;
                const errorInfo = parseJSError(err, codeLines);
                
                setJSErrors([{
                    lineNum: errorInfo.lineNum,
                    column: errorInfo.column,
                    endColumn: errorInfo.endColumn,
                    message: `Runtime error in enterframe(): ${errorInfo.message}`
                }]);
                
                logStatus(`✗ JS enterframe() error (line ${errorInfo.lineNum}): ${err.message}`, 'error');
            } else {
                logStatus(`✗ JS runtime error: ${err.message}`, 'error');
            }
            console.error('enterframe error:', err);
        }
    }
    
    device.queue.writeBuffer(state.uniformBuffer, 0, uniformData);

        const textureView = state.gpuContext.getCurrentTexture().createView();
        const bindGroup = device.createBindGroup({
            layout: state.bindGroupLayout,
            entries: [
                { binding: 0, resource: { buffer: state.uniformBuffer } },
                { binding: 1, resource: { buffer: state.computeBuffer } },
                { binding: 2, resource: { buffer: state.audioBufferGPU } },
                { binding: 3, resource: textureView },
                { binding: 4, resource: { buffer: state.phaseStateBuffer } },
            ],
        });

        // Check if we need to generate audio THIS frame
        const needsAudio = state.isPlaying && 
                          state.audioPipeline &&
                          ctx.currentTime >= state.nextAudioTime - CONFIG.audioBlockDuration && 
                          !state.pendingAudio;

        const encoder = device.createCommandEncoder();
        const pass = encoder.beginComputePass();
        
        // AUDIO PASS FIRST - Only when we actually need a new block and have audio pipeline!
        if (needsAudio) {
            pass.setPipeline(state.audioPipeline);
            pass.setBindGroup(0, bindGroup);
            pass.dispatchWorkgroups(
                Math.ceil(DERIVED.samplesPerBlock / 128),  // e.g., ceil(4800/128) = 38 workgroups
                1,
                1
            );
        }
        
        // GRAPHICS PASS SECOND - Reads audio data from buffer
        // 8×8 workgroups for optimal 2D texture access
        pass.setPipeline(state.graphicsPipeline);
        pass.setBindGroup(0, bindGroup);
        pass.dispatchWorkgroups(
            CONFIG.screenSize / 8,  // 512/8 = 64 workgroups X
            CONFIG.screenSize / 8,  // 512/8 = 64 workgroups Y
            1
        );
        
        pass.end();

        if (needsAudio) {
            state.pendingAudio = true;
            
            const readbackBuffer = state.audioBuffersReadback[state.readbackIndex];
            encoder.copyBufferToBuffer(
                state.audioBufferGPU, 0,
                readbackBuffer, 0,
                DERIVED.audioBufferSize
            );
            
            device.queue.submit([encoder.finish()]);
            
            readbackBuffer.mapAsync(GPUMapMode.READ).then(() => {
                playAudioBlock(readbackBuffer);
                state.readbackIndex = 1 - state.readbackIndex;
                state.pendingAudio = false;
            }).catch(err => {
                console.error('Audio readback failed:', err);
                state.pendingAudio = false;
            });
        } else {
            device.queue.submit([encoder.finish()]);
        }

        requestAnimationFrame(render);
    }

    function playAudioBlock(readbackBuffer) {
        const ctx = state.audioContext;
        const audioData = new Float32Array(readbackBuffer.getMappedRange());
        
        const audioBuffer = ctx.createBuffer(
            CONFIG.channels,
            DERIVED.samplesPerBlock,
            DERIVED.sampleRate
        );
        
        for (let ch = 0; ch < CONFIG.channels; ch++) {
            const channelData = audioBuffer.getChannelData(ch);
            const offset = ch * DERIVED.samplesPerBlock;
            for (let i = 0; i < DERIVED.samplesPerBlock; i++) {
                channelData[i] = audioData[offset + i];
            }
        }
        
        readbackBuffer.unmap();
        
        const source = ctx.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(state.gainNode);
        source.start(state.nextAudioTime);
        
        state.nextAudioTime += CONFIG.audioBlockDuration;
        state.audioFrame++;
    }

    // ============================================================================
    // Start
    // ============================================================================
    window.addEventListener('load', init);
    </script>
</body>
</html>