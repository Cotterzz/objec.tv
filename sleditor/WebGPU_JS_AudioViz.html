<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <title>WGSL Editor with Monaco</title>
    <style>
        body {
            margin: 0;
            padding: 10px;
            background: #1e1e1e;
            color: #d4d4d4;
            font-family: system-ui, -apple-system, sans-serif;
            overflow: hidden;
        }
        #editorTabs {
    display: flex;
    gap: 5px;
    margin-bottom: 5px;
}
.editorTab {
    background: #2d2d2d;
    color: #858585;
    border: none;
    padding: 6px 12px;
    cursor: pointer;
    font-size: 13px;
}
.editorTab.active {
    background: #1e1e1e;
    color: #d4d4d4;
}
#jsEditorContainer {
    display: none;
}
        #container {
            display: flex;
            gap: 10px;
            height: 98vh;
        }
        #leftPanel {
            flex: 1;
            display: flex;
            flex-direction: column;
            gap: 10px;
            min-width: 400px;
        }
        #rightPanel {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        #editorContainer {
            flex: 1;
            border: 1px solid #3c3c3c;
            overflow: hidden;
            position: relative;
        }
        #loadingMessage {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #858585;
            font-size: 14px;
        }
        #controls {
            display: flex;
            gap: 10px;
            align-items: center;
            flex-wrap: wrap;
        }
        button {
            background: #0e639c;
            color: white;
            border: none;
            padding: 8px 16px;
            cursor: pointer;
            font-size: 14px;
            font-weight: 500;
            transition: background 0.2s;
        }
        button:hover {
            background: #1177bb;
        }
        button.playing {
            background: #16825d;
        }
        button.playing:hover {
            background: #1a9870;
        }
        button.paused {
            background: #c5a332;
        }
        button.paused:hover {
            background: #d4b547;
        }
        #errorDisplay {
            background: #1e1e1e;
            border: 1px solid #3c3c3c;
            padding: 10px;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 12px;
            min-height: 60px;
            max-height: 120px;
            overflow-y: auto;
        }
        .error { color: #f48771; }
        .success { color: #4ec9b0; }
        .info { color: #9cdcfe; }
        #canvas {
            border: 1px solid #3c3c3c;
            image-rendering: pixelated;
        }
        .hint {
            color: #858585;
            font-size: 12px;
        }
        .statusBadge {
            display: inline-block;
            padding: 2px 8px;
            font-size: 11px;
            font-weight: bold;
        }
        .statusBadge.playing {
            background: #16825d;
            color: white;
        }
        .statusBadge.paused {
            background: #c5a332;
            color: white;
        }
    </style>
</head>
<body>
    <div id="container">
        <div id="leftPanel">
<div id="editorTabs">
    <button class="editorTab active" onclick="switchTab('boilerplate')">üìÑ Boilerplate</button>
    <button class="editorTab" onclick="switchTab('graphics')">üé® Graphics</button>
    <button class="editorTab" onclick="switchTab('audio')">üîä Audio</button>
    <button class="editorTab" onclick="switchTab('js')">‚ö° JavaScript</button>
</div>
<div id="boilerplateContainer" style="flex: 1; border: 1px solid #3c3c3c; overflow: hidden;">
    <div id="loadingMessage">Loading Monaco Editor...</div>
</div>
<div id="graphicsContainer" style="flex: 1; border: 1px solid #3c3c3c; overflow: hidden; display: none;">
</div>
<div id="audioContainer" style="flex: 1; border: 1px solid #3c3c3c; overflow: hidden; display: none;">
</div>
<div id="jsEditorContainer" style="flex: 1; border: 1px solid #3c3c3c; overflow: hidden; display: none;">
</div>
            <div>
                <div class="hint">Status:</div>
                <div id="errorDisplay" class="info">Loading editor...</div>
            </div>
        </div>
        <div id="rightPanel">
            <canvas id="canvas"></canvas>
            <div id="controls">
                <button id="playPauseBtn" class="paused">‚ñ∂</button>
                <button id="reloadBtn">‚ü≥</button>
                <label style="color: #858585;">
                    Volume: <input type="range" id="volumeSlider" min="0" max="100" value="50" style="width: 100px;">
                    <span id="volumeValue">50%</span>
                </label>
            </div>
            <div class="hint">
                Frame: <span id="frameCounter">0</span><br>
                Time: <span id="timeCounter">0.00s</span>
            </div>
        </div>
    </div>

    <!-- Load from CDN -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/monaco-editor/0.44.0/min/vs/loader.min.js"></script>
    
    <script>
    'use strict';

    // Monaco Editor Setup

    let monacoEditor = null;

    // Configure Monaco loader
    require.config({ 
        paths: { 
            'vs': 'https://cdnjs.cloudflare.com/ajax/libs/monaco-editor/0.44.0/min/vs' 
        }
    });

    // Define WGSL language configuration
    const WGSL_LANGUAGE_CONFIG = {
        comments: {
            lineComment: '//',
            blockComment: ['/*', '*/']
        },
        brackets: [
            ['{', '}'],
            ['[', ']'],
            ['(', ')']
        ],
        autoClosingPairs: [
            { open: '{', close: '}' },
            { open: '[', close: ']' },
            { open: '(', close: ')' },
            { open: '"', close: '"', notIn: ['string'] },
        ],
        surroundingPairs: [
            { open: '{', close: '}' },
            { open: '[', close: ']' },
            { open: '(', close: ')' },
            { open: '"', close: '"' },
        ]
    };

    // WGSL syntax highlighting
    const WGSL_MONARCH_TOKENS = {
        keywords: [
            'const', 'let', 'var', 'fn', 'return', 'if', 'else', 'for', 'while',
            'break', 'continue', 'discard', 'struct', 'type', 'alias'
        ],
        typeKeywords: [
            'f32', 'f16', 'i32', 'u32', 'bool',
            'vec2f', 'vec3f', 'vec4f', 'vec2i', 'vec3i', 'vec4i', 'vec2u', 'vec3u', 'vec4u',
            'vec2', 'vec3', 'vec4',
            'mat2x2', 'mat2x3', 'mat2x4', 'mat3x2', 'mat3x3', 'mat3x4', 'mat4x2', 'mat4x3', 'mat4x4',
            'mat2x2f', 'mat2x3f', 'mat2x4f', 'mat3x2f', 'mat3x3f', 'mat3x4f', 'mat4x2f', 'mat4x3f', 'mat4x4f',
            'array', 'ptr', 'sampler', 'texture_2d', 'texture_storage_2d'
        ],
        builtins: [
            'position', 'vertex_index', 'instance_index', 'front_facing', 'frag_depth',
            'local_invocation_id', 'local_invocation_index', 'global_invocation_id',
            'workgroup_id', 'num_workgroups', 'sample_index', 'sample_mask'
        ],
        operators: [
            '=', '>', '<', '!', '~', '?', ':', '==', '<=', '>=', '!=',
            '&&', '||', '++', '--', '+', '-', '*', '/', '&', '|', '^', '%',
            '<<', '>>', '+=', '-=', '*=', '/=', '&=', '|=', '^=',
            '%=', '<<=', '>>=', '->'
        ],
        functions: [
            'sin', 'cos', 'tan', 'asin', 'acos', 'atan', 'atan2',
            'sinh', 'cosh', 'tanh', 'asinh', 'acosh', 'atanh',
            'pow', 'exp', 'log', 'exp2', 'log2', 'sqrt', 'inverseSqrt',
            'abs', 'sign', 'floor', 'ceil', 'fract', 'trunc', 'round',
            'min', 'max', 'clamp', 'saturate', 'mix', 'step', 'smoothstep',
            'length', 'distance', 'dot', 'cross', 'normalize', 'reflect', 'refract',
            'select', 'all', 'any', 'arrayLength', 'textureStore', 'textureLoad'
        ],
        tokenizer: {
            root: [
                // Attributes
                [/@[a-zA-Z_]\w*/, 'annotation'],
                
                // Keywords
                [/\b(fn|let|const|var|return|if|else|for|while|break|continue|struct)\b/, 'keyword'],
                
                // Type keywords
                [/\b(f32|f16|i32|u32|bool|vec2f|vec3f|vec4f|vec2i|vec3i|vec4i|vec2u|vec3u|vec4u|vec2|vec3|vec4|mat2x2|mat3x3|mat4x4|array|ptr|sampler|texture_2d|texture_storage_2d)\b/, 'type'],
                
                // Built-in functions
                [/\b(sin|cos|tan|abs|min|max|clamp|mix|length|dot|normalize|cross|select|textureStore|textureLoad)\b/, 'support.function'],
                
                // Numbers
                [/\b\d+\.?\d*[fu]?\b/, 'number'],
                [/0[xX][0-9a-fA-F]+[ul]?/, 'number'],
                
                // Strings
                [/"([^"\\]|\\.)*$/, 'string.invalid'],
                [/"/, { token: 'string.quote', bracket: '@open', next: '@string' }],
                
                // Comments
                [/\/\/.*$/, 'comment'],
                [/\/\*/, { token: 'comment', next: '@comment' }],
                
                // Operators
                [/[<>]=?/, 'operator'],
                [/[+\-*\/%=&|^!~]/, 'operator'],
                
                // Delimiters
                [/[{}()\[\]]/, '@brackets'],
                [/[;,.]/, 'delimiter'],
            ],
            comment: [
                [/[^\/*]+/, 'comment'],
                [/\/\*/, 'comment', '@push'],
                ['\\*/', 'comment', '@pop'],
                [/[\/*]/, 'comment']
            ],
            string: [
                [/[^\\"]+/, 'string'],
                [/"/, { token: 'string.quote', bracket: '@close', next: '@pop' }]
            ],
        }
    };

    // Configuration & Constants

    const CONFIG = {
        audioBlockDuration: 0.05,
        channels: 2,
        volume: 0.5,
        screenSize: 512,
        computeThreads: 64,
        computeBufferSize: 65536,  // 64 KB (was 2 MB) - for data sharing between passes
    };

    // These will be set after AudioContext is created
    const DERIVED = {
        sampleRate: 0,              // Read from AudioContext
        samplesPerBlock: 0,         // Calculated from actual sample rate
        audioBufferSize: 0,         // Calculated from samplesPerBlock
        audioWorkgroups: 0,         // Ceil(samplesPerBlock / computeThreads)
    };

    const UNIFORM_STRUCT = {
        time: 0,
        audioCurrentTime: 1,
        audioPlayTime: 2,
        audioFractTime: 3,
        audioFrame: 4,
        SIZE: 5,
    };

    // Application State

    const state = {
        gpuDevice: null,
        audioContext: null,
        gainNode: null,
        
        canvas: null,
        gpuContext: null,
        bindGroupLayout: null,
        graphicsPipeline: null,
        audioPipeline: null,
        uniformBuffer: null,
        computeBuffer: null,
        phaseStateBuffer: null,
        audioBufferGPU: null,
        audioBuffersReadback: [null, null],
        
        lastFrameTime: 0,
        audioFrame: 0,
        nextAudioTime: 0,
        
        readbackIndex: 0,
        pendingAudio: false,
        isRunning: false,
        isPlaying: false,
    
        // Monaco editors
        boilerplateEditor: null,
        graphicsEditor: null,
        audioEditor: null,
        jsEditor: null,
        
        userState: null,
        userInit: null,
        userEnterframe: null,
        mouseX: 0,
        mouseY: 0,
};


    // Default WGSL Shader Parts

function getBoilerplate() {
    return `// ============================================================================
// AUTO-GENERATED BOILERPLATE
// This section is read-only and updates when settings change
// ============================================================================

const SAMPLE_RATE = ${DERIVED.sampleRate}f;
const SAMPLES_PER_BLOCK = ${DERIVED.samplesPerBlock};
const COMPUTE_THREADS = ${CONFIG.computeThreads};
const SCREEN_SIZE = ${CONFIG.screenSize};
const PI = 3.1415926535897932f;
const TAU = 6.283185307179586f;

struct Uniforms {
    time: f32,              // 0
    audioCurrentTime: f32,  // 1
    audioPlayTime: f32,     // 2
    audioFractTime: f32,    // 3
    audioFrame: i32,        // 4
    
    // User-accessible uniforms (controlled from JavaScript)
    mouseX: f32,            // 5
    mouseY: f32,            // 6
    frequency: f32,         // 7
    user3: f32,             // 8
    user4: f32,             // 9
}

@binding(0) @group(0) var<uniform> uniforms: Uniforms;
@binding(1) @group(0) var<storage, read_write> computeBuffer: array<f32>;
@binding(2) @group(0) var<storage, read_write> audioBuffer: array<f32>;
@binding(3) @group(0) var screenTexture: texture_storage_2d<bgra8unorm, write>;
@binding(4) @group(0) var<storage, read_write> phaseState: array<f32>;
`;
}

function getDefaultGraphicsShader() {
    return `// ============================================================================
// GRAPHICS SHADER - Edit this to create visuals
// ============================================================================
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_SIZE) || gid.y >= u32(SCREEN_SIZE)) {
        return;
    }
    
    let uv = vec2f(gid.xy) / f32(SCREEN_SIZE);
    let t = uniforms.time;
    
    // Background pattern (dimmed)
    let mouseOffset = vec2f(uniforms.mouseX, uniforms.mouseY) * 5.0;
    let pattern = cos((uv + mouseOffset) * 10.0 + t);
    var color = vec3f(
        pattern.x * 0.15 + 0.15,
        pattern.y * 0.15 + 0.15,
        0.2
    );
    
    // Draw multi-scale waveforms
    let waveformCount = 4;
    let waveformColors = array<vec3f, 4>(
        vec3f(0.0, 1.0, 0.5),   // Cyan-green
        vec3f(1.0, 0.8, 0.0),   // Yellow
        vec3f(1.0, 0.3, 0.5),   // Pink
        vec3f(0.5, 0.5, 1.0)    // Light blue
    );
    
    for (var i = 0; i < waveformCount; i++) {
        let waveformY = (f32(i) + 0.5) / f32(waveformCount);  // Vertical position
        let zoom = pow(4.0, f32(i));  // 1x, 4x, 16x, 64x zoom
        
        // Sample audio buffer at current X position with zoom
        let samplePos = i32(uv.x * f32(SAMPLES_PER_BLOCK) / zoom) % SAMPLES_PER_BLOCK;
        let audioSample = audioBuffer[samplePos];  // Left channel (mono for simplicity)
        
        // Convert audio sample (-1 to 1) to screen space around waveformY
        let waveformHeight = 0.15 / f32(waveformCount);  // Height of each waveform strip
        let sampleY = waveformY + audioSample * waveformHeight;
        
        // Anti-aliased line drawing
        let distToWaveform = abs(uv.y - sampleY);
        let lineThickness = 0.003;
        let lineIntensity = smoothstep(lineThickness * 2.0, lineThickness * 0.5, distToWaveform);
        
        // Add waveform to color
        color += waveformColors[i] * lineIntensity * 0.8;
        
        // Draw center line for reference
        let centerDist = abs(uv.y - waveformY);
        let centerLine = smoothstep(0.002, 0.001, centerDist) * 0.2;
        color += vec3f(0.3) * centerLine;
    }
    
    // Draw scale labels (grid lines at divisions)
    for (var i = 0; i < waveformCount + 1; i++) {
        let divY = f32(i) / f32(waveformCount);
        let divDist = abs(uv.y - divY);
        let divLine = smoothstep(0.002, 0.001, divDist) * 0.3;
        color += vec3f(0.5) * divLine;
    }
    
    textureStore(screenTexture, gid.xy, vec4f(color, 1.0));
}
`;
}

function getDefaultAudioShader() {
    return `// ============================================================================
// AUDIO SHADER - Edit this to create sound
// ============================================================================
@compute @workgroup_size(128, 1, 1)
fn audio_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    let sampleIndex = i32(gid.x);
    
    // Early exit for threads beyond sample count
    if (sampleIndex >= SAMPLES_PER_BLOCK) {
        return;
    }
    
    // GPU-SIDE PHASE ACCUMULATION - Perfect timing!
    // Read persistent phase from previous block (stored on GPU)
    let basePhase = phaseState[0];
    
    // Calculate phase increment per sample using CURRENT frequency
    let phaseIncrement = uniforms.frequency * TAU / SAMPLE_RATE;
    
    // Calculate phase for THIS specific sample
    var phase = basePhase + f32(sampleIndex) * phaseIncrement;
    
    // Generate audio sample
    let sample = sin(phase) * 0.3;
    
    // Write to interleaved stereo buffer
    audioBuffer[sampleIndex] = sample;
    audioBuffer[SAMPLES_PER_BLOCK + sampleIndex] = sample;
    
    // CRITICAL: Only the very last thread updates phase state
    // This ensures one and only one write happens
    if (sampleIndex == SAMPLES_PER_BLOCK - 1) {
        // Calculate final phase after all samples
        var finalPhase = basePhase + f32(SAMPLES_PER_BLOCK) * phaseIncrement;
        
        // Wrap phase to [0, TAU) range to prevent precision loss
        // Use while loop for robust wrapping
        while (finalPhase >= TAU) {
            finalPhase -= TAU;
        }
        while (finalPhase < 0.0) {
            finalPhase += TAU;
        }
        
        phaseState[0] = finalPhase;
    }
}
`;
}

const DEFAULT_JS = `// This code runs alongside your WGSL shader
// Use 'state' to persist data between frames

function init() {
    // Called once when you press Play
    return {
        mouseX: 0,
        mouseY: 0,
        targetFreq: 440,
        smoothFreq: 440,
    };
}

function enterframe(state, api) {
    // Called every frame while playing
    
    // Smooth mouse movement
    state.mouseX += (api.mouse.x - state.mouseX) * 0.1;
    state.mouseY += (api.mouse.y - state.mouseY) * 0.1;
    
    // Change frequency
    state.targetFreq = 440 + (1. + state.mouseX) * 220 ;
    
    // Optional: smooth frequency changes for even cleaner sound
    state.smoothFreq += (state.targetFreq - state.smoothFreq) * 0.3;
    
    // Pass data to WGSL shader uniforms
    // Indices 5-9 map to: mouseX, mouseY, frequency, user3, user4
    api.uniforms.setFloat(5, state.mouseX);
    api.uniforms.setFloat(6, state.mouseY);
    api.uniforms.setFloat(7, state.smoothFreq);
    
    // You can use user3 and user4 for other data:
    // api.uniforms.setFloat(8, someValue);
    // api.uniforms.setFloat(9, anotherValue);
}`;
    // Monaco Initialization

    function initMonaco(callback) {
    require(['vs/editor/editor.main'], function() {
        // Register WGSL language
        monaco.languages.register({ id: 'wgsl' });
        monaco.languages.setLanguageConfiguration('wgsl', WGSL_LANGUAGE_CONFIG);
        monaco.languages.setMonarchTokensProvider('wgsl', WGSL_MONARCH_TOKENS);
        
        // Common editor options
        const editorOptions = {
            theme: 'vs-dark',
            fontSize: 13,
            minimap: { enabled: false },
            automaticLayout: true,
            scrollBeyondLastLine: false,
            wordWrap: 'on',
            tabSize: 4,
            insertSpaces: true,
            formatOnPaste: true,
            formatOnType: true,
            suggestOnTriggerCharacters: true,
            acceptSuggestionOnEnter: 'on',
            folding: true,
            foldingStrategy: 'indentation',
            renderWhitespace: 'selection',
            renderControlCharacters: false,
            scrollbar: {
                vertical: 'visible',
                horizontal: 'visible',
                useShadows: false,
                verticalHasArrows: false,
                horizontalHasArrows: false
            }
        };
        
        // Create Boilerplate editor (read-only)
        const boilerplateContainer = document.getElementById('boilerplateContainer');
        boilerplateContainer.innerHTML = '';
        state.boilerplateEditor = monaco.editor.create(boilerplateContainer, {
            ...editorOptions,
            value: getBoilerplate(),
            language: 'wgsl',
            readOnly: true,  // Read-only!
        });
        
        // Create Graphics editor
        const graphicsContainer = document.getElementById('graphicsContainer');
        state.graphicsEditor = monaco.editor.create(graphicsContainer, {
            ...editorOptions,
            value: getDefaultGraphicsShader(),
            language: 'wgsl',
        });
        
        // Create Audio editor
        const audioContainer = document.getElementById('audioContainer');
        state.audioEditor = monaco.editor.create(audioContainer, {
            ...editorOptions,
            value: getDefaultAudioShader(),
            language: 'wgsl',
        });
        
        // Create JavaScript editor 
        const jsContainer = document.getElementById('jsEditorContainer');
        state.jsEditor = monaco.editor.create(jsContainer, {
            ...editorOptions,
            value: DEFAULT_JS,
            language: 'javascript',
        });
        
        // Keyboard shortcuts for all editors
        const addShortcuts = (editor) => {
            editor.addCommand(monaco.KeyCode.F5, () => reloadShader());
            editor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.KeyS, () => reloadShader());
            editor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.Space, () => togglePlayPause());
        };
        addShortcuts(state.boilerplateEditor);
        addShortcuts(state.graphicsEditor);
        addShortcuts(state.audioEditor);
        addShortcuts(state.jsEditor);
            
            // Set up error markers when shader compilation fails
            window.setMonacoErrors = function(errors) {
                const markers = errors.map(err => ({
                    severity: monaco.MarkerSeverity.Error,
                    startLineNumber: err.lineNum || 1,
                    startColumn: err.linePos || 1,
                    endLineNumber: err.lineNum || 1,
                    endColumn: 1000,
                    message: err.message
                }));
                // Try to place marker in the relevant editor based on line number
                // For now, clear all and show in graphics (could be smarter later)
                monaco.editor.setModelMarkers(state.graphicsEditor.getModel(), 'wgsl', []);
                monaco.editor.setModelMarkers(state.audioEditor.getModel(), 'wgsl', []);
                monaco.editor.setModelMarkers(state.graphicsEditor.getModel(), 'wgsl', markers);
            };
            
            window.clearMonacoErrors = function() {
                monaco.editor.setModelMarkers(state.graphicsEditor.getModel(), 'wgsl', []);
                monaco.editor.setModelMarkers(state.audioEditor.getModel(), 'wgsl', []);
            };
            
            // JS error markers
            window.setJSErrors = function(errors) {
                const markers = errors.map(err => ({
                    severity: monaco.MarkerSeverity.Error,
                    startLineNumber: err.lineNum || 1,
                    startColumn: err.column || 1,
                    endLineNumber: err.lineNum || 1,
                    endColumn: err.endColumn || 1000,
                    message: err.message
                }));
                monaco.editor.setModelMarkers(state.jsEditor.getModel(), 'javascript', markers);
            };
            
            window.clearJSErrors = function() {
                monaco.editor.setModelMarkers(state.jsEditor.getModel(), 'javascript', []);
            };
            
            callback();
        });
    }
function switchTab(tab) {
    const tabs = document.querySelectorAll('.editorTab');
    const containers = {
        boilerplate: document.getElementById('boilerplateContainer'),
        graphics: document.getElementById('graphicsContainer'),
        audio: document.getElementById('audioContainer'),
        js: document.getElementById('jsEditorContainer')
    };
    const editors = {
        boilerplate: state.boilerplateEditor,
        graphics: state.graphicsEditor,
        audio: state.audioEditor,
        js: state.jsEditor
    };
    
    // Remove active class from all tabs
    tabs.forEach(t => t.classList.remove('active'));
    
    // Hide all containers
    Object.values(containers).forEach(c => c.style.display = 'none');
    
    // Show selected tab and container
    const tabMap = { boilerplate: 0, graphics: 1, audio: 2, js: 3 };
    tabs[tabMap[tab]].classList.add('active');
    containers[tab].style.display = 'block';
    
    // Force layout update for selected editor
    if (editors[tab]) {
        editors[tab].layout();
    }
}
function parseJSError(err, codeLines) {
    // Extract line number from error message or stack
    let lineNum = 1;
    let column = 1;
    let endColumn = 1000; // Default to end of line
    
    // Try to parse from stack trace
    const stackMatch = err.stack?.match(/<anonymous>:(\d+):(\d+)/);
    if (stackMatch) {
        // Line numbers from Function() wrapper need adjustment
        // Testing showed we need to subtract 3 to get correct line
        lineNum = Math.max(1, parseInt(stackMatch[1]) - 3);
        column = parseInt(stackMatch[2]) || 1;
        
        // Try to determine end column by looking at the error type
        // For syntax errors, highlight a reasonable amount
        if (err instanceof SyntaxError) {
            endColumn = column + 10; // Highlight ~10 chars for syntax errors
        } else {
            // For runtime errors, try to highlight the problematic token
            endColumn = column + 20; // Highlight more for runtime errors
        }
    } else {
        // Try parsing from error message (some syntax errors include line info)
        const msgMatch = err.message?.match(/line (\d+)/i);
        if (msgMatch) {
            lineNum = parseInt(msgMatch[1]);
        }
    }
    
    // Clamp to valid range
    lineNum = Math.min(lineNum, codeLines);
    
    return { lineNum, column, endColumn, message: err.message };
}

function compileUserJS() {
    const code = state.jsEditor.getValue();
    const codeLines = code.split('\n').length;
    
    try {
        clearJSErrors();
        
        // Create a safe scope and eval the user's code
        // We add one newline before user code to make line numbers match
        const wrappedCode = `
${code}
return { init, enterframe };
`;
        const factory = new Function(wrappedCode);
        const userFunctions = factory();
        
        state.userInit = userFunctions.init;
        state.userEnterframe = userFunctions.enterframe;
        
        logStatus('‚úì JavaScript compiled successfully', 'success');
        return true;
    } catch (err) {
        const errorInfo = parseJSError(err, codeLines);
        
        setJSErrors([{
            lineNum: errorInfo.lineNum,
            column: errorInfo.column,
            endColumn: errorInfo.endColumn,
            message: errorInfo.message
        }]);
        
        logStatus(`‚úó JS Error (line ${errorInfo.lineNum}): ${errorInfo.message}`, 'error');
        return false;
    }
}
    // Global error handler to catch uncaught errors from user code
    function setupErrorHandling() {
        // Store original handlers
        const originalErrorHandler = window.onerror;
        const originalConsoleError = console.error;
        const originalConsoleWarn = console.warn;
        
        // Intercept console.error to detect user code issues
        console.error = function(...args) {
            // Check if called from user code
            const stack = new Error().stack;
            if (stack && stack.includes('<anonymous>') && state.jsEditor) {
                logStatus(`‚ö† Console error from user code: ${args[0]}`, 'error');
            }
            // Always call original console.error
            originalConsoleError.apply(console, args);
        };
        
        console.warn = function(...args) {
            const stack = new Error().stack;
            if (stack && stack.includes('<anonymous>') && state.jsEditor) {
                logStatus(`‚ö† Console warning from user code: ${args[0]}`, 'info');
            }
            originalConsoleWarn.apply(console, args);
        };
        
        // Global error handler
        window.onerror = function(message, source, lineno, colno, error) {
            // Check if this is from user code (anonymous function)
            if (error && error.stack && error.stack.includes('<anonymous>')) {
                const code = state.jsEditor?.getValue();
                if (code) {
                    const codeLines = code.split('\n').length;
                    const errorInfo = parseJSError(error, codeLines);
                    
                    setJSErrors([{
                        lineNum: errorInfo.lineNum,
                        column: errorInfo.column,
                        endColumn: errorInfo.endColumn,
                        message: `Uncaught error: ${errorInfo.message}`
                    }]);
                    
                    logStatus(`‚úó Uncaught JS error (line ${errorInfo.lineNum}): ${error.message}`, 'error');
                    
                    // Pause if playing
                    if (state.isPlaying) {
                        state.isPlaying = false;
                        state.audioContext?.suspend();
                        
                        const btn = document.getElementById('playPauseBtn');
                        if (btn) {
                            btn.textContent = '‚ñ∂';
                            btn.className = 'paused';
                        }
                    }
                    
                    return true; // Prevent default error handling
                }
            }
            
            // Let editor errors through to console
            if (originalErrorHandler) {
                return originalErrorHandler(message, source, lineno, colno, error);
            }
            return false;
        };
    }

    // Initialization
    async function init() {
        setupErrorHandling();
        setupUI();
        
        // Initialize audio FIRST to get actual sample rate
        initWebAudio();
        
        // Then initialize Monaco with correct shader values
        initMonaco(async () => {
            try {
                await initWebGPU();
                await reloadShader();
                state.isRunning = true;
                requestAnimationFrame(render);
                logStatus('System initialized! Press Play to start audio.', 'success');
            } catch (err) {
                logStatus('Initialization failed: ' + err.message, 'error');
            }
        });
    }

    function setupUI() {
        // Canvas
        state.canvas = document.getElementById('canvas');
        state.canvas.width = CONFIG.screenSize;
        state.canvas.height = CONFIG.screenSize;
        state.canvas.style.width = CONFIG.screenSize + 'px';
        state.canvas.style.height = CONFIG.screenSize + 'px';

        // Play/Pause button
        document.getElementById('playPauseBtn').addEventListener('click', togglePlayPause);

        // Reload button
        document.getElementById('reloadBtn').addEventListener('click', reloadShader);

        // Volume control
        const volumeSlider = document.getElementById('volumeSlider');
        const volumeValue = document.getElementById('volumeValue');
        volumeSlider.addEventListener('input', (e) => {
            const vol = e.target.value / 100;
            CONFIG.volume = vol;
            if (state.gainNode) state.gainNode.gain.value = vol;
            volumeValue.textContent = e.target.value + '%';
        });
    // ADD THIS - Track mouse position
    document.addEventListener('mousemove', (e) => {
        const rect = state.canvas.getBoundingClientRect();
        state.mouseX = (e.clientX - rect.left) / rect.width;
        state.mouseY = 1.0 - (e.clientY - rect.top) / rect.height; // Flip Y
    });
        // Handle visibility change
        document.addEventListener('visibilitychange', () => {
            if (!document.hidden && state.audioContext && state.isPlaying) {
                const ctx = state.audioContext;
                state.nextAudioTime = Math.ceil(ctx.currentTime / CONFIG.audioBlockDuration) 
                                     * CONFIG.audioBlockDuration;
                state.pendingAudio = false;
                logStatus('Audio resynced after visibility change', 'info');
            }
        });
    }

function togglePlayPause() {
    if (!state.audioContext) return;
    
    const btn = document.getElementById('playPauseBtn');
    
    if (state.isPlaying) {
        state.audioContext.suspend();
        state.isPlaying = false;
        btn.textContent = '‚ñ∂';
        btn.className = 'paused';
        logStatus('Audio paused', 'info');
    } else {
        // Compile and initialize user JS
        if (compileUserJS()) {
            try {
                state.userState = state.userInit ? state.userInit() : {};
                clearJSErrors(); // Clear any previous runtime errors
                logStatus('‚úì JS initialized successfully', 'success');
            } catch (err) {
                const code = state.jsEditor.getValue();
                const codeLines = code.split('\n').length;
                const errorInfo = parseJSError(err, codeLines);
                
                setJSErrors([{
                    lineNum: errorInfo.lineNum,
                    column: errorInfo.column,
                    endColumn: errorInfo.endColumn,
                    message: `Runtime error in init(): ${errorInfo.message}`
                }]);
                
                logStatus(`‚úó JS init() error (line ${errorInfo.lineNum}): ${err.message}`, 'error');
                return;
            }
        } else {
            return; // Don't start if JS compilation failed
        }
        
        state.audioContext.resume();
        state.isPlaying = true;
        
        // Reset GPU phase to 0 for clean start
        state.gpuDevice.queue.writeBuffer(state.phaseStateBuffer, 0, new Float32Array([0.0]));
        
        const ctx = state.audioContext;
        state.nextAudioTime = Math.ceil(ctx.currentTime / CONFIG.audioBlockDuration) 
                             * CONFIG.audioBlockDuration;
        state.pendingAudio = false;
        
        btn.textContent = '‚è∏';
        btn.className = 'playing';
    }
}

    async function initWebGPU() {
        const adapter = await navigator.gpu?.requestAdapter();
        if (!adapter) throw new Error('WebGPU not supported');

        state.gpuDevice = await adapter.requestDevice({
            requiredFeatures: ['bgra8unorm-storage'],
            requiredLimits: {
                maxBufferSize: Math.pow(2, 30),
                maxStorageBufferBindingSize: Math.pow(2, 30),
            }
        });

        state.gpuContext = state.canvas.getContext('webgpu');
        state.gpuContext.configure({
            device: state.gpuDevice,
            format: navigator.gpu.getPreferredCanvasFormat(),
            usage: GPUTextureUsage.STORAGE_BINDING,
        });

        createGPUResources();
    }

    function createGPUResources() {
        const device = state.gpuDevice;

        state.uniformBuffer = device.createBuffer({
            size: 256,
            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
        });

        state.computeBuffer = device.createBuffer({
            size: CONFIG.computeBufferSize,
            usage: GPUBufferUsage.STORAGE,
        });

        state.audioBufferGPU = device.createBuffer({
            size: DERIVED.audioBufferSize,
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
        });
        
        // Phase state buffer - persistent GPU-side phase for perfect timing
        state.phaseStateBuffer = device.createBuffer({
            size: 4,  // Single f32
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
        });
        
        // Initialize phase to 0
        device.queue.writeBuffer(state.phaseStateBuffer, 0, new Float32Array([0.0]));

        for (let i = 0; i < 2; i++) {
            state.audioBuffersReadback[i] = device.createBuffer({
                size: DERIVED.audioBufferSize,
                usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
            });
        }

        state.bindGroupLayout = device.createBindGroupLayout({
            entries: [
                { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'uniform' } },
                { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
                { binding: 2, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
                { binding: 3, visibility: GPUShaderStage.COMPUTE, storageTexture: { 
                    format: 'bgra8unorm', access: 'write-only', viewDimension: '2d' 
                }},
                { binding: 4, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
            ],
        });
    }

    function initWebAudio() {
        state.audioContext = new AudioContext();
        
        // Read actual sample rate from AudioContext
        DERIVED.sampleRate = state.audioContext.sampleRate;
        DERIVED.samplesPerBlock = Math.floor(CONFIG.audioBlockDuration * DERIVED.sampleRate);
        DERIVED.audioBufferSize = 4 * CONFIG.channels * DERIVED.samplesPerBlock;
        DERIVED.audioWorkgroups = Math.ceil(DERIVED.samplesPerBlock / 128);  // 128 threads per workgroup for audio
        
        console.log(`Audio initialized: ${DERIVED.sampleRate}Hz, ${DERIVED.samplesPerBlock} samples/block`);
        console.log(`Dispatch: Graphics 64√ó64 workgroups (8√ó8 threads), Audio ${DERIVED.audioWorkgroups}√ó1 workgroups (128 threads)`);
        
        state.gainNode = state.audioContext.createGain();
        state.gainNode.gain.value = CONFIG.volume;
        state.gainNode.connect(state.audioContext.destination);
        
        state.nextAudioTime = Math.ceil(state.audioContext.currentTime / CONFIG.audioBlockDuration) 
                             * CONFIG.audioBlockDuration;
        
        state.audioContext.suspend();
    }

    // Live Shader Reload
    async function reloadShader() {
    // Compose full shader from boilerplate + graphics + audio
    const boilerplate = getBoilerplate();  // Auto-generated
    const graphics = state.graphicsEditor.getValue();
    const audio = state.audioEditor.getValue();
    const code = boilerplate + '\n' + graphics + '\n' + audio;
    
    // Update boilerplate editor to show latest auto-generated values
    state.boilerplateEditor.setValue(boilerplate);
    
    try {
        logStatus('Compiling shader...', 'info');
        clearMonacoErrors();
        
        const shaderModule = state.gpuDevice.createShaderModule({ code });
        
        const compilationInfo = await shaderModule.getCompilationInfo();
        const errors = compilationInfo.messages.filter(m => m.type === 'error');
        
        if (errors.length > 0) {
            setMonacoErrors(errors);
            const errorMsg = errors.map(e => 
                `Line ${e.lineNum}: ${e.message}`
            ).join('\n');
            throw new Error('Shader compilation failed:\n' + errorMsg);
        }
        
        const pipelineLayout = state.gpuDevice.createPipelineLayout({
            bindGroupLayouts: [state.bindGroupLayout],
        });
        
        // Create graphics pipeline (8√ó8 workgroups for 2D)
        const newGraphicsPipeline = state.gpuDevice.createComputePipeline({
            layout: pipelineLayout,
            compute: { module: shaderModule, entryPoint: 'graphics_main' },
        });
        
        // Create audio pipeline (128√ó1 workgroups for 1D)
        const newAudioPipeline = state.gpuDevice.createComputePipeline({
            layout: pipelineLayout,
            compute: { module: shaderModule, entryPoint: 'audio_main' },
        });
        
        state.graphicsPipeline = newGraphicsPipeline;
        state.audioPipeline = newAudioPipeline;
        
        // Also reload JS if playing
        if (state.isPlaying) {
            if (compileUserJS()) {
                logStatus('‚úì Shader and JS reloaded successfully!', 'success');
            } else {
                logStatus('‚úì Shader compiled, but JS has errors', 'error');
            }
        } else {
            logStatus('‚úì Shader compiled successfully!', 'success');
        }
        
    } catch (err) {
        logStatus('‚úó ' + err.message, 'error');
    }
}

    function logStatus(message, type = 'info') {
        const display = document.getElementById('errorDisplay');
        display.textContent = message;
        display.className = type;
    }

    // Render Loop (unchanged)
    function render(time) {
        if (!state.isRunning) return;

        const device = state.gpuDevice;
        const ctx = state.audioContext;
        
        document.getElementById('frameCounter').textContent = state.audioFrame;
        document.getElementById('timeCounter').textContent = (time * 0.001).toFixed(2) + 's';

        const uniformData = new ArrayBuffer(256);
        const uniformF32 = new Float32Array(uniformData);
        const uniformI32 = new Int32Array(uniformData);
        
        uniformF32[UNIFORM_STRUCT.time] = time * 0.001;
        uniformF32[UNIFORM_STRUCT.audioCurrentTime] = ctx.currentTime;
        uniformF32[UNIFORM_STRUCT.audioPlayTime] = state.nextAudioTime;
        uniformF32[UNIFORM_STRUCT.audioFractTime] = state.nextAudioTime % 1;
        uniformI32[UNIFORM_STRUCT.audioFrame] = state.audioFrame;
        
    // Call user's enterframe with API
    if (state.isPlaying && state.userEnterframe) {
        try {
            const api = {
                time: time * 0.001,
                deltaTime: 0.016, // Could calculate real delta
                mouse: { x: state.mouseX, y: state.mouseY },
                sampleRate: DERIVED.sampleRate,
                samplesPerBlock: DERIVED.samplesPerBlock,
                audioFrame: state.audioFrame,
                audioBlockGenerated: false,  // Will be set to true if audio was generated this frame
                uniforms: {
                    setFloat: (index, value) => {
                        if (index >= 5 && index < 20) {
                            uniformF32[index] = value;
                        }
                    },
                    setInt: (index, value) => {
                        if (index >= 5 && index < 20) {
                            uniformI32[index] = value;
                        }
                    }
                }
            };
            state.userEnterframe(state.userState, api);
        } catch (err) {
            // Pause playback on runtime error
            state.isPlaying = false;
            state.audioContext.suspend();
            
            const btn = document.getElementById('playPauseBtn');
            btn.textContent = '‚ñ∂';
            btn.className = 'paused';
            
            // Show error with line number
            const code = state.jsEditor.getValue();
            const codeLines = code.split('\n').length;
            const errorInfo = parseJSError(err, codeLines);
            
            setJSErrors([{
                lineNum: errorInfo.lineNum,
                column: errorInfo.column,
                endColumn: errorInfo.endColumn,
                message: `Runtime error in enterframe(): ${errorInfo.message}`
            }]);
            
            logStatus(`‚úó JS enterframe() error (line ${errorInfo.lineNum}): ${err.message}`, 'error');
            console.error('enterframe error:', err);
        }
    }
    
    device.queue.writeBuffer(state.uniformBuffer, 0, uniformData);

        const textureView = state.gpuContext.getCurrentTexture().createView();
        const bindGroup = device.createBindGroup({
            layout: state.bindGroupLayout,
            entries: [
                { binding: 0, resource: { buffer: state.uniformBuffer } },
                { binding: 1, resource: { buffer: state.computeBuffer } },
                { binding: 2, resource: { buffer: state.audioBufferGPU } },
                { binding: 3, resource: textureView },
                { binding: 4, resource: { buffer: state.phaseStateBuffer } },
            ],
        });

        // Check if we need to generate audio THIS frame
        const needsAudio = state.isPlaying && 
                          ctx.currentTime >= state.nextAudioTime - CONFIG.audioBlockDuration && 
                          !state.pendingAudio;

        const encoder = device.createCommandEncoder();
        const pass = encoder.beginComputePass();
        
        // AUDIO PASS FIRST - Only when we actually need a new block!
        if (needsAudio) {
            pass.setPipeline(state.audioPipeline);
            pass.setBindGroup(0, bindGroup);
            pass.dispatchWorkgroups(
                Math.ceil(DERIVED.samplesPerBlock / 128),  // e.g., ceil(4800/128) = 38 workgroups
                1,
                1
            );
        }
        
        // GRAPHICS PASS SECOND - Reads audio data from buffer
        // 8√ó8 workgroups for optimal 2D texture access
        pass.setPipeline(state.graphicsPipeline);
        pass.setBindGroup(0, bindGroup);
        pass.dispatchWorkgroups(
            CONFIG.screenSize / 8,  // 512/8 = 64 workgroups X
            CONFIG.screenSize / 8,  // 512/8 = 64 workgroups Y
            1
        );
        
        pass.end();

        if (needsAudio) {
            state.pendingAudio = true;
            
            const readbackBuffer = state.audioBuffersReadback[state.readbackIndex];
            encoder.copyBufferToBuffer(
                state.audioBufferGPU, 0,
                readbackBuffer, 0,
                DERIVED.audioBufferSize
            );
            
            device.queue.submit([encoder.finish()]);
            
            readbackBuffer.mapAsync(GPUMapMode.READ).then(() => {
                playAudioBlock(readbackBuffer);
                state.readbackIndex = 1 - state.readbackIndex;
                state.pendingAudio = false;
            }).catch(err => {
                console.error('Audio readback failed:', err);
                state.pendingAudio = false;
            });
        } else {
            device.queue.submit([encoder.finish()]);
        }

        requestAnimationFrame(render);
    }

    function playAudioBlock(readbackBuffer) {
        const ctx = state.audioContext;
        const audioData = new Float32Array(readbackBuffer.getMappedRange());
        
        const audioBuffer = ctx.createBuffer(
            CONFIG.channels,
            DERIVED.samplesPerBlock,
            DERIVED.sampleRate
        );
        
        for (let ch = 0; ch < CONFIG.channels; ch++) {
            const channelData = audioBuffer.getChannelData(ch);
            const offset = ch * DERIVED.samplesPerBlock;
            for (let i = 0; i < DERIVED.samplesPerBlock; i++) {
                channelData[i] = audioData[offset + i];
            }
        }
        
        readbackBuffer.unmap();
        
        const source = ctx.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(state.gainNode);
        source.start(state.nextAudioTime);
        
        state.nextAudioTime += CONFIG.audioBlockDuration;
        state.audioFrame++;
    }

    // ============================================================================
    // Start
    // ============================================================================
    window.addEventListener('load', init);
    </script>
</body>
</html>