<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <title>WGSL Editor with Monaco</title>
    <style>
        :root {
            /* Dark mode colors (default) */
            --bg-primary: #1e1e1e;
            --bg-secondary: #2d2d2d;
            --bg-tertiary: #3c3c3c;
            --text-primary: #d4d4d4;
            --text-secondary: #858585;
            --border-color: #3c3c3c;
        }
        
        body.light-mode {
            /* Light mode colors */
            --bg-primary: #ffffff;
            --bg-secondary: #eeeeff;
            --bg-tertiary: #ccccff;
            --text-primary: #182247;
            --text-secondary: #6e6e6e;
            --border-color: #cccccc;
        }
        
        body {
            margin: 0;
            padding: 10px;
            background: var(--bg-primary);
            color: var(--text-primary);
            font-family: system-ui, -apple-system, sans-serif;
            overflow: hidden;
            transition: background 0.3s, color 0.3s;
        }
        #editorTabs {
    display: flex;
    gap: 5px;
    margin-bottom: 5px;
}
.editorTab {
    background: var(--bg-secondary);
    color: var(--text-secondary);
    border: none;
    padding: 6px 12px;
    cursor: pointer;
    font-size: 13px;
    transition: background 0.3s, color 0.3s;
}
.editorTab.active {
    background: var(--bg-primary);
    color: var(--text-primary);
}
#jsEditorContainer {
    display: none;
}
        #container {
            display: flex;
            gap: 10px;
            height: 98vh;
        }
        #leftPanel {
            flex: 1;
            display: flex;
            flex-direction: column;
            gap: 0px;
            min-width: 400px;
        }
        #rightPanel {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        #editorContainer {
            flex: 1;
            border: 1px solid var(--border-color);
            overflow: hidden;
            position: relative;
        }
        #loadingMessage {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: var(--text-secondary);
            font-size: 14px;
        }
        #controls {
            display: flex;
            gap: 10px;
            align-items: center;
            flex-wrap: wrap;
        }
        button {
            background: #0e639c;
            color: white;
            border: none;
            padding: 8px 16px;
            cursor: pointer;
            font-size: 14px;
            font-weight: 500;
            transition: background 0.2s;
        }
        button:hover {
            background: #1177bb;
        }
        button.playing {
            background: #16825d;
        }
        button.playing:hover {
            background: #1a9870;
        }
        button.paused {
            background: #c5a332;
        }
        button.paused:hover {
            background: #d4b547;
        }
        .verticalSlider {
            writing-mode: bt-lr; /* IE */
            -webkit-appearance: slider-vertical; /* WebKit */
            appearance: slider-vertical; /* Standard */
            width: 8px;
            height: 80px;
            padding: 0;
            margin: 0;
        }
        .sliderContainer {
            display: flex;
            flex-direction: column;
            align-items: center;
            gap: 5px;
        }
        #errorDisplay {
            background: var(--bg-primary);
            border: 1px solid var(--border-color);
            padding: 10px;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 12px;
            min-height: 60px;
            max-height: 120px;
            overflow-y: auto;
            transition: background 0.3s, border 0.3s;
        }
        .error { color: #f48771; }
        .success { color: #4ec9b0; }
        .info { color: #9cdcfe; }
        #canvasContainer {
            position: relative;
            width: fit-content;
            border: 1px solid var(--border-color);
        }
        #canvas {
            display: block;
            /* image-rendering set dynamically via JS */
        }
        #resizeHandle {
            position: absolute;
            bottom: 0;
            left: 0;
            width: 20px;
            height: 20px;
            cursor: nesw-resize;
            background: linear-gradient(225deg, transparent 0%, transparent 50%, #0e639c 50%, #0e639c 100%);
            opacity: 0.6;
            transition: opacity 0.2s;
        }
        #resizeHandle:hover {
            opacity: 1;
        }
        #canvasContainer.resizing #canvas {
            pointer-events: none;
        }
        .hint {
            color: var(--text-secondary);
            font-size: 12px;
        }
        .statusBadge {
            display: inline-block;
            padding: 2px 8px;
            font-size: 11px;
            font-weight: bold;
        }
        .statusBadge.playing {
            background: #16825d;
            color: white;
        }
        .statusBadge.paused {
            background: #c5a332;
            color: white;
        }
    </style>
</head>
<body>
    <div id="container">
        <div id="leftPanel">
<div id="editorTabs" style="display: flex; margin-bottom: 0px; gap: 5px; align-items: center;">
    <!-- Tabs will be dynamically added here -->
    <button id="addPassBtn" style="padding: 6px 12px; font-size: 13px; margin-left: auto;">+ Add Pass</button>
</div>
<div id="boilerplateContainer" style="flex: 1; border: 1px solid var(--border-color); overflow: hidden; display: none;">
</div>
<div id="graphicsContainer" style="flex: 1; border: 1px solid var(--border-color); overflow: hidden;">
    <div id="loadingMessage">Loading Monaco Editor...</div>
</div>
<div id="audioContainer" style="flex: 1; border: 1px solid var(--border-color); overflow: hidden; display: none;">
</div>
<div id="jsEditorContainer" style="flex: 1; border: 1px solid var(--border-color); overflow: hidden; display: none;">
</div>
<div id="helpContainer" style="flex: 1; border: 1px solid var(--border-color); overflow: hidden; display: none;">
</div>
            <div>
                <div class="hint">Status:</div>
                <div id="errorDisplay" class="info">Loading editor...</div>
            </div>
        </div>
        <div id="rightPanel">
            <div id="canvasContainer">
                <canvas id="canvas"></canvas>
                <div id="resizeHandle"></div>
            </div>
            <div id="controls">
                <div style="display: grid; grid-template-columns: 1fr 1fr; gap: 5px;">
                    <button id="playPauseBtn" class="playing">‚è∏</button>
                    <button id="restartBtn" title="Restart from beginning">‚ü≥</button>
                    <button id="reloadBtn" title="Reload shaders">‚öô</button>
                    <button id="themeToggleBtn" title="Toggle light/dark mode">üí°</button>
                </div>
                <div class="sliderContainer">
                    <input type="range" id="volumeSlider" class="verticalSlider" min="0" max="100" value="50" orient="vertical">
                    <div style="font-size: 16px;">üîä</div>
                </div>
                <div class="sliderContainer">
                    <input type="range" id="pixelScaleSlider" class="verticalSlider" min="0" max="5" value="0" step="1" orient="vertical">
                    <div id="renderModeIcon" style="font-size: 16px; cursor: pointer; user-select: none;" title="Click to cycle render modes">‚ñ¶</div>
                </div>
                <div style="display: flex; flex-direction: column; gap: 3px; color: var(--text-secondary); font-size: 12px;">
                    <div id="resolutionDisplay">512 √ó 512 √ó 1</div>
                    <div>FPS: <span id="fpsCounter">0</span></div>
                    <div>Frame: <span id="frameCounter">0</span></div>
                    <div>Time: <span id="timeCounter">0.00s</span></div>
                </div>
            </div>
            <div style="display: flex; gap: 5px; align-items: center; margin-top: 10px;">
                <label style="color: var(--text-secondary); font-size: 13px;">Example:</label>
                <select id="exampleSelector" style="background: var(--bg-secondary); color: var(--text-primary); border: 1px solid var(--border-color); padding: 4px 8px; font-size: 13px; cursor: pointer; flex: 1;">
                    <!-- Populated by JS -->
                </select>
            </div>
        </div>
    </div>

    <!-- Load from CDN -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/monaco-editor/0.44.0/min/vs/loader.min.js"></script>
    
    <script>
    'use strict';

    // Monaco Editor Setup

    let monacoEditor = null;

    // Configure Monaco loader
    require.config({ 
        paths: { 
            'vs': 'https://cdnjs.cloudflare.com/ajax/libs/monaco-editor/0.44.0/min/vs' 
        }
    });

    // Define WGSL language configuration
    const WGSL_LANGUAGE_CONFIG = {
        comments: {
            lineComment: '//',
            blockComment: ['/*', '*/']
        },
        brackets: [
            ['{', '}'],
            ['[', ']'],
            ['(', ')']
        ],
        autoClosingPairs: [
            { open: '{', close: '}' },
            { open: '[', close: ']' },
            { open: '(', close: ')' },
            { open: '"', close: '"', notIn: ['string'] },
        ],
        surroundingPairs: [
            { open: '{', close: '}' },
            { open: '[', close: ']' },
            { open: '(', close: ')' },
            { open: '"', close: '"' },
        ]
    };

    // WGSL syntax highlighting
    const WGSL_MONARCH_TOKENS = {
        keywords: [
            'const', 'let', 'var', 'fn', 'return', 'if', 'else', 'for', 'while',
            'break', 'continue', 'discard', 'struct', 'type', 'alias'
        ],
        typeKeywords: [
            'f32', 'f16', 'i32', 'u32', 'bool',
            'vec2f', 'vec3f', 'vec4f', 'vec2i', 'vec3i', 'vec4i', 'vec2u', 'vec3u', 'vec4u',
            'vec2', 'vec3', 'vec4',
            'mat2x2', 'mat2x3', 'mat2x4', 'mat3x2', 'mat3x3', 'mat3x4', 'mat4x2', 'mat4x3', 'mat4x4',
            'mat2x2f', 'mat2x3f', 'mat2x4f', 'mat3x2f', 'mat3x3f', 'mat3x4f', 'mat4x2f', 'mat4x3f', 'mat4x4f',
            'array', 'ptr', 'sampler', 'texture_2d', 'texture_storage_2d'
        ],
        builtins: [
            'position', 'vertex_index', 'instance_index', 'front_facing', 'frag_depth',
            'local_invocation_id', 'local_invocation_index', 'global_invocation_id',
            'workgroup_id', 'num_workgroups', 'sample_index', 'sample_mask'
        ],
        operators: [
            '=', '>', '<', '!', '~', '?', ':', '==', '<=', '>=', '!=',
            '&&', '||', '++', '--', '+', '-', '*', '/', '&', '|', '^', '%',
            '<<', '>>', '+=', '-=', '*=', '/=', '&=', '|=', '^=',
            '%=', '<<=', '>>=', '->'
        ],
        functions: [
            'sin', 'cos', 'tan', 'asin', 'acos', 'atan', 'atan2',
            'sinh', 'cosh', 'tanh', 'asinh', 'acosh', 'atanh',
            'pow', 'exp', 'log', 'exp2', 'log2', 'sqrt', 'inverseSqrt',
            'abs', 'sign', 'floor', 'ceil', 'fract', 'trunc', 'round',
            'min', 'max', 'clamp', 'saturate', 'mix', 'step', 'smoothstep',
            'length', 'distance', 'dot', 'cross', 'normalize', 'reflect', 'refract',
            'select', 'all', 'any', 'arrayLength', 'textureStore', 'textureLoad'
        ],
        tokenizer: {
            root: [
                // Attributes
                [/@[a-zA-Z_]\w*/, 'annotation'],
                
                // Keywords
                [/\b(fn|let|const|var|return|if|else|for|while|break|continue|struct)\b/, 'keyword'],
                
                // Type keywords
                [/\b(f32|f16|i32|u32|bool|vec2f|vec3f|vec4f|vec2i|vec3i|vec4i|vec2u|vec3u|vec4u|vec2|vec3|vec4|mat2x2|mat3x3|mat4x4|array|ptr|sampler|texture_2d|texture_storage_2d)\b/, 'type'],
                
                // Built-in functions
                [/\b(sin|cos|tan|abs|min|max|clamp|mix|length|dot|normalize|cross|select|textureStore|textureLoad)\b/, 'support.function'],
                
                // Numbers
                [/\b\d+\.?\d*[fu]?\b/, 'number'],
                [/0[xX][0-9a-fA-F]+[ul]?/, 'number'],
                
                // Strings
                [/"([^"\\]|\\.)*$/, 'string.invalid'],
                [/"/, { token: 'string.quote', bracket: '@open', next: '@string' }],
                
                // Comments
                [/\/\/.*$/, 'comment'],
                [/\/\*/, { token: 'comment', next: '@comment' }],
                
                // Operators
                [/[<>]=?/, 'operator'],
                [/[+\-*\/%=&|^!~]/, 'operator'],
                
                // Delimiters
                [/[{}()\[\]]/, '@brackets'],
                [/[;,.]/, 'delimiter'],
            ],
            comment: [
                [/[^\/*]+/, 'comment'],
                [/\/\*/, 'comment', '@push'],
                ['\\*/', 'comment', '@pop'],
                [/[\/*]/, 'comment']
            ],
            string: [
                [/[^\\"]+/, 'string'],
                [/"/, { token: 'string.quote', bracket: '@close', next: '@pop' }]
            ],
        }
    };

    // Configuration & Constants

    const AUDIO_MODES = {
        GPU: 'gpu',
        WORKLET: 'worklet',
        NONE: 'none'
    };
    
    // LocalStorage management
    const STORAGE_KEY = 'sleditor_settings';
    
    function loadSettings() {
        try {
            const stored = localStorage.getItem(STORAGE_KEY);
            return stored ? JSON.parse(stored) : {};
        } catch (e) {
            console.warn('Failed to load settings from localStorage:', e);
            return {};
        }
    }
    
    function saveSettings(settings) {
        try {
            const current = loadSettings();
            const merged = { ...current, ...settings };
            localStorage.setItem(STORAGE_KEY, JSON.stringify(merged));
        } catch (e) {
            console.warn('Failed to save settings to localStorage:', e);
        }
    }

    const CONFIG = {
        audioBlockDuration: 0.1,
        channels: 2,
        volume: 0.5,
        screenSize: 512,
        computeThreads: 64,
        computeBufferSize: 65536,  // 64 KB (was 2 MB) - for data sharing between passes
    };

    // These will be set after AudioContext is created
    const DERIVED = {
        sampleRate: 0,              // Read from AudioContext
        samplesPerBlock: 0,         // Calculated from actual sample rate
        audioBufferSize: 0,         // Calculated from samplesPerBlock
        audioWorkgroups: 0,         // Ceil(samplesPerBlock / computeThreads)
    };

    const UNIFORM_STRUCT = {
        time: 0,
        audioCurrentTime: 1,
        audioPlayTime: 2,
        audioFractTime: 3,
        audioFrame: 4,
        SIZE: 5,
    };

    // Application State

    const state = {
        gpuDevice: null,
        audioContext: null,
        gainNode: null,
        audioMode: AUDIO_MODES.NONE,
        audioWorkletNode: null,
        
        canvas: null,
        canvasWidth: 512,
        canvasHeight: 512,
        pixelScale: 1,  // 1=high, 2=medium, 4=low resolution
        renderMode: 0,  // 0=pixelated, 1=smooth, 2=crisp-edges
        gpuContext: null,
        bindGroupLayout: null,
        graphicsPipeline: null,
        audioPipeline: null,
        uniformBuffer: null,
        computeBuffer: null,
        phaseStateBuffer: null,
        audioBufferGPU: null,
        audioBuffersReadback: [null, null],
        
        // Canvas resizing
        isResizing: false,
        resizeStartX: 0,
        resizeStartY: 0,
        resizeStartWidth: 0,
        resizeStartHeight: 0,
        
        lastFrameTime: 0,
        visualFrame: 0,        // Visual frame counter (increments every render)
        audioFrame: 0,         // Audio frame counter (increments when audio generated)
        nextAudioTime: 0,
        startTime: 0,          // When animation started (for time offset)
        pausedTime: 0,         // Total time spent paused
        lastPauseTime: 0,      // When we last paused
        
        // FPS tracking
        fps: 0,
        fpsFrameCount: 0,
        fpsLastTime: 0,
        
        // Theme
        isDarkMode: false,
        
        readbackIndex: 0,
        pendingAudio: false,
        isRunning: false,      // System initialized and ready
        isPlaying: true,       // Currently playing (default true)
    
        // Monaco editors
        boilerplateEditor: null,
        graphicsEditor: null,
        audioEditor: null,
        jsEditor: null,
        helpEditor: null,
        
        // Active tabs and current example
        activeTabs: ['graphics', 'help'],  // Start with just these
        currentTab: 'graphics',
        currentExample: 'grey_blob',
        currentAudioType: null,  // 'gpu' or 'worklet' - tracks which audio tab is active
        
        userState: null,
        userInit: null,
        userEnterframe: null,
        mouseX: 0.5,
        mouseY: 0.5,
};


    // Default WGSL Shader Parts

function getBoilerplate() {
    return `// ============================================================================
// AUTO-GENERATED BOILERPLATE
// This section is read-only and updates when settings change
// ============================================================================

const SAMPLE_RATE = ${DERIVED.sampleRate}f;
const SAMPLES_PER_BLOCK = ${DERIVED.samplesPerBlock};
const COMPUTE_THREADS = ${CONFIG.computeThreads};
const SCREEN_WIDTH = ${Math.floor(state.canvasWidth / state.pixelScale)};
const SCREEN_HEIGHT = ${Math.floor(state.canvasHeight / state.pixelScale)};
const SCREEN_SIZE = ${CONFIG.screenSize};  // Kept for backward compatibility
const PI = 3.1415926535897932f;
const TAU = 6.283185307179586f;

struct Uniforms {
    time: f32,              // 0
    audioCurrentTime: f32,  // 1
    audioPlayTime: f32,     // 2
    audioFractTime: f32,    // 3
    audioFrame: i32,        // 4
    
    // User-accessible uniforms (controlled from JavaScript)
    mouseX: f32,            // 5
    mouseY: f32,            // 6
    frequency: f32,         // 7
    user3: f32,             // 8
    user4: f32,             // 9
}

@binding(0) @group(0) var<uniform> uniforms: Uniforms;
@binding(1) @group(0) var<storage, read_write> computeBuffer: array<f32>;
@binding(2) @group(0) var<storage, read_write> audioBuffer: array<f32>;
@binding(3) @group(0) var screenTexture: texture_storage_2d<bgra8unorm, write>;
@binding(4) @group(0) var<storage, read_write> phaseState: array<f32>;
`;
}

function getDefaultGraphicsShader() {
    return `// ============================================================================
// GRAPHICS SHADER - Edit this to create visuals
// ============================================================================
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_WIDTH) || gid.y >= u32(SCREEN_HEIGHT)) {
        return;
    }
    
    let uv = vec2f(gid.xy) / vec2f(SCREEN_WIDTH, SCREEN_HEIGHT);
    let t = uniforms.time;
    
    // Background pattern (dimmed)
    let mouseOffset = vec2f(uniforms.mouseX, uniforms.mouseY) * 5.0;
    let pattern = cos((uv + mouseOffset) * 10.0 + t);
    var color = vec3f(
        pattern.x * 0.15 + 0.15,
        pattern.y * 0.15 + 0.15,
        0.2
    );
    
    // Draw multi-scale waveforms
    let waveformCount = 4;
    let waveformColors = array<vec3f, 4>(
        vec3f(0.0, 1.0, 0.5),   // Cyan-green
        vec3f(1.0, 0.8, 0.0),   // Yellow
        vec3f(1.0, 0.3, 0.5),   // Pink
        vec3f(0.5, 0.5, 1.0)    // Light blue
    );
    
    for (var i = 0; i < waveformCount; i++) {
        let waveformY = (f32(i) + 0.5) / f32(waveformCount);  // Vertical position
        let zoom = pow(4.0, f32(i));  // 1x, 4x, 16x, 64x zoom
        
        // Sample audio buffer at current X position with zoom
        let samplePos = i32(uv.x * f32(SAMPLES_PER_BLOCK) / zoom) % SAMPLES_PER_BLOCK;
        let audioSample = audioBuffer[samplePos];  // Left channel (mono for simplicity)
        
        // Convert audio sample (-1 to 1) to screen space around waveformY
        let waveformHeight = 0.15 / f32(waveformCount);  // Height of each waveform strip
        let sampleY = waveformY + audioSample * waveformHeight;
        
        // Anti-aliased line drawing
        let distToWaveform = abs(uv.y - sampleY);
        let lineThickness = 0.003;
        let lineIntensity = smoothstep(lineThickness * 2.0, lineThickness * 0.5, distToWaveform);
        
        // Add waveform to color
        color += waveformColors[i] * lineIntensity * 0.8;
        
        // Draw center line for reference
        let centerDist = abs(uv.y - waveformY);
        let centerLine = smoothstep(0.002, 0.001, centerDist) * 0.2;
        color += vec3f(0.3) * centerLine;
    }
    
    // Draw scale labels (grid lines at divisions)
    for (var i = 0; i < waveformCount + 1; i++) {
        let divY = f32(i) / f32(waveformCount);
        let divDist = abs(uv.y - divY);
        let divLine = smoothstep(0.002, 0.001, divDist) * 0.3;
        color += vec3f(0.5) * divLine;
    }
    
    textureStore(screenTexture, gid.xy, vec4f(color, 1.0));
}
`;
}

function getDefaultAudioShader() {
    return `// ============================================================================
// AUDIO SHADER - Edit this to create sound
// ============================================================================
@compute @workgroup_size(128, 1, 1)
fn audio_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    let sampleIndex = i32(gid.x);
    
    // Early exit for threads beyond sample count
    if (sampleIndex >= SAMPLES_PER_BLOCK) {
        return;
    }
    
    // GPU-SIDE PHASE ACCUMULATION - Perfect timing!
    // Read persistent phase from previous block (stored on GPU)
    let basePhase = phaseState[0];
    
    // Calculate phase increment per sample using CURRENT frequency
    let phaseIncrement = uniforms.frequency * TAU / SAMPLE_RATE;
    
    // Calculate phase for THIS specific sample
    var phase = basePhase + f32(sampleIndex) * phaseIncrement;
    
    // Generate audio sample
    let sample = sin(phase) * 0.3;
    
    // Write to interleaved stereo buffer
    audioBuffer[sampleIndex] = sample;
    audioBuffer[SAMPLES_PER_BLOCK + sampleIndex] = sample;
    
    // CRITICAL: Only the very last thread updates phase state
    // This ensures one and only one write happens
    if (sampleIndex == SAMPLES_PER_BLOCK - 1) {
        // Calculate final phase after all samples
        var finalPhase = basePhase + f32(SAMPLES_PER_BLOCK) * phaseIncrement;
        
        // Wrap phase to [0, TAU) range to prevent precision loss
        // Use while loop for robust wrapping
        while (finalPhase >= TAU) {
            finalPhase -= TAU;
        }
        while (finalPhase < 0.0) {
            finalPhase += TAU;
        }
        
        phaseState[0] = finalPhase;
    }
}
`;
}

// Minimal starter code for when user adds a new tab
const MINIMAL_JS = `function init() {
    return {};
}

function enterframe(state, api) {
    // Pass mouse position to shader
    api.uniforms.setFloat(5, api.mouse.x);
    api.uniforms.setFloat(6, api.mouse.y);
}`;

const MINIMAL_AUDIO_GPU = `// Simple sine wave (GPU)
@compute @workgroup_size(128, 1, 1)
fn audio_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    let sampleIndex = i32(gid.x);
    if (sampleIndex >= SAMPLES_PER_BLOCK) { return; }
    
    let t = f32(sampleIndex) / SAMPLE_RATE;
    let sample = sin(t * 440.0 * TAU) * 0.3;
    
    audioBuffer[sampleIndex] = sample;
    audioBuffer[SAMPLES_PER_BLOCK + sampleIndex] = sample;
}`;

const MINIMAL_AUDIO_WORKLET = `// Simple sine wave (AudioWorklet)
class AudioProcessor extends AudioWorkletProcessor {
    constructor() {
        super();
        this.phase = 0;
        this.frequency = 440;
        
        // Listen for parameter updates from JS
        this.port.onmessage = (e) => {
            if (e.data.frequency !== undefined) {
                this.frequency = e.data.frequency;
            }
        };
    }
    
    process(inputs, outputs, parameters) {
        const output = outputs[0];
        
        for (let channel = 0; channel < output.length; channel++) {
            const outputChannel = output[channel];
            
            for (let i = 0; i < outputChannel.length; i++) {
                // Generate sine wave
                outputChannel[i] = Math.sin(this.phase) * 0.3;
                
                // Increment phase
                this.phase += (this.frequency * Math.PI * 2) / sampleRate;
                if (this.phase > Math.PI * 2) {
                    this.phase -= Math.PI * 2;
                }
            }
        }
        
        return true; // Keep processor alive
    }
}

registerProcessor('user-audio', AudioProcessor);`;

const DEFAULT_JS = `// This code runs alongside your WGSL shader
// Use 'state' to persist data between frames

function init() {
    // Called once when you press Play
    return {
        mouseX: 0,
        mouseY: 0,
        targetFreq: 440,
        smoothFreq: 440,
    };
}

function enterframe(state, api) {
    // Called every frame while playing
    
    // Smooth mouse movement
    state.mouseX += (api.mouse.x - state.mouseX) * 0.1;
    state.mouseY += (api.mouse.y - state.mouseY) * 0.1;
    
    // Change frequency
    state.targetFreq = 440 + (1. + state.mouseX) * 220 ;
    
    // Optional: smooth frequency changes for even cleaner sound
    state.smoothFreq += (state.targetFreq - state.smoothFreq) * 0.3;
    
    // Pass data to WGSL shader uniforms
    // Indices 5-9 map to: mouseX, mouseY, frequency, user3, user4
    api.uniforms.setFloat(5, state.mouseX);
    api.uniforms.setFloat(6, state.mouseY);
    api.uniforms.setFloat(7, state.smoothFreq);
    
    // You can use user3 and user4 for other data:
    // api.uniforms.setFloat(8, someValue);
    // api.uniforms.setFloat(9, anotherValue);
}`;

// ============================================================================
// EXAMPLES LIBRARY
// ============================================================================

const EXAMPLES = {
        grey_blob: {
        name: "Grey Blob",
        description: "imported glsl raymarching",
        tabs: ["graphics", "help"],
        graphics: `/*
//port of this shadertoy by diatribes:
void mainImage(out vec4 o, vec2 u) {
    float i, d, s, n,T = iTime;
    vec3 p,r = iResolution;
    for(o = vec4(0); i++<1e2;
        d += s = .004+.3*abs(s),
        o += 1./s)
        for (p = vec3((u-r.xy/2.)/r.y * d, d - 8.),
             p += .1*(cos(2.*T+dot(cos(3.*T+p+cos(.3*p)), p) *  p )),
             s = length(p) - 1.5,
             n = .01; n <.4; n += n )
                 s -= abs(dot(cos(T+p/n),sin(4.*p.yzx)*.2)) * n;
    o = tanh(o/8e3);
}
*/
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_WIDTH) || gid.y >= u32(SCREEN_HEIGHT)) { return; }
    let u = vec2f(gid.xy);
    let r = vec2f(SCREEN_WIDTH, SCREEN_HEIGHT);
    let T = uniforms.time;
    
    var o = vec4f(0.0);
    var d = 0.0;
    var s = 0.0;
    var p = vec3f(0.0);
    // Main ray marching loop
    for (var i = 0.0; i < 100.0; i += 1.0) {
        // Calculate p for this iteration
        p = vec3f((u - r / 2.0) / r.y * d, d - 8.0);
        p += 0.1 * (cos(2.0 * T + dot(cos(3.0 * T + p + cos(0.3 * p)), p) * p)); 
        // Calculate s (distance field)
        s = length(p) - 1.5;
        // Detail loop
        var n = 0.01;
        while (n < 0.4) {
            s -= abs(dot(cos(T + p / n), sin(4.0 * p.yzx) * 0.2)) * n;
            n += n;
        }
        // Update d and accumulate color
        d += 0.004 + 0.3 * abs(s);
        o += 1.0 / (0.004 + 0.3 * abs(s));
    }
    // Apply tone mapping
    o = tanh(o / 8000.0);
    textureStore(screenTexture, gid.xy, o);
}`,
        audio: null,
        js: null
    },
    hello_world: {
        name: "Hello World",
        description: "A simple gradient",
        tabs: ["graphics", "help"],
        graphics: `// Simple gradient - your first shader!
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_WIDTH) || gid.y >= u32(SCREEN_HEIGHT)) {
        return;
    }
    
    let uv = vec2f(gid.xy) / vec2f(SCREEN_WIDTH, SCREEN_HEIGHT);
    let color = vec3f(uv.x, uv.y, 0.5);
    
    textureStore(screenTexture, gid.xy, vec4f(color, 1.0));
}`,
        audio: null,
        js: null
    },
    
    animated_pattern: {
        name: "Animated Pattern",
        description: "Time-based animation",
        tabs: ["graphics"],
        graphics: `// Animated pattern using time
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_WIDTH) || gid.y >= u32(SCREEN_HEIGHT)) {
        return;
    }
    
    let uv = vec2f(gid.xy) / vec2f(SCREEN_WIDTH, SCREEN_HEIGHT);
    let t = uniforms.time;
    
    // Rotating pattern
    let angle = atan2(uv.y - 0.5, uv.x - 0.5);
    let radius = length(uv - 0.5);
    let pattern = sin(angle * 5.0 + t) * cos(radius * 20.0 - t * 2.0);
    
    let color = vec3f(
        pattern * 0.5 + 0.5,
        sin(t * 0.5) * 0.5 + 0.5,
        cos(t * 0.3) * 0.5 + 0.5
    );
    
    textureStore(screenTexture, gid.xy, vec4f(color, 1.0));
}`,
        audio: null,
        js: null
    },
    
    mouse_interactive: {
        name: "Mouse Interactive",
        description: "Mouse controls the pattern",
        tabs: ["graphics", "js"],
        graphics: `// Mouse-controlled visuals
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_WIDTH) || gid.y >= u32(SCREEN_HEIGHT)) {
        return;
    }
    
    let uv = vec2f(gid.xy) / vec2f(SCREEN_WIDTH, SCREEN_HEIGHT);
    let mouse = vec2f(uniforms.mouseX, 1.0-uniforms.mouseY);
    let t = uniforms.time;
    
    // Distance from mouse
    let dist = length(uv - mouse);
    
    // Ripple effect
    let ripple = sin(dist * 20.0 - t * 3.0) * 0.5 + 0.5;
    
    // Color based on distance and time
    let color = vec3f(
        ripple * (1.0 - dist),
        dist,
        sin(t + dist * 5.0) * 0.5 + 0.5
    );
    
    textureStore(screenTexture, gid.xy, vec4f(color, 1.0));
}`,
        audio: null,
        js: `function init() {
    return {
        mouseX: 0.5,
        mouseY: 0.5,
    };
}

function enterframe(state, api) {
    // Smooth mouse tracking
    state.mouseX += (api.mouse.x - state.mouseX) * 0.1;
    state.mouseY += (api.mouse.y - state.mouseY) * 0.1;
    
    api.uniforms.setFloat(5, state.mouseX);
    api.uniforms.setFloat(6, state.mouseY);
}`
    },
    
    simple_tone: {
        name: "Simple Tone (AudioWorklet)",
        description: "Basic audio synthesis with AudioWorklet",
        tabs: ["graphics", "audio", "js"],
        graphics: `// Visualize the frequency
@compute @workgroup_size(8, 8, 1)
fn graphics_main(@builtin(global_invocation_id) gid: vec3<u32>) {
    if (gid.x >= u32(SCREEN_WIDTH) || gid.y >= u32(SCREEN_HEIGHT)) {
        return;
    }
    
    let uv = vec2f(gid.xy) / vec2f(SCREEN_WIDTH, SCREEN_HEIGHT);
    let freq = uniforms.frequency;
    
    // Frequency visualization
    let normalizedFreq = (freq - 220.0) / 660.0;  // Range: 220-880 Hz
    let freqLine = smoothstep(0.02, 0.01, abs(uv.y - normalizedFreq));
    
    // Background gradient
    var color = vec3f(uv.x * 0.2, uv.y * 0.2, 0.3);
    
    // Frequency indicator line
    color += vec3f(0.0, 1.0, 0.5) * freqLine;
    
    // Mouse position indicator
    let mouseDist = length(uv - vec2f(uniforms.mouseX, uniforms.mouseY));
    let mouseCircle = smoothstep(0.05, 0.04, mouseDist);
    color += vec3f(1.0, 0.5, 0.0) * mouseCircle;
    
    textureStore(screenTexture, gid.xy, vec4f(color, 1.0));
}`,
        audio: `// AudioWorklet sine wave synthesizer
class AudioProcessor extends AudioWorkletProcessor {
    constructor() {
        super();
        this.phase = 0;
        this.frequency = 440;
        
        // Listen for frequency updates from JS
        this.port.onmessage = (e) => {
            if (e.data.frequency !== undefined) {
                this.frequency = e.data.frequency;
            }
        };
    }
    
    process(inputs, outputs, parameters) {
        const output = outputs[0];
        
        for (let channel = 0; channel < output.length; channel++) {
            const outputChannel = output[channel];
            
            for (let i = 0; i < outputChannel.length; i++) {
                // Generate sine wave
                outputChannel[i] = Math.sin(this.phase) * 0.3;
                
                // Increment phase
                this.phase += (this.frequency * Math.PI * 2) / sampleRate;
                if (this.phase > Math.PI * 2) {
                    this.phase -= Math.PI * 2;
                }
            }
        }
        
        return true; // Keep processor alive
    }
}

registerProcessor('user-audio', AudioProcessor);`,
        js: `function init() {
    return {
        mouseX: 0.5,
        mouseY: 0.5,
        frequency: 440,
    };
}

function enterframe(state, api) {
    state.mouseX += (api.mouse.x - state.mouseX) * 0.1;
    state.mouseY += (api.mouse.y - state.mouseY) * 0.1;
    
    // Mouse X controls frequency (220-880 Hz)
    state.frequency = 220 + state.mouseX * 660;
    
    // Send frequency to AudioWorklet
    api.audio.send({ frequency: state.frequency });
    
    // Also set shader uniforms for visualization
    api.uniforms.setFloat(5, state.mouseX);
    api.uniforms.setFloat(6, state.mouseY);
    api.uniforms.setFloat(7, state.frequency);
}`
    },
    
    waveform_viz: {
        name: "Waveform Visualizer",
        description: "Multi-scale audio visualization (complex)",
        tabs: ["graphics", "audio", "js", "boilerplate"],
        graphics: getDefaultGraphicsShader(),
        audio: getDefaultAudioShader(),
        js: DEFAULT_JS
    }
};

function getHelpContent() {
    return `WEBGPU COMPUTE SHADER EDITOR - QUICK START GUIDE
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

OVERVIEW
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
This is a live WebGPU compute shader editor with real-time graphics and audio
output. You write WGSL shaders that run on your GPU to generate both visuals
and audio simultaneously.

EDITOR TABS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
üìÑ BOILERPLATE - Auto-generated shader setup (read-only)
   Contains all uniforms, buffers, and constants. Updated when settings change.

üé® GRAPHICS - Your graphics shader code
   Entry point: graphics_main(@builtin(global_invocation_id) id: vec3<u32>)
   Write to: textureOutput (512x512 RGBA8)
   Workgroup size: 8x8x1 (optimized for 2D rendering)

üîä AUDIO - Your audio synthesis shader code
   Entry point: audio_main(@builtin(global_invocation_id) id: vec3<u32>)
   Write to: audioBuffer (stereo interleaved)
   Workgroup size: 128x1x1 (optimized for 1D audio)
   Phase accumulation handled on GPU for smooth frequency changes

‚ö° JAVASCRIPT - Runtime control code
   init() - Called once when you press Play
   enterframe(state, api) - Called every visual frame (~60 FPS)
   Use this to animate uniforms, respond to mouse input, etc.

‚ùì HELP - This guide + WGSL cheatsheet

CONTROLS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚ñ∂/‚è∏ - Play/Pause audio and shader execution
‚ü≥ - Reload shader (also: F5 or Ctrl+S in any editor)
Volume Slider - Control audio output volume
Ctrl+Space - Toggle play/pause from any editor

AVAILABLE UNIFORMS (read-only in your shaders)
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
struct Uniforms {
    time: f32,              // Total elapsed time in seconds
    audioCurrentTime: f32,  // Web Audio API current time
    audioPlayTime: f32,     // Time since playback started
    audioFractTime: f32,    // Fractional part of audio time
    audioFrame: u32,        // Current audio block number
    mouseX: f32,            // Mouse X position [0, 1] (set from JS)
    mouseY: f32,            // Mouse Y position [0, 1] (set from JS)
    frequency: f32,         // Audio frequency in Hz (set from JS)
    user3: f32,             // Custom uniform 3 (set from JS)
    user4: f32,             // Custom uniform 4 (set from JS)
}

Access in shaders: uniforms.time, uniforms.mouseX, etc.

AVAILABLE BUFFERS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
@group(0) @binding(1) var<storage, read_write> computeBuffer: array<f32>;
  - 64KB shared buffer for passing data between graphics and audio passes

@group(0) @binding(2) var textureOutput: texture_storage_2d<rgba8unorm, write>;
  - 512x512 texture for graphics output

@group(0) @binding(3) var<storage, read_write> audioBuffer: array<f32>;
  - Stereo audio buffer (interleaved L/R channels)
  - Size depends on sample rate (typically 2205 or 2400 samples per block)

@group(0) @binding(4) var<storage, read_write> phaseState: array<f32>;
  - Single float for persistent phase accumulation (audio synthesis)

JAVASCRIPT API
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
In your enterframe() function, you have access to:

api.time - Current time in seconds
api.audioFrame - Current audio block number
api.mouse.x, api.mouse.y - Mouse position [0, 1]
api.uniforms.setFloat(index, value) - Set uniform values:
  - Index 5: mouseX
  - Index 6: mouseY
  - Index 7: frequency (Hz)
  - Index 8: user3
  - Index 9: user4

TIPS & TRICKS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚Ä¢ The audio pass runs at ~20 FPS (every 0.05 seconds by default)
‚Ä¢ The graphics pass runs at ~60 FPS (every visual frame)
‚Ä¢ Use computeBuffer to visualize audio data in your graphics shader
‚Ä¢ Phase accumulation for audio happens on GPU - no need to manage it in JS
‚Ä¢ Smooth frequency changes in JS for cleaner audio (see default JS code)
‚Ä¢ Use the audioBuffer in graphics_main to visualize waveforms
‚Ä¢ Press Ctrl+S or F5 in any editor to quickly reload your shader

COMMON PATTERNS
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
Graphics: Distance field rendering, raymarching, cellular automata
Audio: Additive synthesis, FM synthesis, wavetable synthesis
Combined: Reactive visuals driven by audio parameters

PERFORMANCE
‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ
‚Ä¢ Workgroup sizes are optimized: 8x8x1 for graphics, 128x1x1 for audio
‚Ä¢ Avoid divergent branches in hot loops
‚Ä¢ Use shared memory (var<workgroup>) for local collaboration
‚Ä¢ Remember: This all runs on your GPU in parallel!


‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê
WGSL LANGUAGE CHEATSHEET
‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê

` + `// Assignment and declaration with let, var, const - All three support type inference
const A = 5u;           // const for compile time constants
let B = 5.0;            // let for immutable values that wont change
var C = vec3(1.0);      // var for mutable values, loop counters etc
// var is less efficient, use let unless you have to use var
// All three support type specifiers
const D:u32 = 5u; let E:f32 = 5.0; var F:vec3<f32> = vec3(1.0);
// var only - optional assignment, mandatory type
var G:f32;  G = 5.0;

//Scalar Types
var a: bool = true;
var b: i32 = -42;           // 32-bit signed integer
var c: u32 = 42u;           // 32-bit unsigned integer
var d: f32 = 3.14f;         // 32-bit float
var e: f16 = 1.5h;          // 16-bit float (requires extension)
//Vector Types
var v2f: vec2<f32> = vec2(1.0, 2.0);
var v3f: vec3<f32> = vec3(1.0, 2.0, 3.0);
var v4f: vec4<f32> = vec4(1.0, 2.0, 3.0, 4.0);
var v2i: vec2<i32> = vec2<i32>(1, 2);
var v3u: vec3<u32> = vec3<u32>(1u, 2u, 3u);
var v4b: vec4<bool> = vec4<bool>(true, false, true, false);
// Swizzling is read only/right hand side, unless its single component
var xy: vec2<f32> = v4f.xy;
var bgr: vec3<f32> = v4f.bgr;
var wzyx: vec4<f32> = v4f.wzyx;
//Matrix Types
var m2x2: mat2x2<f32> = mat2x2<f32>(1.0, 0.0, 0.0, 1.0);
var m3x3: mat3x3<f32> = mat3x3<f32>(/* 9 values */);
var m4x4: mat4x4<f32> = mat4x4<f32>(/* 16 values */);
// Non-square matrices
var m2x3: mat2x3<f32>;  // 2 columns, 3 rows
var m3x2: mat3x2<f32>;  // 3 columns, 2 rows
var m2x4: mat2x4<f32>;
var m4x2: mat4x2<f32>;
var m3x4: mat3x4<f32>;
var m4x3: mat4x3<f32>;
// Access
var col: vec3<f32> = m3x3[0];      // First column
var element: f32 = m3x3[1][2];     // Column 1, row 2
//Atomic Types
var<storage, read_write> atomic_val: atomic<i32>;
var<storage, read_write> atomic_uval: atomic<u32>;
//Array Types
// Fixed-size arrays
var arr: array<f32, 4> = array<f32, 4>(1.0, 2.0, 3.0, 4.0);
var arr2: array<vec3<f32>, 2>;
// Runtime-sized arrays (only in storage buffers, must be last member)
struct Buffer {
    data: array<f32>  // Runtime-sized
}
//Structs
struct MyStruct {
    position: vec3<f32>,
    @align(16) color: vec4<f32>,  // Explicit alignment
    @size(32) value: f32,          // Explicit size
    count: u32,
}
var s: MyStruct = MyStruct(
    vec3(0.0, 0.0, 0.0),
    vec4(1.0, 0.0, 0.0, 1.0),
    42.0,
    10u
);

// Access
var pos: vec3<f32> = s.position;
s.count = 20u;
Storage Qualifiers & Address Spaces
// Function scope (default)
var local_var: f32;

// Uniform buffer (read-only)
@group(0) @binding(0) var<uniform> uniforms: MyUniforms;

// Storage buffer (read or read_write)
@group(0) @binding(1) var<storage, read> input: Buffer;
@group(0) @binding(2) var<storage, read_write> output: Buffer;

// Workgroup shared memory
var<workgroup> shared_data: array<f32, 256>;

// Private (per-invocation)
var<private> private_var: f32;
//Math Operators
// Arithmetic
var add = a + b;
var sub = a - b;
var mul = a * b;
var div = a / b;
var mod = a % b;  // Integers only
var neg = -a;

// Compound assignment
a += b;
a -= b;
a *= b;
a /= b;
a %= b;  // Integers only

// Comparison
var eq = a == b;
var ne = a != b;
var lt = a < b;
var le = a <= b;
var gt = a > b;
var ge = a >= b;

// Logical
var and = a && b;
var or = a || b;
var not = !a;

// Bitwise (integers only)
var bit_and = a & b;
var bit_or = a | b;
var bit_xor = a ^ b;
var bit_not = ~a;
var shift_left = a << b;
var shift_right = a >> b;

// Compound assignment 2 (ints only)
a &= 5;   // a = a & 5
a |= 5;   // a = a | 5
a ^= 5;   // a = a ^ 5
a <<= 2;  // a = a << 2
a >>= 2;  // a = a >> 2

// Vector/Matrix operations
var v_add = v1 + v2;           // Component-wise
var v_mul = v1 * 2.0;          // Scalar multiplication
var dot_prod = dot(v1, v2);    // Dot product
var cross_prod = cross(v1, v2); // Cross product (vec3 only)
var m_mul = m1 * m2;           // Matrix multiplication
var mv_mul = m * v;            // Matrix-vector multiplication
//Built-in Functions (Compute Shader Safe)
//Math Functions
// Basic math
abs(x)                  // Absolute value
sign(x)                 // Sign (-1, 0, or 1)
floor(x)                // Round down
ceil(x)                 // Round up
round(x)                // Round to nearest
trunc(x)                // Truncate decimal
fract(x)                // Fractional part
modf(x)                 // Split to integer and fractional (returns struct)
clamp(x, min, max)      // Clamp to range
min(a, b)               // Minimum
max(a, b)               // Maximum
mix(a, b, t)            // Linear interpolation: a*(1-t) + b*t
step(edge, x)           // 0 if x < edge, else 1
smoothstep(low, high, x) // Smooth interpolation
saturate(x)             // Clamp to [0, 1]

// Power/Exponential
pow(x, y)               // x^y
exp(x)                  // e^x
exp2(x)                 // 2^x
log(x)                  // Natural logarithm
log2(x)                 // Base-2 logarithm
sqrt(x)                 // Square root
inverseSqrt(x)          // 1/sqrt(x)

// Trigonometry (radians)
sin(x)
cos(x)
tan(x)
asin(x)
acos(x)
atan(x)
atan2(y, x)             // atan(y/x) with correct quadrant
sinh(x)
cosh(x)
tanh(x)
asinh(x)
acosh(x)
atanh(x)
radians(degrees)
degrees(radians)

// Vector functions
dot(v1, v2)             // Dot product
cross(v1, v2)           // Cross product (vec3 only)
length(v)               // Vector length
distance(p1, p2)        // Distance between points
normalize(v)            // Unit vector
faceforward(N, I, Nref) // Flip N if needed
reflect(I, N)           // Reflect vector
refract(I, N, eta)      // Refract vector

// Matrix functions
determinant(m)          // Matrix determinant
transpose(m)            // Matrix transpose
//Bitwise Functions
countOneBits(x)         // Count set bits
reverseBits(x)          // Reverse bit order
firstLeadingBit(x)      // Position of first 1 from MSB
firstTrailingBit(x)     // Position of first 1 from LSB
extractBits(e, offset, count)  // Extract bit range
insertBits(e, newbits, offset, count) // Insert bit range
//Atomic Functions
atomicLoad(atomic_ptr)
atomicStore(atomic_ptr, value)
atomicAdd(atomic_ptr, value)
atomicSub(atomic_ptr, value)
atomicMax(atomic_ptr, value)
atomicMin(atomic_ptr, value)
atomicAnd(atomic_ptr, value)
atomicOr(atomic_ptr, value)
atomicXor(atomic_ptr, value)
atomicExchange(atomic_ptr, value)
atomicCompareExchangeWeak(atomic_ptr, compare, value)
//Data Packing/Unpacking
pack4x8snorm(v)         // vec4<f32> to u32
pack4x8unorm(v)
pack2x16snorm(v)        // vec2<f32> to u32
pack2x16unorm(v)
pack2x16float(v)

unpack4x8snorm(u)       // u32 to vec4<f32>
unpack4x8unorm(u)
unpack2x16snorm(u)      // u32 to vec2<f32>
unpack2x16unorm(u)
unpack2x16float(u)
//Other Useful Functions
all(v)                  // True if all components true
any(v)                  // True if any component true
select(f, t, cond)      // cond ? t : f (component-wise for vectors)
arrayLength(runtime_array_ptr)  // Length of runtime-sized array

// Derivative functions (NOT available in compute!)
// dpdx, dpdy, fwidth - these are fragment shader only
//Control Flow
//If/Else
if (condition) {
    // code
}

if (condition) {
    // code
} else {
    // code
}

if (condition1) {
    // code
} else if (condition2) {
    // code
} else {
    // code
}
//Switch
switch (value) {
    case 0: {
        // code
    }
    case 1, 2: {  // Multiple cases
        // code
    }
    default: {
        // code
    }
}
//For Loop
for (var i = 0u; i < 10u; i++) {
    // code
    break;     // Exit loop
    continue;  // Next iteration
}
//While Loop
while (condition) {
    // code
    break;
    continue;
}
//Loop (infinite with explicit break)
loop {
    if (condition) {
        break;
    }
    
    // continuing block is executed at the end of each iteration
    continuing {
        // Update code
        break if (exit_condition);  // Can break from continuing block
    }
}
//Array Operations
// Declaration
var arr1: array<f32, 4>;                    // Fixed size
var arr2 = array<f32, 4>(1.0, 2.0, 3.0, 4.0); // With initialization
var arr3: array<vec3<f32>, 2>;              // Array of vectors

// Multi-dimensional
var arr2d: array<array<f32, 3>, 4>;         // 4x3 array

// Access
var element = arr1[0];
arr1[1] = 5.0;

// Runtime-sized (in storage buffer)
struct DynamicBuffer {
    length: u32,
    data: array<f32>  // Must be last member
}

@group(0) @binding(0) var<storage, read> buffer: DynamicBuffer;

// Get length of runtime-sized array
var len = arrayLength(&buffer.data);

// Iteration
for (var i = 0u; i < 4u; i++) {
    arr1[i] = f32(i);
}
// Type Casting
// Scalar casting
let i = i32(3.14);      // f32 to i32
let f = f32(42);        // i32 to f32
let u = u32(-1);        // i32 to u32 (bitcast)
let b = bool(1);        // i32 to bool (non-zero = true)

// Vector casting
let v_f32 = vec3f(1.0, 2.0, 3.0);
let v_i32 = vec3i(v_f32);  // vec3f to vec3i

// Bitcast (reinterpret bits)
let bits = bitcast<u32>(3.14f);
let float_back = bitcast<f32>(bits);
//Pointers & References
fn modify(ptr: ptr<function, f32>) {
    *ptr = 10.0;  // Dereference
}

var value = 5.0;
modify(&value);  // Pass pointer

// Get pointer to array element
var arr = array<f32, 4>(1.0, 2.0, 3.0, 4.0);
let elem_ptr = &arr[2];
//Compute Shader Specifics
//Entry Point
@compute @workgroup_size(8, 8, 1)
fn main(
    @builtin(global_invocation_id) global_id: vec3<u32>,
    @builtin(local_invocation_id) local_id: vec3<u32>,
    @builtin(workgroup_id) workgroup_id: vec3<u32>,
    @builtin(local_invocation_index) local_index: u32,
    @builtin(num_workgroups) num_workgroups: vec3<u32>
) {
    // Compute shader code
}
//Workgroup Barrier
workgroupBarrier();  // Synchronize all invocations in workgroup
storageBarrier();    // Ensure memory writes are visible
//Constants
const PI: f32 = 3.14159265359;
const SIZE: u32 = 256u;

// Override constants (can be set from API)
override BLOCK_SIZE: u32 = 16u;
override THRESHOLD: f32;
//Type Aliases
alias Float = f32;
alias Vec3 = vec3<f32>;
alias MyArray = array<f32, 16>;`;
}
    // Monaco Initialization

    function initMonaco(callback) {
    require(['vs/editor/editor.main'], function() {
        // Register WGSL language
        monaco.languages.register({ id: 'wgsl' });
        monaco.languages.setLanguageConfiguration('wgsl', WGSL_LANGUAGE_CONFIG);
        monaco.languages.setMonarchTokensProvider('wgsl', WGSL_MONARCH_TOKENS);
        
        // Define custom themes to match our CSS
        monaco.editor.defineTheme('sleditor-dark', {
            base: 'vs-dark',
            inherit: true,
            rules: [],
            colors: {
                'editor.background': '#1e1e1e',
            }
        });
        
        monaco.editor.defineTheme('sleditor-light', {
            base: 'vs',
            inherit: true,
            rules: [],
            colors: {
                'editor.background': '#eeeeff',
    
                //'editor.foreground': '#182247',           // Text color
                //'editor.lineHighlightBackground': '#f0f0f0',  // Current line
                //'editorLineNumber.foreground': '#6e6e6e', // Line numbers
                //'editorCursor.foreground': '#182247',     // Cursor color
                //'editor.selectionBackground': '#a2a0f6',  // Selected text
                
            }
        });
        
        // Common editor options
        const editorOptions = {
            theme: state.isDarkMode ? 'sleditor-dark' : 'sleditor-light',
            fontSize: 13,
            minimap: { enabled: false },
            automaticLayout: true,
            scrollBeyondLastLine: false,
            wordWrap: 'on',
            tabSize: 4,
            insertSpaces: true,
            formatOnPaste: true,
            formatOnType: true,
            suggestOnTriggerCharacters: true,
            acceptSuggestionOnEnter: 'on',
            folding: true,
            foldingStrategy: 'indentation',
            renderWhitespace: 'selection',
            renderControlCharacters: false,
            scrollbar: {
                vertical: 'visible',
                horizontal: 'visible',
                useShadows: false,
                verticalHasArrows: false,
                horizontalHasArrows: false
            }
        };
        
        // Create Boilerplate editor (read-only)
        const boilerplateContainer = document.getElementById('boilerplateContainer');
        boilerplateContainer.innerHTML = '';
        state.boilerplateEditor = monaco.editor.create(boilerplateContainer, {
            ...editorOptions,
            value: getBoilerplate(),
            language: 'wgsl',
            readOnly: true,  // Read-only!
        });
        
        // Create Graphics editor
        const graphicsContainer = document.getElementById('graphicsContainer');
        graphicsContainer.innerHTML = '';  // Clear loading message
        state.graphicsEditor = monaco.editor.create(graphicsContainer, {
            ...editorOptions,
            value: EXAMPLES[state.currentExample].graphics || '',
            language: 'wgsl',
        });
        
        // Create Audio editor
        const audioContainer = document.getElementById('audioContainer');
        // Determine initial audio type from example tabs
        const exampleTabs = EXAMPLES[state.currentExample].tabs || [];
        const hasAudioTab = exampleTabs.includes('audio');
        let initialAudioCode = '';
        let initialAudioLanguage = 'wgsl';
        
        if (hasAudioTab && EXAMPLES[state.currentExample].audio) {
            initialAudioCode = EXAMPLES[state.currentExample].audio;
            initialAudioLanguage = initialAudioCode.includes('AudioWorkletProcessor') ? 'javascript' : 'wgsl';
        }
        
        state.audioEditor = monaco.editor.create(audioContainer, {
            ...editorOptions,
            value: initialAudioCode,
            language: initialAudioLanguage,
        });
        
        // Create JavaScript editor 
        const jsContainer = document.getElementById('jsEditorContainer');
        state.jsEditor = monaco.editor.create(jsContainer, {
            ...editorOptions,
            value: EXAMPLES[state.currentExample].js || MINIMAL_JS,
            language: 'javascript',
        });
        
        // Create Help editor (read-only)
        const helpContainer = document.getElementById('helpContainer');
        state.helpEditor = monaco.editor.create(helpContainer, {
            ...editorOptions,
            value: getHelpContent(),
            language: 'plaintext',
            readOnly: true,
            wordWrap: 'on',
            lineNumbers: 'off',
        });
        
        // Keyboard shortcuts for all editors
        const addShortcuts = (editor) => {
            editor.addCommand(monaco.KeyCode.F5, () => reloadShader());
            editor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.KeyS, () => reloadShader());
            editor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.Space, () => togglePlayPause());
        };
        addShortcuts(state.boilerplateEditor);
        addShortcuts(state.graphicsEditor);
        addShortcuts(state.audioEditor);
        addShortcuts(state.jsEditor);
        addShortcuts(state.helpEditor);
            
            // Set up error markers when shader compilation fails
            window.setMonacoErrors = function(errors) {
                // Calculate line offsets for each section
                // Code structure: boilerplate + '\n' + graphics + '\n' + audio
                const boilerplateLines = state.boilerplateEditor.getValue().split('\n').length;
                const graphicsLines = state.graphicsEditor.getValue().split('\n').length;
                
                // +1 for each '\n' separator
                const graphicsStartLine = boilerplateLines + 1;
                const audioStartLine = boilerplateLines + 1 + graphicsLines + 1;
                
                // Separate errors by which editor they belong to
                const boilerplateErrors = [];
                const graphicsErrors = [];
                const audioErrors = [];
                
                errors.forEach(err => {
                    const lineNum = err.lineNum || 1;
                    
                    if (lineNum < graphicsStartLine) {
                        // Error is in boilerplate
                        boilerplateErrors.push({
                            severity: monaco.MarkerSeverity.Error,
                            startLineNumber: lineNum,
                            startColumn: err.linePos || 1,
                            endLineNumber: lineNum,
                            endColumn: 1000,
                            message: err.message
                        });
                    } else if (lineNum < audioStartLine) {
                        // Error is in graphics - adjust line number
                        graphicsErrors.push({
                            severity: monaco.MarkerSeverity.Error,
                            startLineNumber: lineNum - graphicsStartLine + 1,
                            startColumn: err.linePos || 1,
                            endLineNumber: lineNum - graphicsStartLine + 1,
                            endColumn: 1000,
                            message: err.message
                        });
                    } else {
                        // Error is in audio - adjust line number
                        audioErrors.push({
                            severity: monaco.MarkerSeverity.Error,
                            startLineNumber: lineNum - audioStartLine + 2,
                            startColumn: err.linePos || 1,
                            endLineNumber: lineNum - audioStartLine + 2,
                            endColumn: 1000,
                            message: err.message
                        });
                    }
                });
                
                // Set markers in the appropriate editors
                monaco.editor.setModelMarkers(state.boilerplateEditor.getModel(), 'wgsl', boilerplateErrors);
                monaco.editor.setModelMarkers(state.graphicsEditor.getModel(), 'wgsl', graphicsErrors);
                monaco.editor.setModelMarkers(state.audioEditor.getModel(), 'wgsl', audioErrors);
            };
            
            window.clearMonacoErrors = function() {
                monaco.editor.setModelMarkers(state.boilerplateEditor.getModel(), 'wgsl', []);
                monaco.editor.setModelMarkers(state.graphicsEditor.getModel(), 'wgsl', []);
                monaco.editor.setModelMarkers(state.audioEditor.getModel(), 'wgsl', []);
                // Also clear JavaScript errors in audio editor (for AudioWorklet)
                monaco.editor.setModelMarkers(state.audioEditor.getModel(), 'javascript', []);
            };
            
            // JS error markers
            window.setJSErrors = function(errors) {
                const markers = errors.map(err => ({
                    severity: monaco.MarkerSeverity.Error,
                    startLineNumber: err.lineNum || 1,
                    startColumn: err.column || 1,
                    endLineNumber: err.lineNum || 1,
                    endColumn: err.endColumn || 1000,
                    message: err.message
                }));
                monaco.editor.setModelMarkers(state.jsEditor.getModel(), 'javascript', markers);
            };
            
            window.clearJSErrors = function() {
                monaco.editor.setModelMarkers(state.jsEditor.getModel(), 'javascript', []);
            };
            
            callback();
        });
    }
// ============================================================================
// TAB MANAGEMENT
// ============================================================================

function getTabIcon(tabName) {
    const icons = {
        boilerplate: 'üìÑ',
        graphics: 'üé®',
        audio_gpu: 'üîä',
        audio_worklet: 'üéµ',
        js: '‚ö°',
        help: '‚ùì'
    };
    return icons[tabName] || 'üìù';
}

function getTabLabel(tabName) {
    const labels = {
        boilerplate: 'Boilerplate',
        graphics: 'Graphics',
        audio_gpu: 'Audio (WGSL)',
        audio_worklet: 'Audio (Worklet)',
        js: 'JavaScript',
        help: 'Help'
    };
    return labels[tabName] || tabName;
}

function renderTabs() {
    const tabsContainer = document.getElementById('editorTabs');
    
    // Remove all tab buttons but keep the "+ Add Pass" button
    const addPassBtn = document.getElementById('addPassBtn');
    tabsContainer.innerHTML = '';
    
    // Add tab buttons
    state.activeTabs.forEach(tabName => {
        const button = document.createElement('button');
        button.className = 'editorTab' + (state.currentTab === tabName ? ' active' : '');
        button.textContent = `${getTabIcon(tabName)} ${getTabLabel(tabName)}`;
        button.onclick = () => switchTab(tabName);
        
        // Add close button for removable tabs (only graphics is mandatory)
        if (tabName !== 'graphics') {
            const closeBtn = document.createElement('span');
            closeBtn.textContent = ' √ó';
            closeBtn.style.marginLeft = '6px';
            closeBtn.style.cursor = 'pointer';
            closeBtn.onclick = (e) => {
                e.stopPropagation();
                removeTab(tabName);
            };
            button.appendChild(closeBtn);
        }
        
        tabsContainer.appendChild(button);
    });
    
    // Re-add the "+ Add Pass" button at the end
    if (addPassBtn) {
        tabsContainer.appendChild(addPassBtn);
    }
}

function switchTab(tabName) {
    if (!state.activeTabs.includes(tabName)) {
        return;
    }
    
    state.currentTab = tabName;
    
    const containers = {
        boilerplate: document.getElementById('boilerplateContainer'),
        graphics: document.getElementById('graphicsContainer'),
        audio_gpu: document.getElementById('audioContainer'),
        audio_worklet: document.getElementById('audioContainer'),  // Both audio tabs use same container
        js: document.getElementById('jsEditorContainer'),
        help: document.getElementById('helpContainer')
    };
    
    const editors = {
        boilerplate: state.boilerplateEditor,
        graphics: state.graphicsEditor,
        audio_gpu: state.audioEditor,
        audio_worklet: state.audioEditor,  // Both audio tabs use same editor
        js: state.jsEditor,
        help: state.helpEditor
    };
    
    // Hide all containers (use unique set to avoid hiding/showing same container twice)
    const uniqueContainers = [...new Set(Object.values(containers))];
    uniqueContainers.forEach(c => c.style.display = 'none');
    
    // Show selected container
    if (containers[tabName]) {
        containers[tabName].style.display = 'block';
    }
    
    // Update editor language mode for audio tabs
    if (tabName === 'audio_gpu' && state.audioEditor) {
        monaco.editor.setModelLanguage(state.audioEditor.getModel(), 'wgsl');
    } else if (tabName === 'audio_worklet' && state.audioEditor) {
        monaco.editor.setModelLanguage(state.audioEditor.getModel(), 'javascript');
    }
    
    // Force layout update
    if (editors[tabName]) {
        editors[tabName].layout();
    }
    
    // Update tab buttons
    renderTabs();
}

function addTab(tabName) {
    if (state.activeTabs.includes(tabName)) {
        switchTab(tabName);
        return;
    }
    
    // Audio tabs are mutually exclusive - remove the other if adding one
    if (tabName === 'audio_gpu' || tabName === 'audio_worklet') {
        const otherAudioTab = tabName === 'audio_gpu' ? 'audio_worklet' : 'audio_gpu';
        const otherIndex = state.activeTabs.indexOf(otherAudioTab);
        if (otherIndex !== -1) {
            state.activeTabs.splice(otherIndex, 1);
        }
        
        // Set the appropriate content based on which audio tab
        if (state.audioEditor) {
            if (tabName === 'audio_gpu') {
                state.audioEditor.setValue(MINIMAL_AUDIO_GPU);
                state.currentAudioType = 'gpu';
            } else {
                state.audioEditor.setValue(MINIMAL_AUDIO_WORKLET);
                state.currentAudioType = 'worklet';
            }
        }
    }
    
    state.activeTabs.push(tabName);
    
    // If adding a tab that the current example doesn't have, populate with minimal starter code
    const currentExample = EXAMPLES[state.currentExample];
    
    if (tabName === 'js' && !currentExample.js && state.jsEditor) {
        state.jsEditor.setValue(MINIMAL_JS);
    }
    
    renderTabs();
    switchTab(tabName);
    
    // If we just added audio or js, reload the shader/script
    if ((tabName === 'audio_gpu' || tabName === 'audio_worklet' || tabName === 'js') && state.isRunning) {
        reloadShader();
    }
}

function removeTab(tabName) {
    // Can't remove graphics (it's mandatory)
    if (tabName === 'graphics') {
        return;
    }
    
    const index = state.activeTabs.indexOf(tabName);
    if (index === -1) return;
    
    state.activeTabs.splice(index, 1);
    
    // If removing an audio tab, clear audio type and stop audio
    if (tabName === 'audio_gpu' || tabName === 'audio_worklet') {
        state.currentAudioType = null;
        if (state.isRunning) {
            stopAudio();
        }
    }
    
    // If we removed the current tab, switch to another
    if (state.currentTab === tabName) {
        switchTab(state.activeTabs[Math.max(0, index - 1)]);
    }
    
    renderTabs();
}

function showAddPassMenu() {
    const btn = document.getElementById('addPassBtn');
    
    // Create menu if it doesn't exist
    let menu = document.getElementById('addPassMenu');
    if (!menu) {
        menu = document.createElement('div');
        menu.id = 'addPassMenu';
        menu.style.cssText = `
            position: absolute;
            background: var(--bg-secondary);
            border: 1px solid var(--border-color);
            padding: 4px;
            z-index: 1000;
            display: none;
        `;
        document.body.appendChild(menu);
    }
    
    // Build menu options - all available tabs except graphics (always present)
    const availableTabs = [
        { name: 'boilerplate', label: 'üìÑ Boilerplate' },
        { name: 'audio_gpu', label: 'üîä Audio (WGSL)' },
        { name: 'audio_worklet', label: 'üéµ Audio (Worklet)' },
        { name: 'js', label: '‚ö° JavaScript' },
        { name: 'help', label: '‚ùì Help' }
    ];
    
    menu.innerHTML = '';
    
    // Check if any audio tab is active for mutual exclusion
    const hasAudioGpu = state.activeTabs.includes('audio_gpu');
    const hasAudioWorklet = state.activeTabs.includes('audio_worklet');
    
    availableTabs.forEach(tab => {
        const isActive = state.activeTabs.includes(tab.name);
        
        // Grey out the other audio tab if one is active
        const isDisabled = (tab.name === 'audio_gpu' && hasAudioWorklet) || 
                          (tab.name === 'audio_worklet' && hasAudioGpu);
        
        const option = document.createElement('div');
        option.textContent = tab.label + (isActive ? ' ‚úì' : '');
        option.style.cssText = `
            padding: 6px 12px;
            cursor: ${(isActive || isDisabled) ? 'default' : 'pointer'};
            color: ${(isActive || isDisabled) ? 'var(--text-secondary)' : 'var(--text-primary)'};
            pointer-events: ${(isActive || isDisabled) ? 'none' : 'auto'};
        `;
        option.onmouseenter = () => {
            if (!isActive && !isDisabled) {
                option.style.background = 'var(--bg-primary)';
            }
        };
        option.onmouseleave = () => {
            option.style.background = 'transparent';
        };
        option.onclick = () => {
            addTab(tab.name);
            menu.style.display = 'none';
        };
        menu.appendChild(option);
    });
    
    // Position menu below button
    const rect = btn.getBoundingClientRect();
    menu.style.left = rect.left + 'px';
    menu.style.top = (rect.bottom + 2) + 'px';
    menu.style.display = 'block';
    
    // Close menu when clicking outside
    const closeMenu = (e) => {
        if (!menu.contains(e.target) && e.target !== btn) {
            menu.style.display = 'none';
            document.removeEventListener('click', closeMenu);
        }
    };
    setTimeout(() => document.addEventListener('click', closeMenu), 0);
}
// ============================================================================
// EXAMPLE MANAGEMENT
// ============================================================================

function populateExampleSelector() {
    const selector = document.getElementById('exampleSelector');
    selector.innerHTML = '';
    
    Object.keys(EXAMPLES).forEach(exampleId => {
        const example = EXAMPLES[exampleId];
        const option = document.createElement('option');
        option.value = exampleId;
        option.textContent = example.name;
        option.title = example.description;
        selector.appendChild(option);
    });
    
    selector.value = state.currentExample;
    selector.addEventListener('change', (e) => {
        loadExample(e.target.value);
    });
}

function loadExample(exampleId) {
    const example = EXAMPLES[exampleId];
    if (!example) return;
    
    state.currentExample = exampleId;
    
    // Convert old 'audio' tab references to new audio_gpu or audio_worklet
    const updatedTabs = example.tabs.map(tab => {
        if (tab === 'audio') {
            // Detect which type of audio based on content
            if (example.audio) {
                const isWorklet = example.audio.includes('AudioWorkletProcessor') || 
                                 example.audio.includes('registerProcessor');
                return isWorklet ? 'audio_worklet' : 'audio_gpu';
            }
            // Default to worklet if no audio code provided
            return 'audio_worklet';
        }
        return tab;
    });
    
    // Update active tabs to match example
    state.activeTabs = [...updatedTabs];
    
    // Determine current audio type from tabs
    if (state.activeTabs.includes('audio_gpu')) {
        state.currentAudioType = 'gpu';
    } else if (state.activeTabs.includes('audio_worklet')) {
        state.currentAudioType = 'worklet';
    } else {
        state.currentAudioType = null;
    }
    
    // Load code into editors
    if (state.graphicsEditor) {
        state.graphicsEditor.setValue(example.graphics || '');
    }
    if (state.audioEditor && example.audio) {
        state.audioEditor.setValue(example.audio);
    }
    if (state.jsEditor) {
        state.jsEditor.setValue(example.js || MINIMAL_JS);
    }
    
    // Update UI
    renderTabs();
    
    // Switch to graphics tab by default
    if (state.activeTabs.includes('graphics')) {
        switchTab('graphics');
    } else if (state.activeTabs.length > 0) {
        switchTab(state.activeTabs[0]);
    }
    
    // Reload shader with new code, then restart and auto-play
    if (state.isRunning) {
        reloadShader().then((success) => {
            // Restart regardless (to reset state)
            restart();
            if (!state.isPlaying) {
                state.isPlaying = true;
                state.audioContext.resume();
                updatePlayPauseButton();
            }
            // Only show success message if compilation succeeded
            if (success) {
                logStatus(`Loaded example: ${example.name}`, 'success');
            }
            // If failed, error message is already shown by reloadShader()
        }).catch((err) => {
            // Error already logged in reloadShader, just don't show success message
            console.error('Failed to load example (caught):', err);
        });
    } else {
        logStatus(`Loaded example: ${example.name}`, 'success');
    }
}

function parseJSError(err, codeLines) {
    // Extract line number from error message or stack
    let lineNum = 1;
    let column = 1;
    let endColumn = 1000; // Default to end of line
    
    // Try to parse from stack trace
    const stackMatch = err.stack?.match(/<anonymous>:(\d+):(\d+)/);
    if (stackMatch) {
        // Line numbers from Function() wrapper need adjustment
        // Testing shows we need to subtract 3 to get the correct line
        const rawLineNum = parseInt(stackMatch[1]);
        lineNum = Math.max(1, rawLineNum - 3);
        column = parseInt(stackMatch[2]) || 1;
        
        // Try to determine end column by looking at the error type
        // For syntax errors, highlight a reasonable amount
        if (err instanceof SyntaxError) {
            endColumn = column + 10; // Highlight ~10 chars for syntax errors
        } else {
            // For runtime errors, try to highlight the problematic token
            endColumn = column + 20; // Highlight more for runtime errors
        }
    } else {
        // Try parsing from error message (some syntax errors include line info)
        const msgMatch = err.message?.match(/line (\d+)/i);
        if (msgMatch) {
            lineNum = parseInt(msgMatch[1]);
        }
    }
    
    // Clamp to valid range
    lineNum = Math.min(lineNum, codeLines);
    
    return { lineNum, column, endColumn, message: err.message };
}

// Default JS that runs when JS tab is not visible
const INVISIBLE_DEFAULT_JS = `
function init() {
    return { mouseX: 0.5, mouseY: 0.5 };
}

function enterframe(state, api) {
    // Smooth mouse tracking
    state.mouseX += (api.mouse.x - state.mouseX) * 0.1;
    state.mouseY += (api.mouse.y - state.mouseY) * 0.1;
    
    // Pass to uniforms
    api.uniforms.setFloat(5, state.mouseX);
    api.uniforms.setFloat(6, state.mouseY);
}
`;

function compileUserJS() {
    // If JS tab is not active, use invisible default
    const useDefault = !state.activeTabs.includes('js');
    const code = useDefault ? INVISIBLE_DEFAULT_JS : state.jsEditor.getValue();
    const codeLines = code.split('\n').length;
    
    try {
        if (!useDefault) clearJSErrors();
        
        // Create a safe scope and eval the user's code
        // We add one newline before user code to make line numbers match
        const wrappedCode = `
${code}
return { init, enterframe };
`;
        const factory = new Function(wrappedCode);
        const userFunctions = factory();
        
        state.userInit = userFunctions.init;
        state.userEnterframe = userFunctions.enterframe;
        
        // Only show success message if there's no error already showing
        if (!useDefault) {
            const statusDisplay = document.getElementById('errorDisplay');
            if (!statusDisplay.classList.contains('error')) {
                logStatus('‚úì JavaScript compiled successfully', 'success');
            }
        }
        return true;
    } catch (err) {
        if (useDefault) {
            // Default JS should never fail, but if it does, log and continue
            console.error('Default JS compilation failed:', err);
            return false;
        }
        
        const errorInfo = parseJSError(err, codeLines);
        
        setJSErrors([{
            lineNum: errorInfo.lineNum,
            column: errorInfo.column,
            endColumn: errorInfo.endColumn,
            message: errorInfo.message
        }]);
        
        // Show error with line number if available
        if (errorInfo.lineNum > 1) {
            // We have a valid line number (runtime error)
            logStatus(`‚úó JS Error (line ${errorInfo.lineNum}): ${errorInfo.message}`, 'error');
        } else {
            // No line number (syntax error - browser limitation)
            // Monaco's built-in linter should show these in real-time
            logStatus(`‚úó JS Syntax Error: ${errorInfo.message} (check editor for red underlines)`, 'error');
        }
        return false;
    }
}
    // Global error handler to catch uncaught errors from user code
    function setupErrorHandling() {
        // Store original handlers
        const originalErrorHandler = window.onerror;
        const originalConsoleError = console.error;
        const originalConsoleWarn = console.warn;
        
        // Intercept console.error to detect user code issues
        console.error = function(...args) {
            // Check if called from user code
            const stack = new Error().stack;
            if (stack && stack.includes('<anonymous>') && state.jsEditor) {
                logStatus(`‚ö† Console error from user code: ${args[0]}`, 'error');
            }
            // Always call original console.error
            originalConsoleError.apply(console, args);
        };
        
        console.warn = function(...args) {
            const stack = new Error().stack;
            if (stack && stack.includes('<anonymous>') && state.jsEditor) {
                logStatus(`‚ö† Console warning from user code: ${args[0]}`, 'info');
            }
            originalConsoleWarn.apply(console, args);
        };
        
        // Global error handler
        window.onerror = function(message, source, lineno, colno, error) {
            // Check if this is from user code (anonymous function)
            if (error && error.stack && error.stack.includes('<anonymous>')) {
                const code = state.jsEditor?.getValue();
                if (code) {
                    const codeLines = code.split('\n').length;
                    const errorInfo = parseJSError(error, codeLines);
                    
                    setJSErrors([{
                        lineNum: errorInfo.lineNum,
                        column: errorInfo.column,
                        endColumn: errorInfo.endColumn,
                        message: `Uncaught error: ${errorInfo.message}`
                    }]);
                    
                    logStatus(`‚úó Uncaught JS error (line ${errorInfo.lineNum}): ${error.message}`, 'error');
                    
                    // Pause if playing
                    if (state.isPlaying) {
                        state.isPlaying = false;
                        state.audioContext?.suspend();
                        
                        const btn = document.getElementById('playPauseBtn');
                        if (btn) {
                            btn.textContent = '‚ñ∂';
                            btn.className = 'paused';
                        }
                    }
                    
                    return true; // Prevent default error handling
                }
            }
            
            // Let editor errors through to console
            if (originalErrorHandler) {
                return originalErrorHandler(message, source, lineno, colno, error);
            }
            return false;
        };
    }

    // Initialization
    async function init() {
        setupErrorHandling();
        
        // Load theme from localStorage
        const settings = loadSettings();
        if (settings.isDarkMode !== undefined) {
            state.isDarkMode = settings.isDarkMode;
        }
        applyTheme();
        
        setupUI();
        
        // Initialize audio FIRST to get actual sample rate
        initWebAudio();
        
        // Then initialize Monaco with correct shader values
        initMonaco(async () => {
            try {
                await initWebGPU();
                await reloadShader();
                state.isRunning = true;
                
                // Auto-play from beginning
                restart();
                state.isPlaying = true;
                state.audioContext.resume();
                updatePlayPauseButton();
                
                requestAnimationFrame(render);
                logStatus('Ready! Animation playing.', 'success');
            } catch (err) {
                logStatus('Initialization failed: ' + err.message, 'error');
            }
        });
    }

    function updateCanvasSize(width, height, recompile = true) {
        state.canvasWidth = width;
        state.canvasHeight = height;
        
        // Apply pixel scaling to actual render resolution
        const renderWidth = Math.floor(width / state.pixelScale);
        const renderHeight = Math.floor(height / state.pixelScale);
        
        // Update canvas DISPLAY size first (stretches old frame - avoids black flash!)
        state.canvas.style.width = width + 'px';
        state.canvas.style.height = height + 'px';
        
        // Update resolution display
        updateResolutionDisplay();
        
        // Recompile shader with new dimensions
        if (recompile && state.isRunning) {
            reloadShader(true).then(() => {  // Pass true to skip AudioWorklet reload
                // NOW update canvas RENDER resolution (this clears canvas, but we render immediately after)
                state.canvas.width = renderWidth;
                state.canvas.height = renderHeight;
                
                // Reconfigure GPU context with new size
                if (state.gpuContext && state.gpuDevice) {
                    state.gpuContext.configure({
                        device: state.gpuDevice,
                        format: navigator.gpu.getPreferredCanvasFormat(),
                        usage: GPUTextureUsage.STORAGE_BINDING,
                    });
                }
                
                const scaleLabel = state.pixelScale === 1 ? 'High' : state.pixelScale === 2 ? 'Medium' : 'Low';
                logStatus(`Canvas: ${width}√ó${height} (${scaleLabel}: ${renderWidth}√ó${renderHeight})`, 'success');
                
                // Always render immediately to fill the canvas (paused or playing)
                if (!state.isPlaying && state.isRunning) {
                    renderSingleFrame();
                }
                // If playing, next frame will render immediately anyway
            });
        } else {
            // If not recompiling, update render size immediately
            state.canvas.width = renderWidth;
            state.canvas.height = renderHeight;
            
            if (state.gpuContext && state.gpuDevice) {
                state.gpuContext.configure({
                    device: state.gpuDevice,
                    format: navigator.gpu.getPreferredCanvasFormat(),
                    usage: GPUTextureUsage.STORAGE_BINDING,
                });
            }
        }
    }
    
    function updateResolutionDisplay() {
        const resDisplay = document.getElementById('resolutionDisplay');
        if (resDisplay) {
            const renderWidth = Math.floor(state.canvasWidth / state.pixelScale);
            const renderHeight = Math.floor(state.canvasHeight / state.pixelScale);
            resDisplay.textContent = `${renderWidth} √ó ${renderHeight} √ó ${state.pixelScale}`;
        }
    }
    
    function toggleTheme() {
        state.isDarkMode = !state.isDarkMode;
        saveSettings({ isDarkMode: state.isDarkMode });
        applyTheme();
    }
    
    function applyTheme() {
        const body = document.body;
        const btn = document.getElementById('themeToggleBtn');
        
        if (state.isDarkMode) {
            body.classList.remove('light-mode');
            if (btn) btn.textContent = 'üí°';
        } else {
            body.classList.add('light-mode');
            if (btn) btn.textContent = 'üïØ';
        }
        
        // Update Monaco editors theme
        if (window.monaco && state.graphicsEditor) {
            const theme = state.isDarkMode ? 'sleditor-dark' : 'sleditor-light';
            monaco.editor.setTheme(theme);
        }
    }
    
    function updateRenderMode() {
        const modes = [
            { 
                css: 'pixelated', 
                icon: '‚ñ¶', 
                name: 'Pixelated (Sharp)' 
            },
            { 
                css: 'auto', 
                icon: '‚ñ©', 
                name: 'Smooth (Bilinear)' 
            },
            { 
                css: 'crisp-edges', 
                icon: '‚ñ†', 
                name: 'Crisp Edges' 
            }
        ];
        
        const mode = modes[state.renderMode];
        
        // Update canvas image-rendering CSS
        // Set multiple times with different vendor prefixes for compatibility
        state.canvas.style.imageRendering = mode.css;
        state.canvas.style.imageRendering = '-moz-' + mode.css;  // Firefox
        state.canvas.style.imageRendering = '-webkit-' + mode.css;  // Safari
        state.canvas.style.imageRendering = mode.css;  // Standard (last wins)
        
        // Update icon
        const icon = document.getElementById('renderModeIcon');
        if (icon) {
            icon.textContent = mode.icon;
            icon.title = `Render mode: ${mode.name} (click to cycle)`;
        }
        
        // Force a frame render if paused to show the change immediately
        if (!state.isPlaying && state.isRunning) {
            renderSingleFrame();
        }
    }
    
    function setupCanvasResize() {
        const handle = document.getElementById('resizeHandle');
        const container = document.getElementById('canvasContainer');
        
        handle.addEventListener('mousedown', (e) => {
            e.preventDefault();
            state.isResizing = true;
            state.resizeStartX = e.clientX;
            state.resizeStartY = e.clientY;
            state.resizeStartWidth = state.canvasWidth;
            state.resizeStartHeight = state.canvasHeight;
            container.classList.add('resizing');
        });
        
        document.addEventListener('mousemove', (e) => {
            if (!state.isResizing) return;
            
            // Calculate new size (left handle means negative X increases width)
            const deltaX = state.resizeStartX - e.clientX;  // Reversed for left side
            const deltaY = e.clientY - state.resizeStartY;
            
            let newWidth = state.resizeStartWidth + deltaX;
            let newHeight = state.resizeStartHeight + deltaY;
            
            // Get browser constraints
            const maxWidth = window.innerWidth * 0.66;
            const maxHeight = window.innerHeight * 0.75;
            
            // Apply constraints
            newWidth = Math.max(256, Math.min(newWidth, maxWidth));
            newHeight = Math.max(256, Math.min(newHeight, maxHeight));
            
            // Snap to 16px grid
            newWidth = Math.round(newWidth / 16) * 16;
            newHeight = Math.round(newHeight / 16) * 16;
            
            // Update display size only (stretch existing image)
            state.canvas.style.width = newWidth + 'px';
            state.canvas.style.height = newHeight + 'px';
        });
        
        document.addEventListener('mouseup', (e) => {
            if (!state.isResizing) return;
            
            state.isResizing = false;
            container.classList.remove('resizing');
            
            // Get final size from style (what was stretched to)
            const finalWidth = parseInt(state.canvas.style.width);
            const finalHeight = parseInt(state.canvas.style.height);
            
            // Only recompile if size actually changed
            if (finalWidth !== state.canvasWidth || finalHeight !== state.canvasHeight) {
                updateCanvasSize(finalWidth, finalHeight, true);
            }
        });
    }

    function setupUI() {
        // Canvas
        state.canvas = document.getElementById('canvas');
        updateCanvasSize(state.canvasWidth, state.canvasHeight, false);
        
        // Canvas resize handle
        setupCanvasResize();

        // Play/Pause button
        document.getElementById('playPauseBtn').addEventListener('click', togglePlayPause);
        
        // Restart button
        document.getElementById('restartBtn').addEventListener('click', restart);

        // Reload button
        document.getElementById('reloadBtn').addEventListener('click', reloadShader);
        
        // Theme toggle button
        document.getElementById('themeToggleBtn').addEventListener('click', toggleTheme);
        
        // Add Pass button
        document.getElementById('addPassBtn').addEventListener('click', showAddPassMenu);

        // Volume control
        const volumeSlider = document.getElementById('volumeSlider');
        volumeSlider.addEventListener('input', (e) => {
            const vol = e.target.value / 100;
            CONFIG.volume = vol;
            if (state.gainNode) state.gainNode.gain.value = vol;
        });
        
        // Pixel scale control
        const pixelScaleSlider = document.getElementById('pixelScaleSlider');
        pixelScaleSlider.addEventListener('input', (e) => {
            const scaleIndex = parseInt(e.target.value);
            const scales = [1, 2, 3, 4, 6, 8];  // 1x, 2x, 3x, 4x, 6x, 8x
            
            state.pixelScale = scales[scaleIndex];
            
            // Update canvas with new pixel scale
            updateCanvasSize(state.canvasWidth, state.canvasHeight, true);
        });
        
        // Render mode toggle (click icon to cycle through modes)
        const renderModeIcon = document.getElementById('renderModeIcon');
        renderModeIcon.addEventListener('click', () => {
            state.renderMode = (state.renderMode + 1) % 3;
            updateRenderMode();
        });
        
        // Initialize render mode
        updateRenderMode();
        
        // Track mouse position
        document.addEventListener('mousemove', (e) => {
            const rect = state.canvas.getBoundingClientRect();
            state.mouseX = (e.clientX - rect.left) / rect.width;
            state.mouseY = 1.0 - (e.clientY - rect.top) / rect.height; // Flip Y
        });
        
        // Handle visibility change
        document.addEventListener('visibilitychange', () => {
            if (!document.hidden && state.audioContext && state.isPlaying) {
                const ctx = state.audioContext;
                state.nextAudioTime = Math.ceil(ctx.currentTime / CONFIG.audioBlockDuration) 
                                     * CONFIG.audioBlockDuration;
                state.pendingAudio = false;
                logStatus('Audio resynced after visibility change', 'info');
            }
        });
        
        // Initialize example selector
        populateExampleSelector();
        
        // Initialize tab display
        renderTabs();
    }

function togglePlayPause() {
    if (!state.audioContext || !state.isRunning) return;
    
    if (state.isPlaying) {
        // PAUSE everything
        state.audioContext.suspend();
        state.isPlaying = false;
        state.lastPauseTime = performance.now();
        logStatus('Paused', 'info');
    } else {
        // RESUME everything
        state.audioContext.resume();
        state.isPlaying = true;
        
        // Account for time spent paused
        if (state.lastPauseTime > 0) {
            state.pausedTime += performance.now() - state.lastPauseTime;
        }
        
        // Resync audio timing
        const ctx = state.audioContext;
        state.nextAudioTime = Math.ceil(ctx.currentTime / CONFIG.audioBlockDuration) 
                             * CONFIG.audioBlockDuration;
        state.pendingAudio = false;
        
        logStatus('Playing', 'success');
    }
    
    updatePlayPauseButton();
}

function updatePlayPauseButton() {
    const btn = document.getElementById('playPauseBtn');
    if (state.isPlaying) {
        btn.textContent = '‚è∏';
        btn.className = 'playing';
    } else {
        btn.textContent = '‚ñ∂';
        btn.className = 'paused';
    }
}

function restart() {
    // Reset time tracking
    const now = performance.now();
    state.startTime = now;
    state.pausedTime = 0;
    state.visualFrame = 0;
    state.audioFrame = 0;
    
    // Reset FPS tracking
    state.fps = 0;
    state.fpsFrameCount = 0;
    state.fpsLastTime = now;
    
    // If currently paused, set lastPauseTime to now so time doesn't accumulate while paused
    if (!state.isPlaying) {
        state.lastPauseTime = now;
    } else {
        state.lastPauseTime = 0;
    }
    
    // Reset GPU phase for clean audio start
    if (state.gpuDevice && state.phaseStateBuffer) {
        state.gpuDevice.queue.writeBuffer(state.phaseStateBuffer, 0, new Float32Array([0.0]));
    }
    
    // Resync audio timing
    if (state.audioContext) {
        const ctx = state.audioContext;
        state.nextAudioTime = Math.ceil(ctx.currentTime / CONFIG.audioBlockDuration) 
                             * CONFIG.audioBlockDuration;
        state.pendingAudio = false;
    }
    
    // Compile and initialize JS
    if (compileUserJS()) {
        try {
            state.userState = state.userInit ? state.userInit() : {};
            clearJSErrors();
            // Only show "Restarted" message if there's no error already showing
            const statusDisplay = document.getElementById('errorDisplay');
            if (!statusDisplay.classList.contains('error')) {
                logStatus('Restarted from beginning', 'success');
            }
        } catch (err) {
            const code = state.jsEditor?.getValue() || INVISIBLE_DEFAULT_JS;
            const codeLines = code.split('\n').length;
            const errorInfo = parseJSError(err, codeLines);
            
            if (state.jsEditor && state.activeTabs.includes('js')) {
                setJSErrors([{
                    lineNum: errorInfo.lineNum,
                    column: errorInfo.column,
                    endColumn: errorInfo.endColumn,
                    message: `Runtime error in init(): ${errorInfo.message}`
                }]);
            }
            
            logStatus(`‚úó JS init() error (line ${errorInfo.lineNum}): ${err.message}`, 'error');
        }
    }
    
    // Update display immediately to show t=0
    document.getElementById('frameCounter').textContent = '0';
    document.getElementById('timeCounter').textContent = '0.00s';
    document.getElementById('fpsCounter').textContent = '0';
    
    // If paused, render one frame to show the restart visually
    if (!state.isPlaying && state.isRunning) {
        renderSingleFrame();
    }
}

    async function initWebGPU() {
        const adapter = await navigator.gpu?.requestAdapter();
        if (!adapter) throw new Error('WebGPU not supported');

        state.gpuDevice = await adapter.requestDevice({
            requiredFeatures: ['bgra8unorm-storage'],
            requiredLimits: {
                maxBufferSize: Math.pow(2, 30),
                maxStorageBufferBindingSize: Math.pow(2, 30),
            }
        });

        state.gpuContext = state.canvas.getContext('webgpu');
        state.gpuContext.configure({
            device: state.gpuDevice,
            format: navigator.gpu.getPreferredCanvasFormat(),
            usage: GPUTextureUsage.STORAGE_BINDING,
        });

        createGPUResources();
    }

    function createGPUResources() {
        const device = state.gpuDevice;

        state.uniformBuffer = device.createBuffer({
            size: 256,
            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
        });

        state.computeBuffer = device.createBuffer({
            size: CONFIG.computeBufferSize,
            usage: GPUBufferUsage.STORAGE,
        });

        state.audioBufferGPU = device.createBuffer({
            size: DERIVED.audioBufferSize,
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
        });
        
        // Phase state buffer - persistent GPU-side phase for perfect timing
        state.phaseStateBuffer = device.createBuffer({
            size: 4,  // Single f32
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_DST,
        });
        
        // Initialize phase to 0
        device.queue.writeBuffer(state.phaseStateBuffer, 0, new Float32Array([0.0]));

        for (let i = 0; i < 2; i++) {
            state.audioBuffersReadback[i] = device.createBuffer({
                size: DERIVED.audioBufferSize,
                usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
            });
        }

        state.bindGroupLayout = device.createBindGroupLayout({
            entries: [
                { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'uniform' } },
                { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
                { binding: 2, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
                { binding: 3, visibility: GPUShaderStage.COMPUTE, storageTexture: { 
                    format: 'bgra8unorm', access: 'write-only', viewDimension: '2d' 
                }},
                { binding: 4, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
            ],
        });
    }

    function initWebAudio() {
        state.audioContext = new AudioContext();
        
        // Read actual sample rate from AudioContext
        DERIVED.sampleRate = state.audioContext.sampleRate;
        DERIVED.samplesPerBlock = Math.floor(CONFIG.audioBlockDuration * DERIVED.sampleRate);
        DERIVED.audioBufferSize = 4 * CONFIG.channels * DERIVED.samplesPerBlock;
        DERIVED.audioWorkgroups = Math.ceil(DERIVED.samplesPerBlock / 128);  // 128 threads per workgroup for audio
        
        console.log(`Audio initialized: ${DERIVED.sampleRate}Hz, ${DERIVED.samplesPerBlock} samples/block`);
        console.log(`Dispatch: Graphics 64√ó64 workgroups (8√ó8 threads), Audio ${DERIVED.audioWorkgroups}√ó1 workgroups (128 threads)`);
        
        state.gainNode = state.audioContext.createGain();
        state.gainNode.gain.value = CONFIG.volume;
        state.gainNode.connect(state.audioContext.destination);
        
        state.nextAudioTime = Math.ceil(state.audioContext.currentTime / CONFIG.audioBlockDuration) 
                             * CONFIG.audioBlockDuration;
        
        state.audioContext.suspend();
    }

    // Parse AudioWorklet errors to extract line numbers
    function parseAudioWorkletError(err, codeLines) {
        let lineNum = null;
        let column = 1;
        let endColumn = 1000;
        
        // Try multiple patterns for line number extraction
        // Pattern 1: "blob:http://localhost:5500/xxx:5:10" format (most common)
        let match = err.stack?.match(/blob:[^:]+:(\d+):(\d+)/);
        if (match) {
            lineNum = parseInt(match[1]);
            column = parseInt(match[2]);
            endColumn = column + 10;
        }
        
        // Pattern 2: Simple ":line:col" format
        if (!match) {
            match = err.stack?.match(/:(\d+):(\d+)/);
            if (match) {
                lineNum = parseInt(match[1]);
                column = parseInt(match[2]);
                endColumn = column + 10;
            }
        }
        
        // Pattern 3: "line X" in the message
        if (!lineNum) {
            match = err.message?.match(/line (\d+)/i);
            if (match) {
                lineNum = parseInt(match[1]);
            }
        }
        
        // If we still don't have a line number, return null to signal no error marker
        if (!lineNum || lineNum < 1) {
            console.warn('Could not parse line number from AudioWorklet error');
            return null;
        }
        
        // Clamp to valid range
        lineNum = Math.min(Math.max(1, lineNum), codeLines);
        
        return { lineNum, column, endColumn, message: err.message };
    }
    
    // Set AudioWorklet error markers in Monaco
    function setAudioWorkletErrors(errors) {
        const markers = errors.map(err => ({
            severity: monaco.MarkerSeverity.Error,
            startLineNumber: err.lineNum || 1,
            startColumn: err.column || 1,
            endLineNumber: err.lineNum || 1,
            endColumn: err.endColumn || 1000,
            message: err.message
        }));
        monaco.editor.setModelMarkers(state.audioEditor.getModel(), 'javascript', markers);
    }
    
    function clearAudioWorkletErrors() {
        monaco.editor.setModelMarkers(state.audioEditor.getModel(), 'javascript', []);
    }

    // AudioWorklet Management
    async function loadAudioWorklet() {
        if (!state.audioContext) return false;
        
        const audioCode = state.audioEditor.getValue();
        const codeLines = audioCode.split('\n').length;
        
        try {
            clearAudioWorkletErrors();
            
            // Note: We can't pre-validate AudioWorklet code because AudioWorkletProcessor
            // and other AudioWorklet APIs only exist in the AudioWorklet scope.
            // We'll catch errors during the actual addModule() call instead.
            
            // Disconnect and remove old worklet if exists
            if (state.audioWorkletNode) {
                state.audioWorkletNode.disconnect();
                state.audioWorkletNode = null;
            }
            
            // Generate unique processor name for each reload to avoid registration conflicts
            const processorName = 'user-audio-' + Date.now();
            
            // Replace the registerProcessor call in user's code with our unique name
            const modifiedCode = audioCode.replace(
                /registerProcessor\s*\(\s*['"]user-audio['"]\s*,/,
                `registerProcessor('${processorName}',`
            );
            
            // Create blob URL with the modified audio code
            const blob = new Blob([modifiedCode], { type: 'application/javascript' });
            const url = URL.createObjectURL(blob);
            
            // Load the module
            await state.audioContext.audioWorklet.addModule(url);
            URL.revokeObjectURL(url);
            
            // Create the worklet node with our unique processor name
            state.audioWorkletNode = new AudioWorkletNode(state.audioContext, processorName);
            state.audioWorkletNode.connect(state.gainNode);
            
            // Listen for errors from the worklet
            state.audioWorkletNode.port.onmessageerror = (event) => {
                console.error('AudioWorklet message error:', event);
                logStatus(`‚úó AudioWorklet runtime error`, 'error');
            };
            
            state.audioMode = AUDIO_MODES.WORKLET;
            return true;
        } catch (err) {
            console.error('AudioWorklet loading error:', err);
            
            // Try to parse line numbers from the error
            let lineNum = null;
            let column = 1;
            let endColumn = 1000;
            
            // Try to parse from stack trace
            // AudioWorklet errors from addModule often have format like ":30:10"
            const stackMatch = err.stack?.match(/:(\d+):(\d+)/);
            if (stackMatch) {
                lineNum = parseInt(stackMatch[1]);
                column = parseInt(stackMatch[2]);
                endColumn = column + 10;
            }
            
            if (lineNum && lineNum > 0 && lineNum <= codeLines) {
                // We got a valid line number - show marker
                setAudioWorkletErrors([{
                    lineNum,
                    column,
                    endColumn,
                    message: err.message
                }]);
                logStatus(`‚úó AudioWorklet error (line ${lineNum}): ${err.message}`, 'error');
            } else {
                // No line number available (AudioWorklet limitation)
                // Monaco's built-in JavaScript linter should still show errors in the editor
                console.warn('Could not parse line number from AudioWorklet error (browser limitation)');
                logStatus(`‚úó AudioWorklet error: ${err.message} (check editor for red underlines)`, 'error');
            }
            
            state.audioMode = AUDIO_MODES.NONE;
            return false;
        }
    }
    
    function stopAudio() {
        // Stop GPU audio
        state.audioPipeline = null;
        state.pendingAudio = false;
        
        // Stop AudioWorklet
        if (state.audioWorkletNode) {
            state.audioWorkletNode.disconnect();
            state.audioWorkletNode = null;
        }
        
        state.audioMode = AUDIO_MODES.NONE;
    }

    // Live Shader Reload - no time reset, no init() call
    async function reloadShader(isResizeOnly = false) {
    const hasAudioGpu = state.activeTabs.includes('audio_gpu');
    const hasAudioWorklet = state.activeTabs.includes('audio_worklet');
    const hasAudio = hasAudioGpu || hasAudioWorklet;
    
    // CRITICAL: Stop old audio before loading new audio
    // This prevents both audio modes from playing simultaneously
    // EXCEPTION: If this is just a resize and AudioWorklet is active, keep it running
    const isWorkletActive = state.audioMode === AUDIO_MODES.WORKLET && state.audioWorkletNode;
    const skipAudioWorkletReload = isResizeOnly && isWorkletActive && hasAudioWorklet;
    
    if (!skipAudioWorkletReload) {
        stopAudio();
    }
    
    // Compile graphics shader
    const boilerplate = getBoilerplate();
    const graphics = state.graphicsEditor.getValue();
    
    // Get audio code only if we have a GPU audio tab
    const audio = hasAudioGpu ? state.audioEditor.getValue() : '';
    const code = boilerplate + '\n' + graphics + '\n' + audio;
    
    // Update boilerplate editor
    state.boilerplateEditor.setValue(boilerplate);
    
    try {
        logStatus('Compiling...', 'info');
        clearMonacoErrors();
        
        // Compile graphics shader
        const shaderModule = state.gpuDevice.createShaderModule({ code });
        const compilationInfo = await shaderModule.getCompilationInfo();
        const errors = compilationInfo.messages.filter(m => m.type === 'error');
        
        if (errors.length > 0) {
            setMonacoErrors(errors);
            const errorMsg = errors.map(e => 
                `Line ${e.lineNum}: ${e.message}`
            ).join('\n');
            throw new Error('Shader compilation failed:\n' + errorMsg);
        }
        
        const pipelineLayout = state.gpuDevice.createPipelineLayout({
            bindGroupLayouts: [state.bindGroupLayout],
        });
        
        // Create graphics pipeline
        const newGraphicsPipeline = state.gpuDevice.createComputePipeline({
            layout: pipelineLayout,
            compute: { module: shaderModule, entryPoint: 'graphics_main' },
        });
        state.graphicsPipeline = newGraphicsPipeline;
        
        // Handle audio based on active tab type
        let audioCompileSuccess = true;
        if (hasAudioWorklet) {
            // Skip AudioWorklet reload if this is just a canvas resize
            if (skipAudioWorkletReload) {
                // AudioWorklet is still running from before, no need to reload
                audioCompileSuccess = true;
            } else {
                // Load AudioWorklet - this will always reload the code
                const workletLoaded = await loadAudioWorklet();
                if (workletLoaded) {
                    state.audioMode = AUDIO_MODES.WORKLET;
                    state.currentAudioType = 'worklet';
                } else {
                    // AudioWorklet failed to load - error already logged by loadAudioWorklet
                    audioCompileSuccess = false;
                }
            }
        } else if (hasAudioGpu) {
            // Create GPU audio pipeline
            const newAudioPipeline = state.gpuDevice.createComputePipeline({
                layout: pipelineLayout,
                compute: { module: shaderModule, entryPoint: 'audio_main' },
            });
            state.audioPipeline = newAudioPipeline;
            state.audioMode = AUDIO_MODES.GPU;
            state.currentAudioType = 'gpu';
        } else {
            // No audio - already stopped above
            state.currentAudioType = null;
        }
        
        // Compile JS
        const jsCompileSuccess = compileUserJS();
        
        // Show appropriate status message
        if (audioCompileSuccess && jsCompileSuccess) {
            const audioStatus = hasAudioWorklet ? ' (AudioWorklet)' : hasAudioGpu ? ' (GPU Audio)' : '';
            logStatus('‚úì Compiled successfully!' + audioStatus, 'success');
            return true; // Success
        } else if (!audioCompileSuccess) {
            // Audio error already logged in loadAudioWorklet, don't override
            return false; // Failed
        } else if (!jsCompileSuccess) {
            // JS error already logged by compileUserJS with line number, don't override
            return false; // Failed
        }
        
    } catch (err) {
        logStatus('‚úó ' + err.message, 'error');
        return false; // Failed
    }
    
    return true; // Success by default
}

    function logStatus(message, type = 'info') {
        const display = document.getElementById('errorDisplay');
        display.textContent = message;
        display.className = type;
    }

    // Render a single frame (used when paused, e.g., after restart)
    function renderSingleFrame() {
        if (!state.isRunning || !state.gpuDevice) return;
        
        const device = state.gpuDevice;
        const ctx = state.audioContext;
        
        // Calculate current elapsed time (accounting for pauses)
        // If paused, freeze time at the pause moment
        let rawTime;
        if (!state.isPlaying && state.lastPauseTime > 0) {
            // Use the frozen time from when we paused
            rawTime = state.lastPauseTime;
        } else {
            rawTime = performance.now();
        }
        const elapsedMs = rawTime - state.startTime - state.pausedTime;
        const elapsedSec = elapsedMs * 0.001;
        
        const uniformData = new ArrayBuffer(256);
        const uniformF32 = new Float32Array(uniformData);
        const uniformI32 = new Int32Array(uniformData);
        
        uniformF32[UNIFORM_STRUCT.time] = elapsedSec;
        uniformF32[UNIFORM_STRUCT.audioCurrentTime] = ctx.currentTime;
        uniformF32[UNIFORM_STRUCT.audioPlayTime] = state.nextAudioTime;
        uniformF32[UNIFORM_STRUCT.audioFractTime] = state.nextAudioTime % 1;
        uniformI32[UNIFORM_STRUCT.audioFrame] = state.audioFrame;
        
        // Call enterframe with current elapsed time
        if (state.userEnterframe) {
            try {
                const api = {
                    time: elapsedSec,
                    deltaTime: 0,
                    mouse: { x: state.mouseX, y: state.mouseY },
                    sampleRate: DERIVED.sampleRate,
                    samplesPerBlock: DERIVED.samplesPerBlock,
                    audioFrame: state.audioFrame,
                    audioBlockGenerated: false,
                    uniforms: {
                        setFloat: (index, value) => {
                            if (index >= 5 && index < 20) {
                                uniformF32[index] = value;
                            }
                        },
                        setInt: (index, value) => {
                            if (index >= 5 && index < 20) {
                                uniformI32[index] = value;
                            }
                        }
                    },
                    audio: {
                        send: (data) => {
                            if (state.audioWorkletNode && state.audioWorkletNode.port) {
                                state.audioWorkletNode.port.postMessage(data);
                            }
                        },
                        setParam: (name, value) => {
                            if (state.audioWorkletNode && state.audioWorkletNode.parameters && state.audioWorkletNode.parameters.has(name)) {
                                state.audioWorkletNode.parameters.get(name).value = value;
                            }
                        }
                    }
                };
                state.userEnterframe(state.userState, api);
            } catch (err) {
                // Silently fail for single frame render
                console.warn('enterframe error during single frame render:', err);
            }
        }
        
        device.queue.writeBuffer(state.uniformBuffer, 0, uniformData);
        
        const textureView = state.gpuContext.getCurrentTexture().createView();
        const bindGroup = device.createBindGroup({
            layout: state.bindGroupLayout,
            entries: [
                { binding: 0, resource: { buffer: state.uniformBuffer } },
                { binding: 1, resource: { buffer: state.computeBuffer } },
                { binding: 2, resource: { buffer: state.audioBufferGPU } },
                { binding: 3, resource: textureView },
                { binding: 4, resource: { buffer: state.phaseStateBuffer } },
            ],
        });
        
        const encoder = device.createCommandEncoder();
        const pass = encoder.beginComputePass();
        
        // Only render graphics (no audio)
        pass.setPipeline(state.graphicsPipeline);
        pass.setBindGroup(0, bindGroup);
        pass.dispatchWorkgroups(
            Math.ceil(state.canvasWidth / state.pixelScale / 8),
            Math.ceil(state.canvasHeight / state.pixelScale / 8),
            1
        );
        
        pass.end();
        device.queue.submit([encoder.finish()]);
    }

    // Render Loop
    function render(rawTime) {
        if (!state.isRunning) return;
        
        // Only render when playing
        if (!state.isPlaying) {
            requestAnimationFrame(render);
            return;
        }

        const device = state.gpuDevice;
        const ctx = state.audioContext;
        
        // Calculate elapsed time (accounting for pauses)
        const elapsedMs = rawTime - state.startTime - state.pausedTime;
        const elapsedSec = elapsedMs * 0.001;
        
        // Increment visual frame counter
        state.visualFrame++;
        
        // Calculate FPS (update every second)
        state.fpsFrameCount++;
        if (rawTime - state.fpsLastTime >= 1000) {
            state.fps = Math.round(state.fpsFrameCount * 1000 / (rawTime - state.fpsLastTime));
            state.fpsFrameCount = 0;
            state.fpsLastTime = rawTime;
            document.getElementById('fpsCounter').textContent = state.fps;
        }
        
        document.getElementById('frameCounter').textContent = state.visualFrame;
        document.getElementById('timeCounter').textContent = elapsedSec.toFixed(2) + 's';

        const uniformData = new ArrayBuffer(256);
        const uniformF32 = new Float32Array(uniformData);
        const uniformI32 = new Int32Array(uniformData);
        
        uniformF32[UNIFORM_STRUCT.time] = elapsedSec;
        uniformF32[UNIFORM_STRUCT.audioCurrentTime] = ctx.currentTime;
        uniformF32[UNIFORM_STRUCT.audioPlayTime] = state.nextAudioTime;
        uniformF32[UNIFORM_STRUCT.audioFractTime] = state.nextAudioTime % 1;
        uniformI32[UNIFORM_STRUCT.audioFrame] = state.audioFrame;
        
    // Call user's enterframe with API
    if (state.isPlaying && state.userEnterframe) {
        try {
            const api = {
                time: elapsedSec,
                deltaTime: 0.016, // Could calculate real delta
                mouse: { x: state.mouseX, y: state.mouseY },
                sampleRate: DERIVED.sampleRate,
                samplesPerBlock: DERIVED.samplesPerBlock,
                audioFrame: state.audioFrame,
                audioMode: state.audioMode,
                audioBlockGenerated: false,  // Will be set to true if audio was generated this frame
                uniforms: {
                    setFloat: (index, value) => {
                        if (index >= 5 && index < 20) {
                            uniformF32[index] = value;
                        }
                    },
                    setInt: (index, value) => {
                        if (index >= 5 && index < 20) {
                            uniformI32[index] = value;
                        }
                    }
                },
                audio: {
                    send: (data) => {
                        if (state.audioWorkletNode && state.audioWorkletNode.port) {
                            state.audioWorkletNode.port.postMessage(data);
                        }
                    },
                    setParam: (name, value) => {
                        if (state.audioWorkletNode && state.audioWorkletNode.parameters && state.audioWorkletNode.parameters.has(name)) {
                            state.audioWorkletNode.parameters.get(name).value = value;
                        }
                    }
                }
            };
            state.userEnterframe(state.userState, api);
        } catch (err) {
            // Pause playback on runtime error
            state.isPlaying = false;
            state.audioContext.suspend();
            updatePlayPauseButton();
            
            // Show error with line number (only if JS tab is visible)
            if (state.activeTabs.includes('js')) {
                const code = state.jsEditor.getValue();
                const codeLines = code.split('\n').length;
                const errorInfo = parseJSError(err, codeLines);
                
                setJSErrors([{
                    lineNum: errorInfo.lineNum,
                    column: errorInfo.column,
                    endColumn: errorInfo.endColumn,
                    message: `Runtime error in enterframe(): ${errorInfo.message}`
                }]);
                
                logStatus(`‚úó JS enterframe() error (line ${errorInfo.lineNum}): ${err.message}`, 'error');
            } else {
                logStatus(`‚úó JS runtime error: ${err.message}`, 'error');
            }
            console.error('enterframe error:', err);
        }
    }
    
    device.queue.writeBuffer(state.uniformBuffer, 0, uniformData);

        const textureView = state.gpuContext.getCurrentTexture().createView();
        const bindGroup = device.createBindGroup({
            layout: state.bindGroupLayout,
            entries: [
                { binding: 0, resource: { buffer: state.uniformBuffer } },
                { binding: 1, resource: { buffer: state.computeBuffer } },
                { binding: 2, resource: { buffer: state.audioBufferGPU } },
                { binding: 3, resource: textureView },
                { binding: 4, resource: { buffer: state.phaseStateBuffer } },
            ],
        });

        // Check if we need to generate GPU audio THIS frame (only for GPU audio mode)
        const needsGPUAudio = state.isPlaying && 
                              state.audioMode === AUDIO_MODES.GPU &&
                              state.audioPipeline &&
                              ctx.currentTime >= state.nextAudioTime - CONFIG.audioBlockDuration && 
                              !state.pendingAudio;

        const encoder = device.createCommandEncoder();
        const pass = encoder.beginComputePass();
        
        // AUDIO PASS FIRST - Only for GPU audio mode!
        if (needsGPUAudio) {
            pass.setPipeline(state.audioPipeline);
            pass.setBindGroup(0, bindGroup);
            pass.dispatchWorkgroups(
                Math.ceil(DERIVED.samplesPerBlock / 128),  // e.g., ceil(4800/128) = 38 workgroups
                1,
                1
            );
        }
        
        // GRAPHICS PASS SECOND - Reads audio data from buffer
        // 8√ó8 workgroups for optimal 2D texture access
        pass.setPipeline(state.graphicsPipeline);
        pass.setBindGroup(0, bindGroup);
        pass.dispatchWorkgroups(
            Math.ceil(state.canvasWidth / state.pixelScale / 8),   // Scaled workgroups X
            Math.ceil(state.canvasHeight / state.pixelScale / 8),  // Scaled workgroups Y
            1
        );
        
        pass.end();

        if (needsGPUAudio) {
            state.pendingAudio = true;
            
            const readbackBuffer = state.audioBuffersReadback[state.readbackIndex];
            encoder.copyBufferToBuffer(
                state.audioBufferGPU, 0,
                readbackBuffer, 0,
                DERIVED.audioBufferSize
            );
            
            device.queue.submit([encoder.finish()]);
            
            readbackBuffer.mapAsync(GPUMapMode.READ).then(() => {
                playAudioBlock(readbackBuffer);
                state.readbackIndex = 1 - state.readbackIndex;
                state.pendingAudio = false;
            }).catch(err => {
                console.error('Audio readback failed:', err);
                state.pendingAudio = false;
            });
        } else {
            device.queue.submit([encoder.finish()]);
        }

        requestAnimationFrame(render);
    }

    function playAudioBlock(readbackBuffer) {
        const ctx = state.audioContext;
        const audioData = new Float32Array(readbackBuffer.getMappedRange());
        
        const audioBuffer = ctx.createBuffer(
            CONFIG.channels,
            DERIVED.samplesPerBlock,
            DERIVED.sampleRate
        );
        
        for (let ch = 0; ch < CONFIG.channels; ch++) {
            const channelData = audioBuffer.getChannelData(ch);
            const offset = ch * DERIVED.samplesPerBlock;
            for (let i = 0; i < DERIVED.samplesPerBlock; i++) {
                channelData[i] = audioData[offset + i];
            }
        }
        
        readbackBuffer.unmap();
        
        const source = ctx.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(state.gainNode);
        source.start(state.nextAudioTime);
        
        state.nextAudioTime += CONFIG.audioBlockDuration;
        state.audioFrame++;
    }

    // ============================================================================
    // Start
    // ============================================================================
    window.addEventListener('load', init);
    </script>
</body>
</html>