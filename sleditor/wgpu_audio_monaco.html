<!doctype html>
<html>
<head>
    <meta charset="utf-8">
    <title>WGSL Editor with Monaco</title>
    <style>
        body {
            margin: 0;
            padding: 10px;
            background: #1e1e1e;
            color: #d4d4d4;
            font-family: system-ui, -apple-system, sans-serif;
        }
        #container {
            display: flex;
            gap: 10px;
            height: 98vh;
        }
        #leftPanel {
            flex: 1;
            display: flex;
            flex-direction: column;
            gap: 10px;
            min-width: 400px;
        }
        #rightPanel {
            display: flex;
            flex-direction: column;
            gap: 10px;
        }
        #editorContainer {
            flex: 1;
            border: 1px solid #3c3c3c;
            border-radius: 4px;
            overflow: hidden;
            position: relative;
        }
        #loadingMessage {
            position: absolute;
            top: 50%;
            left: 50%;
            transform: translate(-50%, -50%);
            color: #858585;
            font-size: 14px;
        }
        #controls {
            display: flex;
            gap: 10px;
            align-items: center;
            flex-wrap: wrap;
        }
        button {
            background: #0e639c;
            color: white;
            border: none;
            padding: 8px 16px;
            border-radius: 4px;
            cursor: pointer;
            font-size: 14px;
            font-weight: 500;
            transition: background 0.2s;
        }
        button:hover {
            background: #1177bb;
        }
        button.playing {
            background: #16825d;
        }
        button.playing:hover {
            background: #1a9870;
        }
        button.paused {
            background: #c5a332;
        }
        button.paused:hover {
            background: #d4b547;
        }
        #errorDisplay {
            background: #1e1e1e;
            border: 1px solid #3c3c3c;
            border-radius: 4px;
            padding: 10px;
            font-family: 'Consolas', 'Monaco', 'Courier New', monospace;
            font-size: 12px;
            min-height: 60px;
            max-height: 120px;
            overflow-y: auto;
        }
        .error { color: #f48771; }
        .success { color: #4ec9b0; }
        .info { color: #9cdcfe; }
        #canvas {
            border: 1px solid #3c3c3c;
            border-radius: 4px;
            image-rendering: pixelated;
        }
        .hint {
            color: #858585;
            font-size: 12px;
        }
        .statusBadge {
            display: inline-block;
            padding: 2px 8px;
            border-radius: 3px;
            font-size: 11px;
            font-weight: bold;
        }
        .statusBadge.playing {
            background: #16825d;
            color: white;
        }
        .statusBadge.paused {
            background: #c5a332;
            color: white;
        }
    </style>
</head>
<body>
    <div id="container">
        <div id="leftPanel">
            <div id="controls">
                <button id="playPauseBtn" class="paused">▶ Play</button>
                <button id="reloadBtn">Reload Shader (F5/Ctrl+S)</button>
                <label style="color: #858585;">
                    Volume: <input type="range" id="volumeSlider" min="0" max="100" value="50" style="width: 100px;">
                    <span id="volumeValue">50%</span>
                </label>
            </div>
            <div id="editorContainer">
                <div id="loadingMessage">Loading Monaco Editor...</div>
            </div>
            <div>
                <div class="hint">Status:</div>
                <div id="errorDisplay" class="info">Loading editor...</div>
            </div>
        </div>
        <div id="rightPanel">
            <canvas id="canvas"></canvas>
            <div class="hint">
                Audio: <span id="audioStatus" class="statusBadge paused">⏸ PAUSED</span><br>
                Frame: <span id="frameCounter">0</span><br>
                Time: <span id="timeCounter">0.00s</span>
            </div>
        </div>
    </div>

    <!-- Load Monaco from CDN -->
    <script src="https://cdnjs.cloudflare.com/ajax/libs/monaco-editor/0.44.0/min/vs/loader.min.js"></script>
    
    <script>
    'use strict';

    // ============================================================================
    // Monaco Editor Setup
    // ============================================================================
    let monacoEditor = null;

    // Configure Monaco loader
    require.config({ 
        paths: { 
            'vs': 'https://cdnjs.cloudflare.com/ajax/libs/monaco-editor/0.44.0/min/vs' 
        }
    });

    // Define WGSL language configuration
    const WGSL_LANGUAGE_CONFIG = {
        comments: {
            lineComment: '//',
            blockComment: ['/*', '*/']
        },
        brackets: [
            ['{', '}'],
            ['[', ']'],
            ['(', ')']
        ],
        autoClosingPairs: [
            { open: '{', close: '}' },
            { open: '[', close: ']' },
            { open: '(', close: ')' },
            { open: '"', close: '"', notIn: ['string'] },
        ],
        surroundingPairs: [
            { open: '{', close: '}' },
            { open: '[', close: ']' },
            { open: '(', close: ')' },
            { open: '"', close: '"' },
        ]
    };

    // WGSL syntax highlighting
    const WGSL_MONARCH_TOKENS = {
        keywords: [
            'const', 'let', 'var', 'fn', 'return', 'if', 'else', 'for', 'while',
            'break', 'continue', 'discard', 'struct', 'type', 'alias'
        ],
        typeKeywords: [
            'f32', 'f16', 'i32', 'u32', 'bool',
            'vec2f', 'vec3f', 'vec4f', 'vec2i', 'vec3i', 'vec4i', 'vec2u', 'vec3u', 'vec4u',
            'vec2', 'vec3', 'vec4',
            'mat2x2', 'mat2x3', 'mat2x4', 'mat3x2', 'mat3x3', 'mat3x4', 'mat4x2', 'mat4x3', 'mat4x4',
            'mat2x2f', 'mat2x3f', 'mat2x4f', 'mat3x2f', 'mat3x3f', 'mat3x4f', 'mat4x2f', 'mat4x3f', 'mat4x4f',
            'array', 'ptr', 'sampler', 'texture_2d', 'texture_storage_2d'
        ],
        builtins: [
            'position', 'vertex_index', 'instance_index', 'front_facing', 'frag_depth',
            'local_invocation_id', 'local_invocation_index', 'global_invocation_id',
            'workgroup_id', 'num_workgroups', 'sample_index', 'sample_mask'
        ],
        operators: [
            '=', '>', '<', '!', '~', '?', ':', '==', '<=', '>=', '!=',
            '&&', '||', '++', '--', '+', '-', '*', '/', '&', '|', '^', '%',
            '<<', '>>', '+=', '-=', '*=', '/=', '&=', '|=', '^=',
            '%=', '<<=', '>>=', '->'
        ],
        functions: [
            'sin', 'cos', 'tan', 'asin', 'acos', 'atan', 'atan2',
            'sinh', 'cosh', 'tanh', 'asinh', 'acosh', 'atanh',
            'pow', 'exp', 'log', 'exp2', 'log2', 'sqrt', 'inverseSqrt',
            'abs', 'sign', 'floor', 'ceil', 'fract', 'trunc', 'round',
            'min', 'max', 'clamp', 'saturate', 'mix', 'step', 'smoothstep',
            'length', 'distance', 'dot', 'cross', 'normalize', 'reflect', 'refract',
            'select', 'all', 'any', 'arrayLength', 'textureStore', 'textureLoad'
        ],
        tokenizer: {
            root: [
                // Attributes
                [/@[a-zA-Z_]\w*/, 'annotation'],
                
                // Keywords
                [/\b(fn|let|const|var|return|if|else|for|while|break|continue|struct)\b/, 'keyword'],
                
                // Type keywords
                [/\b(f32|f16|i32|u32|bool|vec2f|vec3f|vec4f|vec2i|vec3i|vec4i|vec2u|vec3u|vec4u|vec2|vec3|vec4|mat2x2|mat3x3|mat4x4|array|ptr|sampler|texture_2d|texture_storage_2d)\b/, 'type'],
                
                // Built-in functions
                [/\b(sin|cos|tan|abs|min|max|clamp|mix|length|dot|normalize|cross|select|textureStore|textureLoad)\b/, 'support.function'],
                
                // Numbers
                [/\b\d+\.?\d*[fu]?\b/, 'number'],
                [/0[xX][0-9a-fA-F]+[ul]?/, 'number'],
                
                // Strings
                [/"([^"\\]|\\.)*$/, 'string.invalid'],
                [/"/, { token: 'string.quote', bracket: '@open', next: '@string' }],
                
                // Comments
                [/\/\/.*$/, 'comment'],
                [/\/\*/, { token: 'comment', next: '@comment' }],
                
                // Operators
                [/[<>]=?/, 'operator'],
                [/[+\-*\/%=&|^!~]/, 'operator'],
                
                // Delimiters
                [/[{}()\[\]]/, '@brackets'],
                [/[;,.]/, 'delimiter'],
            ],
            comment: [
                [/[^\/*]+/, 'comment'],
                [/\/\*/, 'comment', '@push'],
                ['\\*/', 'comment', '@pop'],
                [/[\/*]/, 'comment']
            ],
            string: [
                [/[^\\"]+/, 'string'],
                [/"/, { token: 'string.quote', bracket: '@close', next: '@pop' }]
            ],
        }
    };

    // ============================================================================
    // Configuration & Constants
    // ============================================================================
    const CONFIG = {
        sampleRate: 48000,
        audioBlockDuration: 0.1,
        channels: 2,
        volume: 0.5,
        screenSize: 512,
        computeThreads: 64,
        computeBufferSize: 2 << 20,
    };

    const DERIVED = {
        samplesPerBlock: (CONFIG.audioBlockDuration * CONFIG.sampleRate) | 0,
        audioBufferSize: 0,
    };
    DERIVED.audioBufferSize = 4 * CONFIG.channels * DERIVED.samplesPerBlock;

    const UNIFORM_STRUCT = {
        time: 0,
        audioCurrentTime: 1,
        audioPlayTime: 2,
        audioFractTime: 3,
        audioFrame: 4,
        SIZE: 5,
    };

    // ============================================================================
    // Application State
    // ============================================================================
    const state = {
        gpuDevice: null,
        audioContext: null,
        gainNode: null,
        
        canvas: null,
        gpuContext: null,
        bindGroupLayout: null,
        pipeline: null,
        uniformBuffer: null,
        computeBuffer: null,
        audioBufferGPU: null,
        audioBuffersReadback: [null, null],
        
        lastFrameTime: 0,
        audioFrame: 0,
        nextAudioTime: 0,
        
        readbackIndex: 0,
        pendingAudio: false,
        isRunning: false,
        isPlaying: false,
    };

    // ============================================================================
    // Default WGSL Shader
    // ============================================================================
    const DEFAULT_WGSL = `const SAMPLE_RATE = ${CONFIG.sampleRate}f;
const SAMPLES_PER_BLOCK = ${DERIVED.samplesPerBlock};
const COMPUTE_THREADS = ${CONFIG.computeThreads};
const SCREEN_SIZE = ${CONFIG.screenSize};
const PI = 3.1415926535897932f;
const TAU = 6.283185307179586f;

struct Uniforms {
    time: f32,
    audioCurrentTime: f32,
    audioPlayTime: f32,
    audioFractTime: f32,
    audioFrame: i32,
}

@binding(0) @group(0) var<uniform> uniforms: Uniforms;
@binding(1) @group(0) var<storage, read_write> computeBuffer: array<f32>;
@binding(2) @group(0) var<storage, read_write> audioBuffer: array<f32>;
@binding(3) @group(0) var screenTexture: texture_storage_2d<bgra8unorm, write>;

@compute @workgroup_size(COMPUTE_THREADS, 1, 1)
fn main(@builtin(global_invocation_id) gid: vec3<u32>) {
    let threadId = gid.x + gid.y * u32(SCREEN_SIZE);
    
    // ========================================================================
    // Graphics: Write to screen texture
    // ========================================================================
    if (gid.x < u32(SCREEN_SIZE) && gid.y < u32(SCREEN_SIZE)) {
        let uv = vec2f(gid.xy) / f32(SCREEN_SIZE);
        let t = uniforms.time;
        
        // Animated pattern synced to audio
        let audioPhase = uniforms.audioFractTime * TAU * 440.0;
        let pattern = cos(uv * 10.0 + t);
        let pulse = sin(audioPhase) * 0.5 + 0.5;
        
        let color = vec4f(
            pattern.x * 0.5 + 0.5,
            pattern.y * 0.5 + 0.5,
            pulse,
            1.0
        );
        
        textureStore(screenTexture, gid.xy, color);
    }
    
    // ========================================================================
    // Audio: Generate samples
    // ========================================================================
    let sampleIndex = i32(threadId);
    if (sampleIndex < SAMPLES_PER_BLOCK) {
        // TIME PRECISION FIX: Use fractional seconds to avoid float drift
        let sampleTime = uniforms.audioFractTime + f32(sampleIndex) / SAMPLE_RATE;
        
        // 440Hz sine wave (A4 note)
        let frequency = 440.0;
        let phase = sampleTime * frequency * TAU;
        let sample = sin(phase) * 0.3;
        
        // Write to interleaved stereo buffer
        audioBuffer[sampleIndex] = sample;
        audioBuffer[SAMPLES_PER_BLOCK + sampleIndex] = sample;
    }
}`;

    // ============================================================================
    // Monaco Initialization
    // ============================================================================
    function initMonaco(callback) {
        require(['vs/editor/editor.main'], function() {
            // Register WGSL language
            monaco.languages.register({ id: 'wgsl' });
            
            // Set language configuration
            monaco.languages.setLanguageConfiguration('wgsl', WGSL_LANGUAGE_CONFIG);
            
            // Define syntax highlighting
            monaco.languages.setMonarchTokensProvider('wgsl', WGSL_MONARCH_TOKENS);
            
            // Create the editor
            const container = document.getElementById('editorContainer');
            container.innerHTML = ''; // Clear loading message
            
            monacoEditor = monaco.editor.create(container, {
                value: DEFAULT_WGSL,
                language: 'wgsl',
                theme: 'vs-dark',
                fontSize: 13,
                minimap: { enabled: false },
                automaticLayout: true,
                scrollBeyondLastLine: false,
                wordWrap: 'on',
                tabSize: 4,
                insertSpaces: true,
                formatOnPaste: true,
                formatOnType: true,
                suggestOnTriggerCharacters: true,
                acceptSuggestionOnEnter: 'on',
                folding: true,
                foldingStrategy: 'indentation',
                renderWhitespace: 'selection',
                renderControlCharacters: false,
                scrollbar: {
                    vertical: 'visible',
                    horizontal: 'visible',
                    useShadows: false,
                    verticalHasArrows: false,
                    horizontalHasArrows: false
                }
            });
            
            // Add keyboard shortcuts
            monacoEditor.addCommand(monaco.KeyCode.F5, () => {
                reloadShader();
            });
            
            monacoEditor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.KeyS, () => {
                reloadShader();
            });
            
            monacoEditor.addCommand(monaco.KeyMod.CtrlCmd | monaco.KeyCode.Space, () => {
                togglePlayPause();
            });
            
            // Set up error markers when shader compilation fails
            window.setMonacoErrors = function(errors) {
                const markers = errors.map(err => ({
                    severity: monaco.MarkerSeverity.Error,
                    startLineNumber: err.lineNum || 1,
                    startColumn: err.linePos || 1,
                    endLineNumber: err.lineNum || 1,
                    endColumn: 1000,
                    message: err.message
                }));
                monaco.editor.setModelMarkers(monacoEditor.getModel(), 'wgsl', markers);
            };
            
            window.clearMonacoErrors = function() {
                monaco.editor.setModelMarkers(monacoEditor.getModel(), 'wgsl', []);
            };
            
            callback();
        });
    }

    // ============================================================================
    // Initialization
    // ============================================================================
    async function init() {
        setupUI();
        
        // Initialize Monaco first
        initMonaco(async () => {
            try {
                await initWebGPU();
                initWebAudio();
                await reloadShader();
                state.isRunning = true;
                requestAnimationFrame(render);
                logStatus('System initialized! Press Play to start audio.', 'success');
            } catch (err) {
                logStatus('Initialization failed: ' + err.message, 'error');
            }
        });
    }

    function setupUI() {
        // Canvas
        state.canvas = document.getElementById('canvas');
        state.canvas.width = CONFIG.screenSize;
        state.canvas.height = CONFIG.screenSize;
        state.canvas.style.width = CONFIG.screenSize + 'px';
        state.canvas.style.height = CONFIG.screenSize + 'px';

        // Play/Pause button
        document.getElementById('playPauseBtn').addEventListener('click', togglePlayPause);

        // Reload button
        document.getElementById('reloadBtn').addEventListener('click', reloadShader);

        // Volume control
        const volumeSlider = document.getElementById('volumeSlider');
        const volumeValue = document.getElementById('volumeValue');
        volumeSlider.addEventListener('input', (e) => {
            const vol = e.target.value / 100;
            CONFIG.volume = vol;
            if (state.gainNode) state.gainNode.gain.value = vol;
            volumeValue.textContent = e.target.value + '%';
        });

        // Handle visibility change
        document.addEventListener('visibilitychange', () => {
            if (!document.hidden && state.audioContext && state.isPlaying) {
                const ctx = state.audioContext;
                state.nextAudioTime = Math.ceil(ctx.currentTime / CONFIG.audioBlockDuration) 
                                     * CONFIG.audioBlockDuration;
                state.pendingAudio = false;
                logStatus('Audio resynced after visibility change', 'info');
            }
        });
    }

    function togglePlayPause() {
        if (!state.audioContext) return;
        
        const btn = document.getElementById('playPauseBtn');
        const statusBadge = document.getElementById('audioStatus');
        
        if (state.isPlaying) {
            state.audioContext.suspend();
            state.isPlaying = false;
            btn.textContent = '▶ Play';
            btn.className = 'paused';
            statusBadge.textContent = '⏸ PAUSED';
            statusBadge.className = 'statusBadge paused';
            logStatus('Audio paused', 'info');
        } else {
            state.audioContext.resume();
            state.isPlaying = true;
            
            const ctx = state.audioContext;
            state.nextAudioTime = Math.ceil(ctx.currentTime / CONFIG.audioBlockDuration) 
                                 * CONFIG.audioBlockDuration;
            state.pendingAudio = false;
            
            btn.textContent = '⏸ Pause';
            btn.className = 'playing';
            statusBadge.textContent = '▶ PLAYING';
            statusBadge.className = 'statusBadge playing';
            logStatus('Audio playing', 'success');
        }
    }

    async function initWebGPU() {
        const adapter = await navigator.gpu?.requestAdapter();
        if (!adapter) throw new Error('WebGPU not supported');

        state.gpuDevice = await adapter.requestDevice({
            requiredFeatures: ['bgra8unorm-storage'],
            requiredLimits: {
                maxBufferSize: Math.pow(2, 30),
                maxStorageBufferBindingSize: Math.pow(2, 30),
            }
        });

        state.gpuContext = state.canvas.getContext('webgpu');
        state.gpuContext.configure({
            device: state.gpuDevice,
            format: navigator.gpu.getPreferredCanvasFormat(),
            usage: GPUTextureUsage.STORAGE_BINDING,
        });

        createGPUResources();
    }

    function createGPUResources() {
        const device = state.gpuDevice;

        state.uniformBuffer = device.createBuffer({
            size: 256,
            usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST,
        });

        state.computeBuffer = device.createBuffer({
            size: CONFIG.computeBufferSize,
            usage: GPUBufferUsage.STORAGE,
        });

        state.audioBufferGPU = device.createBuffer({
            size: DERIVED.audioBufferSize,
            usage: GPUBufferUsage.STORAGE | GPUBufferUsage.COPY_SRC,
        });

        for (let i = 0; i < 2; i++) {
            state.audioBuffersReadback[i] = device.createBuffer({
                size: DERIVED.audioBufferSize,
                usage: GPUBufferUsage.MAP_READ | GPUBufferUsage.COPY_DST,
            });
        }

        state.bindGroupLayout = device.createBindGroupLayout({
            entries: [
                { binding: 0, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'uniform' } },
                { binding: 1, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
                { binding: 2, visibility: GPUShaderStage.COMPUTE, buffer: { type: 'storage' } },
                { binding: 3, visibility: GPUShaderStage.COMPUTE, storageTexture: { 
                    format: 'bgra8unorm', access: 'write-only', viewDimension: '2d' 
                }},
            ],
        });
    }

    function initWebAudio() {
        state.audioContext = new AudioContext();
        state.gainNode = state.audioContext.createGain();
        state.gainNode.gain.value = CONFIG.volume;
        state.gainNode.connect(state.audioContext.destination);
        
        state.nextAudioTime = Math.ceil(state.audioContext.currentTime / CONFIG.audioBlockDuration) 
                             * CONFIG.audioBlockDuration;
        
        state.audioContext.suspend();
    }

    // ============================================================================
    // Live Shader Reload
    // ============================================================================
    async function reloadShader() {
        const code = monacoEditor.getValue();
        
        try {
            logStatus('Compiling shader...', 'info');
            clearMonacoErrors();
            
            const shaderModule = state.gpuDevice.createShaderModule({ code });
            
            const compilationInfo = await shaderModule.getCompilationInfo();
            const errors = compilationInfo.messages.filter(m => m.type === 'error');
            
            if (errors.length > 0) {
                setMonacoErrors(errors);
                const errorMsg = errors.map(e => 
                    `Line ${e.lineNum}: ${e.message}`
                ).join('\n');
                throw new Error('Shader compilation failed:\n' + errorMsg);
            }
            
            const newPipeline = state.gpuDevice.createComputePipeline({
                layout: state.gpuDevice.createPipelineLayout({
                    bindGroupLayouts: [state.bindGroupLayout],
                }),
                compute: { module: shaderModule, entryPoint: 'main' },
            });
            
            state.pipeline = newPipeline;
            
            logStatus('✓ Shader compiled successfully!', 'success');
        } catch (err) {
            logStatus('✗ ' + err.message, 'error');
        }
    }

    function logStatus(message, type = 'info') {
        const display = document.getElementById('errorDisplay');
        display.textContent = message;
        display.className = type;
    }

    // ============================================================================
    // Render Loop (unchanged)
    // ============================================================================
    function render(time) {
        if (!state.isRunning) return;

        const device = state.gpuDevice;
        const ctx = state.audioContext;
        
        document.getElementById('frameCounter').textContent = state.audioFrame;
        document.getElementById('timeCounter').textContent = (time * 0.001).toFixed(2) + 's';

        const uniformData = new ArrayBuffer(256);
        const uniformF32 = new Float32Array(uniformData);
        const uniformI32 = new Int32Array(uniformData);
        
        uniformF32[UNIFORM_STRUCT.time] = time * 0.001;
        uniformF32[UNIFORM_STRUCT.audioCurrentTime] = ctx.currentTime;
        uniformF32[UNIFORM_STRUCT.audioPlayTime] = state.nextAudioTime;
        uniformF32[UNIFORM_STRUCT.audioFractTime] = state.nextAudioTime % 1;
        uniformI32[UNIFORM_STRUCT.audioFrame] = state.audioFrame;
        
        device.queue.writeBuffer(state.uniformBuffer, 0, uniformData);

        const textureView = state.gpuContext.getCurrentTexture().createView();
        const bindGroup = device.createBindGroup({
            layout: state.bindGroupLayout,
            entries: [
                { binding: 0, resource: { buffer: state.uniformBuffer } },
                { binding: 1, resource: { buffer: state.computeBuffer } },
                { binding: 2, resource: { buffer: state.audioBufferGPU } },
                { binding: 3, resource: textureView },
            ],
        });

        const encoder = device.createCommandEncoder();
        const pass = encoder.beginComputePass();
        pass.setPipeline(state.pipeline);
        pass.setBindGroup(0, bindGroup);
        pass.dispatchWorkgroups(
            CONFIG.screenSize / CONFIG.computeThreads,
            CONFIG.screenSize,
            1
        );
        pass.end();

        if (state.isPlaying && ctx.currentTime >= state.nextAudioTime - CONFIG.audioBlockDuration && !state.pendingAudio) {
            state.pendingAudio = true;
            
            const readbackBuffer = state.audioBuffersReadback[state.readbackIndex];
            encoder.copyBufferToBuffer(
                state.audioBufferGPU, 0,
                readbackBuffer, 0,
                DERIVED.audioBufferSize
            );
            
            device.queue.submit([encoder.finish()]);
            
            readbackBuffer.mapAsync(GPUMapMode.READ).then(() => {
                playAudioBlock(readbackBuffer);
                state.readbackIndex = 1 - state.readbackIndex;
                state.pendingAudio = false;
            }).catch(err => {
                console.error('Audio readback failed:', err);
                state.pendingAudio = false;
            });
        } else {
            device.queue.submit([encoder.finish()]);
        }

        requestAnimationFrame(render);
    }

    function playAudioBlock(readbackBuffer) {
        const ctx = state.audioContext;
        const audioData = new Float32Array(readbackBuffer.getMappedRange());
        
        const audioBuffer = ctx.createBuffer(
            CONFIG.channels,
            DERIVED.samplesPerBlock,
            CONFIG.sampleRate
        );
        
        for (let ch = 0; ch < CONFIG.channels; ch++) {
            const channelData = audioBuffer.getChannelData(ch);
            const offset = ch * DERIVED.samplesPerBlock;
            for (let i = 0; i < DERIVED.samplesPerBlock; i++) {
                channelData[i] = audioData[offset + i];
            }
        }
        
        readbackBuffer.unmap();
        
        const source = ctx.createBufferSource();
        source.buffer = audioBuffer;
        source.connect(state.gainNode);
        source.start(state.nextAudioTime);
        
        state.nextAudioTime += CONFIG.audioBlockDuration;
        state.audioFrame++;
    }

    // ============================================================================
    // Start
    // ============================================================================
    window.addEventListener('load', init);
    </script>
</body>
</html>